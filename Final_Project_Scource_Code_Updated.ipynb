{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2a6a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (2.90)\n",
      "Requirement already satisfied: pyaudio in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (0.2.14)\n",
      "Requirement already satisfied: pywhatkit in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (5.4)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pyttsx3) (306)\n",
      "Requirement already satisfied: comtypes in c:\\programdata\\anaconda3\\lib\\site-packages (from pyttsx3) (1.1.10)\n",
      "Requirement already satisfied: wikipedia in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pywhatkit) (1.4.0)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from pywhatkit) (9.2.0)\n",
      "Requirement already satisfied: Flask in c:\\programdata\\anaconda3\\lib\\site-packages (from pywhatkit) (1.1.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from pywhatkit) (2.28.1)\n",
      "Requirement already satisfied: pyautogui in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pywhatkit) (0.9.54)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask->pywhatkit) (2.0.3)\n",
      "Requirement already satisfied: click>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask->pywhatkit) (8.0.4)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from Flask->pywhatkit) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask->pywhatkit) (2.0.1)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pyautogui->pywhatkit) (0.0.9)\n",
      "Requirement already satisfied: pymsgbox in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pyautogui->pywhatkit) (1.0.9)\n",
      "Requirement already satisfied: pytweening>=1.0.4 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pyautogui->pywhatkit) (1.0.7)\n",
      "Requirement already satisfied: mouseinfo in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pyautogui->pywhatkit) (0.1.3)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pyautogui->pywhatkit) (0.1.30)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pywhatkit) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pywhatkit) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pywhatkit) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from requests->pywhatkit) (2.10)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from wikipedia->pywhatkit) (4.11.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from click>=5.1->Flask->pywhatkit) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask->pywhatkit) (2.0.1)\n",
      "Requirement already satisfied: pyrect in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pygetwindow>=0.0.5->pyautogui->pywhatkit) (0.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia->pywhatkit) (2.3.1)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from mouseinfo->pyautogui->pywhatkit) (1.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3 pyaudio pywhatkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f10c06a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (2.15.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (3.7.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.5.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (8.2.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow spacy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cba66d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: speechrecognition in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (3.10.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from speechrecognition) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from speechrecognition) (4.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.26.0->speechrecognition) (2.10)\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy download en_core_web_sm\n",
    "!pip install speechrecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aefe376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (4.36.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a581013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (3.7.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.5.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.24.4)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (8.2.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efab8d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Entry, Button, PhotoImage\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import spacy\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c63c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8db97b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d6f58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load pre-trained language model (GPT-2)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e22d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement json (from versions: none)\n",
      "ERROR: No matching distribution found for json\n"
     ]
    }
   ],
   "source": [
    "!pip install json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "825b2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71b3d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/VAMSI/OneDrive/Desktop/chatbot.h5/tech.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffac8dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'aiml',\n",
       "   'question': ['What is Artificial Intelligence (AI)?'],\n",
       "   'answer': ['AI is the development of computer systems that can perform tasks requiring human intelligence.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'b',\n",
       "   'question': ['Explain the difference between narrow AI and general AI.'],\n",
       "   'answer': ['Narrow AI is task-specific, while general AI has broad cognitive abilities.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'c',\n",
       "   'question': ['What are the main goals of AI?'],\n",
       "   'answer': ['Goals of AI include automation, problem-solving, learning, perception, and language understanding.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'd',\n",
       "   'question': ['How does machine learning differ from traditional programming?'],\n",
       "   'answer': ['ML learns from data patterns, while traditional programming uses explicit instructions.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'e',\n",
       "   'question': ['What is supervised learning in machine learning?'],\n",
       "   'answer': ['Supervised learning involves training on labeled data with known outcomes.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'f',\n",
       "   'question': ['Can you provide an example of unsupervised learning?'],\n",
       "   'answer': ['Unsupervised learning includes clustering, identifying patterns without labeled data.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'g',\n",
       "   'question': ['What is the role of neural networks in AI?'],\n",
       "   'answer': ['Neural networks model the human brain, crucial for pattern recognition.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'h',\n",
       "   'question': ['Explain the concept of deep learning.'],\n",
       "   'answer': ['Deep learning uses deep neural networks for hierarchical data representation.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'i',\n",
       "   'question': ['What are the challenges in implementing natural language processing (NLP)?'],\n",
       "   'answer': ['Challenges in NLP include context understanding and language nuances.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'j',\n",
       "   'question': ['How does reinforcement learning work in AI systems?'],\n",
       "   'answer': ['Reinforcement learning trains algorithms by rewarding or penalizing based on actions.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'k',\n",
       "   'question': ['May I know Your Name?'],\n",
       "   'answer': ['Hi,My Name is Friday , How Can I Help You?'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'l',\n",
       "   'question': ['Describe the bias-variance tradeoff in machine learning.'],\n",
       "   'answer': ['Bias-variance tradeoff balances model complexity to prevent overfitting or underfitting.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'm',\n",
       "   'question': ['How is AI used in computer vision applications?'],\n",
       "   'answer': ['AI in computer vision is employed for tasks like image recognition, object detection, and scene understanding.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'n',\n",
       "   'question': ['What are the ethical considerations in AI development and deployment?'],\n",
       "   'answer': ['Ethical considerations in AI involve issues such as bias, transparency, accountability, and the impact on privacy and employment.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'o',\n",
       "   'question': ['Explain the concept of transfer learning in machine learning.'],\n",
       "   'answer': ['Transfer learning involves leveraging knowledge gained from one task to improve learning in a different but related task.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'p',\n",
       "   'question': ['How does AI contribute to robotics and automation?'],\n",
       "   'answer': ['AI enhances robotics and automation by enabling machines to perceive, learn, and adapt to dynamic environments, improving efficiency and autonomy.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'q',\n",
       "   'question': ['What is the Turing Test, and why is it significant in AI?'],\n",
       "   'answer': [\"The Turing Test assesses a machine's ability to exhibit human-like intelligence, emphasizing the goal of achieving indistinguishable human-machine interactions.\"],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'r',\n",
       "   'question': ['Discuss the role of AI in healthcare and medical diagnosis.'],\n",
       "   'answer': ['AI aids healthcare by analyzing medical data, assisting in diagnostics, predicting disease outcomes, and personalizing treatment plans.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 's',\n",
       "   'question': ['What are the key components of a conversational AI system?'],\n",
       "   'answer': ['Conversational AI systems consist of natural language processing, dialogue management, intent recognition, and response generation components.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 't',\n",
       "   'question': ['Explain the concept of Explainable AI (XAI).'],\n",
       "   'answer': ['Explainable AI focuses on making AI models interpretable, providing insights into their decisions to enhance transparency and trust.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'u',\n",
       "   'question': ['How is AI applied in the financial industry for fraud detection?'],\n",
       "   'answer': ['AI in finance detects fraud by analyzing patterns in transactions, identifying anomalies, and improving security measures to protect against fraudulent activities.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'v',\n",
       "   'question': ['What is the difference between strong AI and weak AI?'],\n",
       "   'answer': ['Strong AI possesses general intelligence comparable to human intelligence, while weak AI is specialized for specific tasks and lacks broad cognitive abilities.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'w',\n",
       "   'question': ['Discuss the impact of AI on job markets and employment.'],\n",
       "   'answer': ['AI impacts job markets by automating routine tasks, creating new job roles, and necessitating upskilling to adapt to changing workforce dynamics.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'x',\n",
       "   'question': ['How can AI be used for personalization in e-commerce?'],\n",
       "   'answer': ['AI in e-commerce personalizes user experiences by analyzing preferences, predicting user behavior, and recommending products tailored to individual needs.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'y',\n",
       "   'question': ['Explain the concept of adversarial attacks in AI.'],\n",
       "   'answer': ['Adversarial attacks involve manipulating input data to deceive AI models, highlighting vulnerabilities and the need for robust model defenses.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'z',\n",
       "   'question': ['What are the challenges in ensuring the security of AI systems?'],\n",
       "   'answer': ['Ensuring the security of AI systems involves addressing issues like data privacy, model robustness, and protection against adversarial attacks.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'aa',\n",
       "   'question': ['How is AI applied in recommendation systems?'],\n",
       "   'answer': ['AI powers recommendation systems by analyzing user behavior, preferences, and historical data to suggest personalized content, products, or services.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ba',\n",
       "   'question': ['Discuss the role of AI in autonomous vehicles.'],\n",
       "   'answer': ['AI enables autonomous vehicles to perceive their environment, make decisions, and navigate safely, contributing to the development of self-driving cars.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ca',\n",
       "   'question': ['What are the limitations of current AI technologies?'],\n",
       "   'answer': ['Current AI technologies face limitations such as interpretability challenges, data biases, ethical concerns, and the inability to fully replicate human cognitive abilities.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'da',\n",
       "   'question': ['How can AI be leveraged for environmental sustainability?'],\n",
       "   'answer': ['AI can contribute to environmental sustainability through applications like climate modeling, energy optimization, and natural resource management.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ea',\n",
       "   'question': ['What is the primary goal of natural language processing (NLP) in AI?'],\n",
       "   'answer': ['The primary goal of NLP in AI is to enable machines to understand, interpret, and generate human language, facilitating communication between humans and computers.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'fa',\n",
       "   'question': ['How does computer vision contribute to AI applications?'],\n",
       "   'answer': ['Computer vision in AI enables machines to interpret visual information, supporting applications like image recognition, object detection, and scene understanding.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ga',\n",
       "   'question': ['Explain the concept of reinforcement learning in the context of AI.'],\n",
       "   'answer': ['Reinforcement learning involves training models through a system of rewards and punishments, allowing AI agents to learn optimal behaviors in dynamic environments.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ha',\n",
       "   'question': ['What role do recurrent neural networks (RNNs) play in sequence-based tasks in AI?'],\n",
       "   'answer': ['RNNs are crucial for sequence-based tasks in AI, as they can capture dependencies in sequential data, making them suitable for tasks like natural language processing and time series analysis.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ia',\n",
       "   'question': ['How can AI be applied in the field of cybersecurity?'],\n",
       "   'answer': ['AI enhances cybersecurity by detecting anomalies, identifying potential threats, and automating responses, thereby strengthening defenses against cyber attacks.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ja',\n",
       "   'question': ['What challenges are associated with implementing speech recognition in AI systems?'],\n",
       "   'answer': ['Challenges in speech recognition in AI include variations in accents, background noise, and the need for robust algorithms to accurately transcribe spoken language.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ka',\n",
       "   'question': ['Describe the importance of hyperparameter tuning in machine learning models.'],\n",
       "   'answer': [\"Hyperparameter tuning is vital in machine learning as it optimizes model performance by adjusting parameters that are not learned during training, influencing the model's behavior and accuracy.\"],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'la',\n",
       "   'question': ['In the context of AI, what is the difference between supervised and unsupervised learning?'],\n",
       "   'answer': ['Supervised learning involves training models on labeled data with known outcomes, while unsupervised learning deals with unlabeled data, focusing on finding patterns and relationships without explicit guidance.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ma',\n",
       "   'question': ['How does AI contribute to personalized content recommendations in streaming services?'],\n",
       "   'answer': ['AI personalizes content recommendations by analyzing user preferences, viewing history, and behavior, providing tailored suggestions to enhance user experience in streaming services.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'na',\n",
       "   'question': ['What is the significance of explainability in AI models, especially in critical applications?'],\n",
       "   'answer': ['Explainability in AI models is crucial, particularly in critical applications, as it ensures transparency and enables users to understand how and why a model makes specific decisions, fostering trust and accountability.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'oa',\n",
       "   'question': ['In the realm of AI, what is the purpose of anomaly detection algorithms?'],\n",
       "   'answer': ['Anomaly detection algorithms in AI identify unusual patterns or deviations from normal behavior in data, helping to detect outliers, anomalies, or potential issues in various applications.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'pa',\n",
       "   'question': ['How is AI utilized in the optimization of supply chain management processes?'],\n",
       "   'answer': ['AI optimizes supply chain management by forecasting demand, improving inventory management, and enhancing logistics efficiency, leading to cost savings and operational improvements.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'qa',\n",
       "   'question': ['Explain the concept of adversarial training in the context of AI security.'],\n",
       "   'answer': ['Adversarial training in AI security involves training models on adversarial examples to improve robustness, making them more resistant to attacks and enhancing overall security.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ra',\n",
       "   'question': ['What are the key challenges in implementing AI in the healthcare industry?'],\n",
       "   'answer': ['Challenges in implementing AI in healthcare include data privacy concerns, regulatory compliance, integration with existing systems, and ensuring the ethical use of sensitive medical data.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'sa',\n",
       "   'question': ['How does AI contribute to the development of autonomous drones and robotics?'],\n",
       "   'answer': ['AI enables autonomous drones and robotics by providing capabilities such as navigation, obstacle avoidance, and decision-making, enhancing their autonomy and efficiency in various applications.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ta',\n",
       "   'question': ['Discuss the ethical considerations in the use of AI for predictive policing.'],\n",
       "   'answer': ['Ethical considerations in using AI for predictive policing involve issues of bias, fairness, accountability, and potential infringement on individual rights, requiring careful oversight and responsible deployment.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ua',\n",
       "   'question': ['What role does unsupervised learning play in clustering and data exploration in AI?'],\n",
       "   'answer': ['Unsupervised learning in AI is instrumental in clustering similar data points, exploring patterns, and discovering hidden structures in data without the need for labeled examples.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'va',\n",
       "   'question': ['How can AI be leveraged for sentiment analysis in social media and customer feedback?'],\n",
       "   'answer': ['AI in sentiment analysis analyzes social media and customer feedback to determine attitudes, opinions, and emotions, providing valuable insights for businesses to understand and respond to user sentiments.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'wa',\n",
       "   'question': ['What challenges are associated with ensuring fairness and mitigating bias in AI algorithms?'],\n",
       "   'answer': ['Ensuring fairness and mitigating bias in AI algorithms involves challenges related to biased training data, algorithmic transparency, and the need for ethical guidelines to address potential discrimination and disparities in outcomes.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'xa',\n",
       "   'question': ['Explain the concept of transfer learning and its applications in image recognition.'],\n",
       "   'answer': ['Transfer learning involves leveraging knowledge gained from one task to improve learning in a different but related task. In image recognition, transfer learning accelerates model training by using pre-trained models on large datasets, adapting them to new recognition tasks with smaller datasets.']},\n",
       "  {'tag': 'ya',\n",
       "   'question': ['In AI-driven recommendation systems, what factors influence the accuracy of suggestions?'],\n",
       "   'answer': ['Factors influencing the accuracy of suggestions in AI-driven recommendation systems include user behavior, preferences, historical data, collaborative filtering, and algorithms that analyze patterns to provide personalized and relevant recommendations.']},\n",
       "  {'tag': 'za',\n",
       "   'question': ['How does AI contribute to the field of drug discovery in pharmaceutical research?'],\n",
       "   'answer': ['AI in drug discovery accelerates the identification of potential drug candidates by analyzing biological data, predicting molecular interactions, and optimizing drug properties. It expedites the discovery process, leading to more efficient and cost-effective pharmaceutical research.']},\n",
       "  {'tag': 'ab',\n",
       "   'question': ['Describe the potential impact of AI on job markets and the future of work.'],\n",
       "   'answer': ['The impact of AI on job markets and the future of work includes automation of routine tasks, the creation of new job roles in AI development and maintenance, and the need for upskilling to adapt to changing workforce dynamics. It poses challenges and opportunities for employment.']},\n",
       "  {'tag': 'bb',\n",
       "   'question': ['What are the key components of a reinforcement learning algorithm in AI?'],\n",
       "   'answer': ['The key components of a reinforcement learning algorithm in AI include an agent, an environment, actions, rewards, and a policy. The agent learns to take actions in the environment to maximize cumulative rewards by adapting its policy through trial and error.']},\n",
       "  {'tag': 'cb',\n",
       "   'question': ['How does AI contribute to weather forecasting and climate modeling?'],\n",
       "   'answer': ['AI enhances weather forecasting and climate modeling by analyzing vast datasets, improving prediction accuracy, and modeling complex climate interactions. It aids in understanding climate patterns, predicting extreme events, and developing more reliable forecasting models.']},\n",
       "  {'tag': 'db',\n",
       "   'question': ['Explain the concept of generative adversarial networks (GANs) in AI.'],\n",
       "   'answer': ['Generative adversarial networks (GANs) consist of a generator and a discriminator that compete in a training process. The generator creates data, and the discriminator evaluates its authenticity. This adversarial training results in the generation of realistic synthetic data, valuable in image and content creation.']},\n",
       "  {'tag': 'eb',\n",
       "   'question': ['What challenges are faced in implementing AI for real-time language translation?'],\n",
       "   'answer': ['Challenges in implementing AI for real-time language translation include handling diverse linguistic nuances, context preservation, maintaining low latency, and ensuring accuracy across multiple languages. Addressing these challenges is essential for providing seamless and accurate translations in real-time.']},\n",
       "  {'tag': 'fb',\n",
       "   'question': ['How can AI be used in financial forecasting and investment strategies?'],\n",
       "   'answer': ['AI in financial forecasting analyzes historical data, market trends, and economic indicators to predict financial outcomes. It aids in investment strategies by providing insights into market conditions, risk assessment, and portfolio optimization, contributing to more informed decision-making.']},\n",
       "  {'tag': 'gb',\n",
       "   'question': ['Discuss the role of AI in the creation of virtual assistants and chatbots.'],\n",
       "   'answer': ['AI plays a crucial role in creating virtual assistants and chatbots by employing natural language processing (NLP) and machine learning algorithms. These technologies enable virtual assistants to understand user queries, provide relevant information, and engage in natural and context-aware conversations.']},\n",
       "  {'tag': 'hb',\n",
       "   'question': ['In the context of AI, what are the applications of natural language understanding (NLU)?'],\n",
       "   'answer': ['Natural language understanding (NLU) in AI is applied in tasks such as sentiment analysis, intent recognition, and language comprehension. NLU enables machines to interpret and respond to human language, facilitating more advanced and context-aware interactions.']},\n",
       "  {'tag': 'ib',\n",
       "   'question': ['How is AI utilized in predictive maintenance for industrial machinery and equipment?'],\n",
       "   'answer': ['AI in predictive maintenance analyzes sensor data, equipment performance, and historical maintenance records to predict when machinery and equipment are likely to fail. This proactive approach reduces downtime, extends equipment lifespan, and enhances overall efficiency in industrial operations.']},\n",
       "  {'tag': 'jb',\n",
       "   'question': ['What is the significance of cross-validation in training and evaluating machine learning models?'],\n",
       "   'answer': ['Cross-validation is significant in training and evaluating machine learning models as it helps assess model performance on different subsets of data. It provides a more robust evaluation, minimizing the risk of overfitting or underfitting and improving the generalization ability of the model.']},\n",
       "  {'tag': 'kb',\n",
       "   'question': ['Describe the role of AI in enhancing the efficiency of renewable energy sources.'],\n",
       "   'answer': ['AI enhances the efficiency of renewable energy sources by optimizing energy production, predicting demand, and improving grid management. Machine learning algorithms analyze data from solar and wind sources to maximize energy output, contributing to the integration of sustainable energy into the power grid.']},\n",
       "  {'tag': 'lb',\n",
       "   'question': ['How do recommendation algorithms adapt to changing user preferences in AI?'],\n",
       "   'answer': [\"Recommendation algorithms in AI adapt to changing user preferences by continuously learning from user interactions and feedback. They update user profiles, reevaluate preferences, and adjust recommendations to ensure they remain relevant and reflective of the user's evolving tastes.\"]},\n",
       "  {'tag': 'mb',\n",
       "   'question': ['Explain the concept of semi-supervised learning and its advantages in AI.'],\n",
       "   'answer': ['Semi-supervised learning in AI involves training models on a dataset containing both labeled and unlabeled data. This approach leverages the benefits of labeled data for supervised learning while utilizing unlabeled data to improve model generalization. Semi-supervised learning can be more cost-effective and efficient when labeled data is scarce.']},\n",
       "  {'tag': 'nb',\n",
       "   'question': ['In the field of AI, how does the integration of robotics and automation impact industries?'],\n",
       "   'answer': ['The integration of robotics and automation in AI transforms industries by increasing efficiency, reducing labor costs, and enhancing precision in tasks. Robots and automated systems powered by AI contribute to manufacturing, logistics, healthcare, and various sectors, reshaping workflows and improving productivity.']},\n",
       "  {'tag': 'ob',\n",
       "   'question': ['Discuss the challenges in implementing AI for emotion recognition in human-computer interaction.'],\n",
       "   'answer': ['Challenges in implementing AI for emotion recognition include accurately interpreting complex human emotions, addressing cultural differences, and ensuring privacy and ethical considerations. Achieving reliable and context-aware emotion recognition in diverse settings remains a significant research and development challenge.']},\n",
       "  {'tag': 'pb',\n",
       "   'question': ['What are the applications of AI in the optimization of transportation and logistics?'],\n",
       "   'answer': ['AI applications in transportation and logistics include route optimization, predictive maintenance for vehicles, demand forecasting, and real-time monitoring. These technologies enhance efficiency, reduce costs, and improve overall logistics management in areas such as shipping, delivery, and supply chain operations.']},\n",
       "  {'tag': 'qb',\n",
       "   'question': ['How does AI contribute to the creation of deepfake content, and what risks does it pose?'],\n",
       "   'answer': ['AI contributes to the creation of deepfake content through advanced algorithms that manipulate audio and visual data to generate realistic but synthetic content. Risks associated with deepfakes include misinformation, identity theft, and the potential to deceive and manipulate individuals or the public.']},\n",
       "  {'tag': 'rb',\n",
       "   'question': ['Describe the role of AI in predicting and preventing equipment failures in manufacturing.'],\n",
       "   'answer': ['AI in manufacturing predicts and prevents equipment failures by analyzing sensor data, detecting anomalies, and implementing predictive maintenance strategies. Machine learning models identify patterns indicative of potential failures, allowing for proactive maintenance and minimizing downtime.']},\n",
       "  {'tag': 'sb',\n",
       "   'question': ['What challenges are associated with implementing AI in the field of education?'],\n",
       "   'answer': ['Challenges in implementing AI in education include ensuring data privacy, addressing ethical concerns, adapting to diverse learning environments, and providing sufficient teacher training. Additionally, there may be resistance to technological changes and concerns about equity in access to AI-driven educational tools.']},\n",
       "  {'tag': 'tb',\n",
       "   'question': ['Explain the concept of swarm intelligence and its applications in AI systems.'],\n",
       "   'answer': ['Swarm intelligence involves mimicking the collective behavior of decentralized, self-organized systems, such as those observed in bee colonies or ant colonies. In AI, swarm intelligence is applied to optimization problems, robotics, and decision-making, where a group of simple agents collectively solves complex tasks.']},\n",
       "  {'tag': 'ub',\n",
       "   'question': ['In the context of AI, how does the choice of features impact the performance of a model?'],\n",
       "   'answer': [\"The choice of features in AI significantly impacts model performance. Relevant features enhance a model's ability to capture patterns and make accurate predictions, while irrelevant or redundant features can introduce noise and hinder performance. Feature selection and engineering are crucial steps in improving model accuracy.\"]},\n",
       "  {'tag': 'vb',\n",
       "   'question': ['Discuss the potential risks and benefits of AI-driven autonomous weapons.'],\n",
       "   'answer': ['AI-driven autonomous weapons pose risks such as ethical concerns, potential misuse, and the lack of human oversight. However, they also offer benefits in terms of precision, rapid decision-making, and reduced human casualties. Striking a balance between these benefits and risks is essential for responsible development and deployment.']},\n",
       "  {'tag': 'wb',\n",
       "   'question': ['How can AI be applied to enhance the efficiency of customer support services?'],\n",
       "   'answer': ['AI enhances customer support services by implementing chatbots, virtual assistants, and natural language processing (NLP) algorithms. These technologies automate routine inquiries, provide instant responses, and route complex issues to human agents, thereby improving efficiency, reducing response times, and enhancing the overall customer experience.']},\n",
       "  {'tag': 'xb',\n",
       "   'question': ['What role does AI play in the development of smart cities and urban planning?'],\n",
       "   'answer': ['AI contributes to smart cities and urban planning by analyzing data from sensors, traffic systems, and public services. It aids in optimizing traffic flow, energy consumption, waste management, and public safety. AI-driven insights enable informed decision-making for sustainable urban development.']},\n",
       "  {'tag': 'yb',\n",
       "   'question': ['Explain the concept of ensemble learning and its advantages in improving model accuracy.'],\n",
       "   'answer': ['Ensemble learning combines multiple models to improve overall accuracy and generalization. Methods like bagging and boosting create diverse models, reducing overfitting and enhancing performance. Ensemble learning is effective when individual models may have different strengths or weaknesses, leading to a more robust prediction.']},\n",
       "  {'tag': 'zb',\n",
       "   'question': ['In AI-driven image recognition, how do convolutional neural networks (CNNs) work?'],\n",
       "   'answer': ['Convolutional Neural Networks (CNNs) in AI image recognition use convolutional layers to automatically learn features from input images. These features are then used for classification or detection. CNNs are effective for tasks like image recognition due to their ability to capture hierarchical patterns in data.']},\n",
       "  {'tag': 'ac',\n",
       "   'question': ['How does AI contribute to the optimization of advertising targeting and campaigns?'],\n",
       "   'answer': ['AI optimizes advertising targeting and campaigns by analyzing user behavior, preferences, and demographics. Algorithms predict which ads are most likely to resonate with specific audiences, improving ad relevance and increasing the efficiency of advertising spend. This leads to more personalized and effective marketing strategies.']},\n",
       "  {'tag': 'bc',\n",
       "   'question': ['Discuss the challenges and opportunities in implementing AI for natural disaster prediction and response.'],\n",
       "   'answer': ['Challenges in implementing AI for natural disaster prediction and response include data scarcity, model accuracy, and the need for real-time decision-making. However, AI offers opportunities for early warning systems, risk assessment, and resource allocation, improving disaster preparedness and response strategies.']},\n",
       "  {'tag': 'cc',\n",
       "   'question': ['What is machine learning, and how does it differ from traditional programming?'],\n",
       "   'answer': ['Machine learning is a subset of artificial intelligence that involves the development of algorithms that enable computers to learn from data and make predictions without being explicitly programmed. In traditional programming, explicit instructions are provided to perform specific tasks, while in machine learning, models learn patterns and relationships from data.']},\n",
       "  {'tag': 'dc',\n",
       "   'question': ['Explain the concept of supervised learning in machine learning.'],\n",
       "   'answer': ['Supervised learning in machine learning involves training a model on a labeled dataset, where the input data is paired with corresponding output labels. The model learns to map inputs to outputs, making predictions on new, unseen data. It is commonly used for tasks such as classification and regression.']},\n",
       "  {'tag': 'ec',\n",
       "   'question': ['How does unsupervised learning differ from supervised learning?'],\n",
       "   'answer': ['Unsupervised learning in machine learning involves training a model on an unlabeled dataset, where the algorithm discovers patterns and structures in the data without explicit output labels. Unlike supervised learning, there is no provided target variable, and the model explores inherent relationships within the data.']},\n",
       "  {'tag': 'fc',\n",
       "   'question': ['What is the role of labeled data in training machine learning models?'],\n",
       "   'answer': ['Labeled data in machine learning serves as the training set containing input-output pairs used to teach a model. The labeled examples provide the model with information about the relationships between inputs and desired outputs, enabling the algorithm to learn and make predictions on new, unseen data.']},\n",
       "  {'tag': 'gc',\n",
       "   'question': ['Describe the bias-variance tradeoff in the context of machine learning.'],\n",
       "   'answer': [\"The bias-variance tradeoff in machine learning refers to the balance between model simplicity (bias) and flexibility (variance). High bias may result in underfitting, while high variance may lead to overfitting. Achieving an optimal tradeoff minimizes errors on both training and unseen data, improving the model's generalization.\"]},\n",
       "  {'tag': 'hc',\n",
       "   'question': ['What are some common algorithms used in supervised learning?'],\n",
       "   'answer': ['Common algorithms in supervised learning include linear regression, logistic regression, decision trees, support vector machines, and neural networks. These algorithms are used for tasks such as regression and classification, where the model learns from labeled data to make predictions on new data.']},\n",
       "  {'tag': 'ic',\n",
       "   'question': ['Explain the purpose of cross-validation in machine learning.'],\n",
       "   'answer': [\"Cross-validation in machine learning assesses the performance and generalization ability of a model by splitting the dataset into multiple subsets. It helps detect overfitting or underfitting issues, providing a more reliable estimate of the model's performance on new, unseen data than a single train-test split.\"]},\n",
       "  {'tag': 'jc',\n",
       "   'question': ['How does feature engineering contribute to the performance of machine learning models?'],\n",
       "   'answer': [\"Feature engineering involves transforming or creating new features from existing data to improve the performance of machine learning models. Well-designed features can enhance the model's ability to capture patterns and relationships, leading to better predictions and improved overall model performance.\"]},\n",
       "  {'tag': 'kc',\n",
       "   'question': ['What is the significance of regularization in preventing overfitting in machine learning?'],\n",
       "   'answer': [\"Regularization in machine learning is a technique that introduces a penalty term to the model's cost function, discouraging overly complex models. It helps prevent overfitting by controlling the magnitude of model parameters, leading to improved generalization on unseen data.\"]},\n",
       "  {'tag': 'lc',\n",
       "   'question': ['Discuss the difference between regression and classification in machine learning.'],\n",
       "   'answer': ['Regression in machine learning involves predicting a continuous numerical value, such as prices or temperatures. Classification, on the other hand, deals with predicting the class or category to which an input belongs. Regression and classification represent two main types of supervised learning tasks.']},\n",
       "  {'tag': 'mc',\n",
       "   'question': ['What are decision trees, and how are they used in machine learning?'],\n",
       "   'answer': ['Decision trees in machine learning are tree-like models composed of nodes, representing decisions based on input features, and branches, representing possible outcomes. They are used for both classification and regression tasks, providing a visual and interpretable representation of decision-making processes.']},\n",
       "  {'tag': 'nc',\n",
       "   'question': ['Explain the concept of ensemble learning and provide examples.'],\n",
       "   'answer': ['Ensemble learning combines multiple models to improve overall predictive performance. Examples include Random Forests, which use multiple decision trees, and AdaBoost, which combines weak learners into a strong learner. Ensemble methods leverage diversity among models to enhance accuracy and robustness.']},\n",
       "  {'tag': 'oc',\n",
       "   'question': ['What is clustering, and how is it applied in unsupervised learning?'],\n",
       "   'answer': ['Clustering in unsupervised learning involves grouping similar data points together based on their features or attributes. Common clustering algorithms include K-means and hierarchical clustering. It helps discover patterns and relationships within data when there are no predefined categories or labels.']},\n",
       "  {'tag': 'pc',\n",
       "   'question': ['Describe the k-nearest neighbors (KNN) algorithm and its applications.'],\n",
       "   'answer': ['The k-nearest neighbors (KNN) algorithm in machine learning classifies data points based on the majority class of their k nearest neighbors in the feature space. It is used for both classification and regression tasks and finds applications in recommendation systems, image recognition, and pattern recognition.']},\n",
       "  {'tag': 'qc',\n",
       "   'question': ['How does dimensionality reduction contribute to machine learning models?'],\n",
       "   'answer': ['Dimensionality reduction in machine learning reduces the number of input features while preserving essential information. It addresses the curse of dimensionality, improves model efficiency, and helps prevent overfitting. Techniques like Principal Component Analysis (PCA) are used for dimensionality reduction.']},\n",
       "  {'tag': 'rc',\n",
       "   'question': ['What is the purpose of gradient descent in machine learning optimization?'],\n",
       "   'answer': ['Gradient descent in machine learning is an optimization algorithm that iteratively adjusts model parameters to minimize the cost function. It uses the gradient of the cost function with respect to the parameters to find the steepest descent, gradually approaching the optimal parameter values for improved model performance.']},\n",
       "  {'tag': 'sc',\n",
       "   'question': ['Explain the difference between batch learning and online learning.'],\n",
       "   'answer': ['Batch learning involves training a model on the entire dataset at once, updating parameters after processing the entire dataset. Online learning, or stochastic gradient descent, updates model parameters after processing each individual data point. Online learning is well-suited for large datasets and dynamic environments.']},\n",
       "  {'tag': 'tc',\n",
       "   'question': ['Discuss the challenges associated with imbalanced datasets in machine learning.'],\n",
       "   'answer': ['Imbalanced datasets in machine learning pose challenges, as models may be biased toward the majority class. Challenges include skewed model performance metrics, difficulty in detecting minority class patterns, and the need for techniques like resampling or adjusting class weights to address the imbalance.']},\n",
       "  {'tag': 'uc',\n",
       "   'question': ['How does the Support Vector Machine (SVM) algorithm work in classification?'],\n",
       "   'answer': ['The Support Vector Machine (SVM) algorithm classifies data by finding the hyperplane that maximally separates different classes in the feature space. SVM is effective in high-dimensional spaces and is used for classification tasks, including image recognition and text categorization.']},\n",
       "  {'tag': 'vc',\n",
       "   'question': ['What are neural networks, and how do they simulate the human brain in machine learning?'],\n",
       "   'answer': [\"Neural networks in machine learning are computational models inspired by the structure and function of the human brain. They consist of interconnected nodes (neurons) organized in layers. Neural networks simulate the brain's ability to learn from data, adapt to patterns, and make predictions based on complex relationships.\"]},\n",
       "  {'tag': 'wc',\n",
       "   'question': ['Describe the backpropagation algorithm and its role in training neural networks.'],\n",
       "   'answer': ['The backpropagation algorithm is used to train neural networks by minimizing the error between predicted and actual outputs. It involves propagating the error backward through the network, adjusting weights and biases to minimize the error. Backpropagation is crucial for optimizing neural networks during the training process.']},\n",
       "  {'tag': 'xc',\n",
       "   'question': ['What is the significance of activation functions in neural networks?'],\n",
       "   'answer': [\"Activation functions in neural networks introduce non-linearity to the model, enabling it to learn complex patterns and relationships. Common activation functions include sigmoid, tanh, and ReLU. They determine the output of a node based on weighted inputs and play a key role in the network's ability to capture and represent data.\"]},\n",
       "  {'tag': 'yc',\n",
       "   'question': ['Explain the concept of deep learning and its applications.'],\n",
       "   'answer': ['Deep learning is a subset of machine learning that involves neural networks with multiple layers (deep neural networks). It excels at learning hierarchical features and representations. Applications include image and speech recognition, natural language processing, autonomous vehicles, and various tasks requiring complex pattern recognition.']},\n",
       "  {'tag': 'zc',\n",
       "   'question': ['How do recurrent neural networks (RNNs) handle sequential data in machine learning?'],\n",
       "   'answer': ['Recurrent Neural Networks (RNNs) are designed to handle sequential data by maintaining a hidden state that captures information from previous time steps. This allows RNNs to model temporal dependencies and process sequences, making them suitable for tasks like natural language processing, time series prediction, and speech recognition.']},\n",
       "  {'tag': 'ad',\n",
       "   'question': ['Discuss the advantages and disadvantages of using convolutional neural networks (CNNs) in image recognition.'],\n",
       "   'answer': ['Convolutional Neural Networks (CNNs) excel in image recognition due to their ability to automatically learn hierarchical features. Advantages include parameter sharing, spatial invariance, and feature extraction. However, disadvantages may include high computational requirements and the need for large datasets.']},\n",
       "  {'tag': 'bd',\n",
       "   'question': ['What is transfer learning, and how does it benefit machine learning models?'],\n",
       "   'answer': ['Transfer learning involves leveraging knowledge gained from one task to improve learning in a different but related task. It benefits machine learning models by enabling them to start with pre-trained models on large datasets, adapting them to new tasks with smaller datasets. Transfer learning accelerates training and enhances performance.']},\n",
       "  {'tag': 'cd',\n",
       "   'question': ['Explain the concept of natural language processing (NLP) in machine learning.'],\n",
       "   'answer': ['Natural Language Processing (NLP) in machine learning focuses on enabling computers to understand, interpret, and generate human language. It involves tasks such as text analysis, sentiment analysis, language translation, and speech recognition. NLP plays a crucial role in applications like virtual assistants and chatbots.']},\n",
       "  {'tag': 'dd',\n",
       "   'question': ['How are word embeddings used in natural language processing tasks?'],\n",
       "   'answer': ['Word embeddings in natural language processing represent words as dense vectors in a continuous vector space. They capture semantic relationships between words, allowing models to understand context and relationships in text data. Word embeddings are widely used in tasks such as text classification, language translation, and sentiment analysis.']},\n",
       "  {'tag': 'ed',\n",
       "   'question': ['What challenges are associated with sentiment analysis in machine learning?'],\n",
       "   'answer': ['Challenges in sentiment analysis include handling context, sarcasm, and ambiguity in language. Additionally, sentiment analysis models may struggle with domain adaptation and diverse cultural expressions of sentiment. Achieving accuracy in sentiment analysis requires addressing these challenges and considering the nuances of human communication.']},\n",
       "  {'tag': 'fd',\n",
       "   'question': ['Discuss the role of machine learning in recommendation systems.'],\n",
       "   'answer': ['Machine learning plays a key role in recommendation systems by analyzing user behavior and preferences to provide personalized suggestions. Collaborative filtering and content-based filtering are common approaches. Recommendation systems are applied in e-commerce, streaming services, and various platforms to enhance user experience and engagement.']},\n",
       "  {'tag': 'gd',\n",
       "   'question': ['How does collaborative filtering work in recommendation systems?'],\n",
       "   'answer': [\"Collaborative filtering in recommendation systems identifies patterns and similarities in user behavior to make predictions. It can be user-based, where recommendations are based on similar users' preferences, or item-based, where recommendations are based on similarities between items. Collaborative filtering is effective in capturing user preferences and improving recommendation accuracy.\"]},\n",
       "  {'tag': 'hd',\n",
       "   'question': ['Explain the concept of reinforcement learning and provide examples.'],\n",
       "   'answer': ['Reinforcement learning involves training models to make sequential decisions by receiving feedback in the form of rewards or penalties. Examples include training a computer program to play games, navigate environments, or control robotic systems. Reinforcement learning is employed in scenarios where agents learn through trial and error.']},\n",
       "  {'tag': 'id',\n",
       "   'question': ['What is Q-learning, and how is it applied in reinforcement learning?'],\n",
       "   'answer': ['Q-learning is a model-free reinforcement learning algorithm used to find optimal actions in a given state. It involves updating a Q-value table based on the rewards obtained from different actions. Q-learning is applied in tasks where an agent learns to take actions to maximize cumulative rewards over time.']},\n",
       "  {'tag': 'jd',\n",
       "   'question': ['Discuss the challenges in training deep reinforcement learning models.'],\n",
       "   'answer': ['Challenges in training deep reinforcement learning models include the need for large amounts of data, high computational requirements, and the risk of overfitting. The exploration-exploitation dilemma and stability issues during training are also challenges that researchers and practitioners aim to address for effective deep reinforcement learning.']},\n",
       "  {'tag': 'kd',\n",
       "   'question': ['How does machine learning contribute to anomaly detection in cybersecurity?'],\n",
       "   'answer': ['Machine learning contributes to anomaly detection in cybersecurity by learning normal patterns of system behavior and identifying deviations that may indicate cyber threats. Supervised and unsupervised learning techniques are applied to detect anomalies in network traffic, user behavior, or system logs, enhancing cybersecurity defenses.']},\n",
       "  {'tag': 'ld',\n",
       "   'question': ['Describe the role of machine learning in fraud detection in financial transactions.'],\n",
       "   'answer': ['Machine learning in fraud detection analyzes patterns in financial transactions to identify unusual or fraudulent activities. Models can learn from historical fraud data to detect anomalies, assess risk, and flag potentially fraudulent transactions. Machine learning enhances the efficiency and accuracy of fraud detection in real-time.']},\n",
       "  {'tag': 'md',\n",
       "   'question': ['What are autoencoders, and how are they used in unsupervised learning?'],\n",
       "   'answer': ['Autoencoders are neural network architectures used in unsupervised learning for feature learning and data compression. They consist of an encoder and a decoder, and the model learns to reconstruct input data. Autoencoders find applications in dimensionality reduction, data denoising, and generating new data similar to the input.']},\n",
       "  {'tag': 'nd',\n",
       "   'question': ['Explain the concept of hyperparameter tuning in machine learning.'],\n",
       "   'answer': ['Hyperparameter tuning in machine learning involves optimizing the hyperparameters, such as learning rates or model complexity, to improve model performance. Techniques include grid search, random search, and Bayesian optimization. Proper hyperparameter tuning is essential for achieving the best possible performance of machine learning models.']},\n",
       "  {'tag': 'od',\n",
       "   'question': ['How can machine learning be applied in predicting stock prices and financial markets?'],\n",
       "   'answer': ['Machine learning in predicting stock prices analyzes historical data, market trends, and relevant indicators to make predictions. Models may use time series analysis, sentiment analysis of financial news, and technical indicators. While predictions can provide insights, the dynamic and unpredictable nature of financial markets poses challenges.']},\n",
       "  {'tag': 'pd',\n",
       "   'question': ['Discuss the role of machine learning in healthcare for disease prediction and diagnosis.'],\n",
       "   'answer': ['Machine learning in healthcare contributes to disease prediction and diagnosis by analyzing medical data, images, and patient records. Models can identify patterns indicative of diseases, assist in early diagnosis, and predict patient outcomes. Machine learning enhances the accuracy and efficiency of healthcare decision-making.']},\n",
       "  {'tag': 'qd',\n",
       "   'question': ['What challenges are associated with handling missing data in machine learning?'],\n",
       "   'answer': ['Challenges in handling missing data in machine learning include potential bias, reduced model accuracy, and the need for imputation techniques. Addressing missing data requires careful consideration of data patterns, choosing appropriate imputation methods, and understanding the impact on model performance.']},\n",
       "  {'tag': 'rd',\n",
       "   'question': ['Explain the concept of kernel methods in support vector machines.'],\n",
       "   'answer': ['Kernel methods in support vector machines (SVM) transform input data into a higher-dimensional space using a kernel function. This allows SVM to find nonlinear decision boundaries in the original feature space. Common kernel functions include linear, polynomial, and radial basis function (RBF) kernels.']},\n",
       "  {'tag': 'sd',\n",
       "   'question': ['Discuss the impact of feature scaling on machine learning algorithms.'],\n",
       "   'answer': ['Feature scaling in machine learning ensures that all features have a similar scale, preventing some features from dominating others. Common scaling methods include Min-Max scaling and Z-score normalization. Feature scaling is crucial for algorithms sensitive to feature magnitudes, such as distance-based models like k-nearest neighbors.']},\n",
       "  {'tag': 'td',\n",
       "   'question': ['How is machine learning applied in image segmentation and object detection?'],\n",
       "   'answer': ['Machine learning in image segmentation and object detection involves training models to identify and delineate objects within images. Techniques include convolutional neural networks (CNNs) and region-based approaches. Applications range from medical image analysis to autonomous vehicles and surveillance systems.']},\n",
       "  {'tag': 'ud',\n",
       "   'question': ['Describe the role of machine learning in natural resource management and environmental monitoring.'],\n",
       "   'answer': ['Machine learning contributes to natural resource management and environmental monitoring by analyzing satellite imagery, sensor data, and environmental variables. Models can predict deforestation, monitor biodiversity, and assess environmental impact. Machine learning aids in making informed decisions for sustainable resource management.']},\n",
       "  {'tag': 'vd',\n",
       "   'question': ['What is the difference between batch gradient descent and stochastic gradient descent?'],\n",
       "   'answer': ['Batch gradient descent and stochastic gradient descent are optimization algorithms used in training machine learning models. Batch gradient descent updates model parameters based on the entire training dataset, while stochastic gradient descent updates parameters after processing individual data points. Stochastic gradient descent is more computationally efficient and suitable for large datasets.']},\n",
       "  {'tag': 'wd',\n",
       "   'question': ['How can machine learning be used for customer churn prediction in business?'],\n",
       "   'answer': ['Machine learning for customer churn prediction analyzes customer behavior, transaction data, and engagement metrics to identify potential churners. Models can predict the likelihood of customers leaving a service, allowing businesses to take proactive measures such as targeted retention efforts. Churn prediction enhances customer relationship management.']},\n",
       "  {'tag': 'xd',\n",
       "   'question': ['Discuss the challenges of interpretability and explainability in machine learning models.'],\n",
       "   'answer': ['Challenges of interpretability and explainability in machine learning models include the complexity of deep learning models, the black-box nature of certain algorithms, and the need for transparency in decision-making. Addressing these challenges is crucial for building trust, understanding model behavior, and ensuring ethical deployment of machine learning.']},\n",
       "  {'tag': 'yd',\n",
       "   'question': ['Explain the concept of imputation in handling missing data in machine learning.'],\n",
       "   'answer': ['Imputation in handling missing data involves filling in missing values with estimated or imputed values. Common imputation methods include mean imputation, median imputation, and predictive imputation. Imputation helps maintain dataset completeness and enables machine learning models to use the available information for analysis.']},\n",
       "  {'tag': 'zd',\n",
       "   'question': ['What is the role of the learning rate in gradient descent optimization algorithms?'],\n",
       "   'answer': ['The learning rate in gradient descent controls the size of the steps taken during optimization. It influences how quickly the algorithm converges to the optimal solution. A high learning rate may cause oscillations or divergence, while a low learning rate may lead to slow convergence. Choosing an appropriate learning rate is crucial for efficient and stable optimization.']},\n",
       "  {'tag': 'ae',\n",
       "   'question': ['How does the Expectation-Maximization (EM) algorithm work in unsupervised learning?'],\n",
       "   'answer': ['The Expectation-Maximization (EM) algorithm in unsupervised learning iteratively estimates the parameters of a model with latent variables. In the E-step, it computes the expected values of latent variables given observed data. In the M-step, it maximizes the likelihood function, updating model parameters. EM is used when data involves missing or unobservable variables, such as in clustering or Gaussian Mixture Models.']},\n",
       "  {'tag': 'be',\n",
       "   'question': ['Discuss the applications of machine learning in speech recognition.'],\n",
       "   'answer': ['Machine learning in speech recognition is applied to convert spoken language into text or commands. It finds applications in virtual assistants, transcription services, voice-activated systems, and hands-free control in various devices. Deep learning models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs), have significantly improved speech recognition accuracy.']},\n",
       "  {'tag': 'ce',\n",
       "   'question': ['What is the Curse of Dimensionality, and how does it impact machine learning models?'],\n",
       "   'answer': ['The Curse of Dimensionality refers to the challenges and limitations that arise when dealing with high-dimensional data. As the number of features or dimensions increases, the data becomes sparse, and the volume of the feature space expands exponentially. This can lead to increased computational complexity, overfitting, and the need for more data to maintain model generalization.']},\n",
       "  {'tag': 'de',\n",
       "   'question': ['Explain the concept of bias in machine learning algorithms.'],\n",
       "   'answer': ['In machine learning, bias refers to the systematic error or deviation of predictions from the true values. It can result from simplifying assumptions made during model training. High bias may lead to underfitting, where the model fails to capture the underlying patterns in the data. Balancing bias and variance is crucial for building accurate and robust machine learning models.']},\n",
       "  {'tag': 'fe',\n",
       "   'question': ['Discuss the applications of machine learning in natural disaster prediction and response.'],\n",
       "   'answer': ['Machine learning is applied in natural disaster prediction and response for tasks such as early detection, risk assessment, and resource allocation. Models analyze historical data, satellite imagery, and sensor data to predict disasters like earthquakes, hurricanes, and floods. Machine learning aids in improving preparedness and coordinating effective responses.']},\n",
       "  {'tag': 'ge',\n",
       "   'question': ['How does the Naive Bayes algorithm work in classification tasks?'],\n",
       "   'answer': [\"The Naive Bayes algorithm in classification tasks is based on Bayes' theorem. It assumes independence between features, simplifying the calculation of conditional probabilities. The algorithm calculates the probability of a class given the observed features and assigns the class with the highest probability. Naive Bayes is commonly used in text classification and spam filtering.\"]},\n",
       "  {'tag': 'he',\n",
       "   'question': ['What are the applications of machine learning in marketing and customer segmentation?'],\n",
       "   'answer': ['Machine learning applications in marketing include customer segmentation, targeted advertising, and personalized recommendations. Models analyze customer behavior, preferences, and purchase history to identify segments with similar characteristics. This enables businesses to tailor marketing strategies, optimize campaigns, and enhance customer engagement.']},\n",
       "  {'tag': 'ie',\n",
       "   'question': ['Explain the concept of bagging and boosting in ensemble learning.'],\n",
       "   'answer': ['Bagging (Bootstrap Aggregating) and boosting are ensemble learning techniques. Bagging combines predictions from multiple models trained on different subsets of the data, reducing variance and improving stability. Boosting focuses on training models sequentially, giving more weight to misclassified instances, and combining them to create a strong learner. Both techniques enhance model performance.']},\n",
       "  {'tag': 'je',\n",
       "   'question': ['How does the Random Forest algorithm work, and what are its advantages?'],\n",
       "   'answer': ['The Random Forest algorithm is an ensemble learning method that builds multiple decision trees during training. It aggregates their predictions to improve accuracy and control overfitting. Random Forest introduces randomness in tree construction, enhancing diversity. Its advantages include high accuracy, robustness, and the ability to handle large datasets with high-dimensional features.']},\n",
       "  {'tag': 'ke',\n",
       "   'question': ['Discuss the tradeoffs between interpretability and complexity in machine learning models.'],\n",
       "   'answer': [\"The tradeoffs between interpretability and complexity involve balancing the model's ability to provide understandable insights versus capturing intricate patterns. Simpler models, like linear regression, are more interpretable but may lack predictive power. Complex models, such as deep neural networks, may achieve high accuracy but are less interpretable. The choice depends on the specific use case and requirements.\"]},\n",
       "  {'tag': 'le',\n",
       "   'question': ['What is the role of feature importance in machine learning models?'],\n",
       "   'answer': [\"Feature importance in machine learning models indicates the contribution of each feature to the model's predictions. It helps identify influential variables and understand their impact on outcomes. Feature importance is used for feature selection, model interpretation, and assessing the relevance of different factors in influencing the model's decisions.\"]},\n",
       "  {'tag': 'me',\n",
       "   'question': ['Explain the concept of one-hot encoding in handling categorical data in machine learning.'],\n",
       "   'answer': ['One-hot encoding is a technique used to represent categorical data numerically. Each category is assigned a unique binary code, with one element set to 1 and the others set to 0. This encoding allows machine learning models to process categorical variables, ensuring that their values do not imply ordinal relationships. One-hot encoding is commonly used in classification tasks.']},\n",
       "  {'tag': 'ne',\n",
       "   'question': ['How can machine learning be used for predictive maintenance in manufacturing?'],\n",
       "   'answer': ['Machine learning for predictive maintenance in manufacturing analyzes equipment and sensor data to predict when maintenance is needed. Models can identify patterns indicative of potential failures or issues, allowing for proactive maintenance to prevent downtime. Predictive maintenance enhances operational efficiency and reduces the costs associated with unplanned equipment breakdowns.']},\n",
       "  {'tag': 'oe',\n",
       "   'question': ['Discuss the challenges associated with overfitting and underfitting in machine learning.'],\n",
       "   'answer': ['Overfitting occurs when a model learns the training data too well, capturing noise and producing poor generalization on new data. Underfitting occurs when a model is too simple to capture the underlying patterns, leading to low accuracy. Balancing these challenges involves selecting an appropriate model complexity, using regularization techniques, and validating models on separate test data.']},\n",
       "  {'tag': 'pe',\n",
       "   'question': ['What is the impact of class imbalance on the performance of machine learning models?'],\n",
       "   'answer': ['Class imbalance in machine learning occurs when one class has significantly fewer instances than others. It can lead to biased models that perform poorly on minority classes. Techniques such as resampling, synthetic data generation, and adjusting class weights are used to address class imbalance and improve model performance on underrepresented classes.']},\n",
       "  {'tag': 'qe',\n",
       "   'question': ['Explain the concept of precision and recall in classification evaluation metrics.'],\n",
       "   'answer': ['Precision and recall are classification evaluation metrics. Precision measures the proportion of true positive predictions among all positive predictions, emphasizing accuracy. Recall measures the proportion of true positives among all actual positives, emphasizing completeness. The balance between precision and recall depends on the specific goals and requirements of the classification task.']},\n",
       "  {'tag': 're',\n",
       "   'question': ['Discuss the role of machine learning in climate modeling and weather prediction.'],\n",
       "   'answer': ['Machine learning in climate modeling and weather prediction involves analyzing vast amounts of atmospheric data to improve accuracy and forecast lead times. Models can identify patterns, predict extreme weather events, and enhance our understanding of climate phenomena. Machine learning contributes to more reliable and timely weather predictions, aiding in disaster preparedness.']},\n",
       "  {'tag': 'se',\n",
       "   'question': ['How does the Time Series analysis contribute to machine learning applications?'],\n",
       "   'answer': ['Time Series analysis in machine learning deals with temporal data points ordered chronologically. It helps model trends, seasonality, and patterns in time-varying data. Applications include stock price prediction, energy consumption forecasting, and epidemiological predictions. Time Series analysis enhances predictive modeling in scenarios where historical sequence information is crucial.']},\n",
       "  {'tag': 'te',\n",
       "   'question': ['What are the applications of machine learning in the gaming industry?'],\n",
       "   'answer': ['Machine learning applications in the gaming industry include personalized game recommendations, player behavior analysis, and dynamic difficulty adjustment. Models can adapt gameplay based on individual preferences, predict player actions, and enhance user experience. Machine learning contributes to creating more engaging and tailored gaming experiences.']},\n",
       "  {'tag': 'ue',\n",
       "   'question': ['Describe the challenges of handling skewed data distributions in machine learning.'],\n",
       "   'answer': ['Skewed data distributions in machine learning, where one class or outcome is heavily represented, can lead to biased models. Challenges include reduced predictive performance on minority classes, biased accuracy metrics, and the need for specialized handling techniques. Addressing skewed data involves techniques such as resampling, using different evaluation metrics, or employing algorithms robust to imbalance.']},\n",
       "  {'tag': 've',\n",
       "   'question': ['Explain the concept of word frequency in natural language processing tasks.'],\n",
       "   'answer': ['Word frequency in natural language processing refers to the count of occurrences of words in a given text corpus. Analyzing word frequency is essential for tasks like text classification, sentiment analysis, and information retrieval. It helps identify important keywords, understand document characteristics, and preprocess text data for machine learning models.']},\n",
       "  {'tag': 'we',\n",
       "   'question': ['Discuss the role of machine learning in optimizing advertising targeting and personalization.'],\n",
       "   'answer': ['Machine learning optimizes advertising targeting and personalization by analyzing user behavior, preferences, and demographic information. Models predict which ads a user is likely to engage with, improving click-through rates and conversion rates. Advertisers can deliver more relevant content to specific audiences, enhancing the overall effectiveness of advertising campaigns.']},\n",
       "  {'tag': 'xe',\n",
       "   'question': ['What is the impact of feature selection on the performance of machine learning models?'],\n",
       "   'answer': ['Feature selection in machine learning involves choosing a subset of relevant features to improve model performance. It reduces dimensionality, mitigates overfitting, and enhances interpretability. Effective feature selection leads to more efficient models, faster training times, and improved generalization on new data. The impact of feature selection depends on the characteristics of the dataset and the chosen algorithm.']},\n",
       "  {'tag': 'ye',\n",
       "   'question': ['How can machine learning be applied in network intrusion detection systems?'],\n",
       "   'answer': ['Machine learning in network intrusion detection systems analyzes network traffic patterns to detect anomalous behavior indicative of cyberattacks or intrusions. Models learn from normal network behavior and can identify deviations that may signify security threats. Machine learning enhances the ability to detect and respond to cybersecurity incidents in real time.']},\n",
       "  {'tag': 'ze',\n",
       "   'question': ['Describe the role of hyperparameter optimization techniques in improving model performance.'],\n",
       "   'answer': ['Hyperparameter optimization techniques in machine learning involve tuning the parameters that are not learned during training. Methods such as grid search, random search, and Bayesian optimization are used to find the optimal combination of hyperparameter values. Proper hyperparameter tuning enhances model generalization, accuracy, and robustness across different datasets.']},\n",
       "  {'tag': 'af',\n",
       "   'question': ['What are the ethical considerations in machine learning, especially in sensitive applications?'],\n",
       "   'answer': ['Ethical considerations in machine learning involve addressing issues related to bias, fairness, transparency, and accountability. In sensitive applications like healthcare or criminal justice, ethical considerations include privacy protection, avoiding discrimination, and ensuring responsible use of AI technologies. Striking a balance between innovation and ethical principles is crucial for the responsible development and deployment of machine learning systems.']},\n",
       "  {'tag': 'bf',\n",
       "   'question': ['Explain the concept of cross-entropy loss in classification tasks.'],\n",
       "   'answer': ['Cross-entropy loss, or log loss, is a measure used in classification tasks to quantify the difference between predicted probabilities and true class labels. It penalizes models for assigning low probabilities to the true class. Minimizing cross-entropy loss during training improves the accuracy of probability estimates and overall classification performance.']},\n",
       "  {'tag': 'cf',\n",
       "   'question': ['Discuss the challenges associated with deploying machine learning models in real-world scenarios.'],\n",
       "   'answer': ['Deploying machine learning models in real-world scenarios poses challenges such as model interpretability, scalability, and adapting to changing environments. Ensuring ethical and unbiased deployment, handling diverse data sources, and addressing security concerns are crucial. Continuous monitoring and updates are needed to maintain model performance and relevance over time.']},\n",
       "  {'tag': 'df',\n",
       "   'question': ['How can machine learning be used for sentiment analysis in social media and customer reviews?'],\n",
       "   'answer': ['Machine learning for sentiment analysis in social media and customer reviews involves classifying text into positive, negative, or neutral sentiments. Models analyze language patterns, context, and sentiment indicators to understand opinions. Sentiment analysis is applied in brand monitoring, customer feedback analysis, and social media insights, helping businesses gauge public sentiment.']},\n",
       "  {'tag': 'ef',\n",
       "   'question': ['What is the role of data preprocessing in preparing datasets for machine learning?'],\n",
       "   'answer': ['Data preprocessing plays a crucial role in preparing datasets for machine learning by cleaning, transforming, and organizing the data. It involves handling missing values, dealing with outliers, scaling features, encoding categorical variables, and splitting the data into training and testing sets. Proper data preprocessing ensures that the data is suitable for training robust and accurate machine learning models.']},\n",
       "  {'tag': 'hf',\n",
       "   'question': ['Describe the concept of A/B testing and its application in machine learning experiments.'],\n",
       "   'answer': ['A/B testing is a statistical method used in machine learning experiments to compare two or more versions of a model or system. It involves dividing users or samples into groups and exposing them to different variants. A/B testing helps assess the impact of changes, features, or algorithms on performance metrics, guiding decisions for model improvement or deployment.']},\n",
       "  {'tag': 'if',\n",
       "   'question': ['How does the LASSO regression algorithm contribute to feature selection in machine learning?'],\n",
       "   'answer': ['The LASSO (Least Absolute Shrinkage and Selection Operator) regression algorithm contributes to feature selection by adding a penalty term to the linear regression objective function. This penalty encourages sparsity, forcing some coefficients to become exactly zero. Features with zero coefficients are excluded from the model, effectively performing automatic feature selection and regularization.']},\n",
       "  {'tag': 'jf',\n",
       "   'question': ['Discuss the challenges of model interpretability in complex deep learning architectures.'],\n",
       "   'answer': ['Model interpretability is challenging in complex deep learning architectures due to the black-box nature of many models. Deep neural networks with numerous layers and parameters make it difficult to understand how specific features contribute to predictions. Addressing this challenge is crucial for gaining trust in model predictions, especially in sensitive domains.']},\n",
       "  {'tag': 'kf',\n",
       "   'question': ['Explain the concept of overfitting and regularization techniques in machine learning.'],\n",
       "   'answer': [\"Overfitting occurs when a model learns noise in the training data, resulting in poor generalization to new data. Regularization techniques aim to prevent overfitting by adding penalty terms to the model's objective function. Common regularization methods include L1 and L2 regularization, dropout, and early stopping. These techniques promote simpler models that generalize well to unseen data.\"]},\n",
       "  {'tag': 'lf',\n",
       "   'question': ['What are the applications of machine learning in energy consumption prediction?'],\n",
       "   'answer': ['Machine learning applications in energy consumption prediction involve forecasting energy usage patterns. Models analyze historical consumption data, weather conditions, and other relevant factors to predict future energy demands. This aids in optimizing energy distribution, managing resources efficiently, and implementing sustainable practices in the energy sector.']},\n",
       "  {'tag': 'mf',\n",
       "   'question': ['Describe the role of machine learning in personalized medicine and treatment plans.'],\n",
       "   'answer': ['Machine learning in personalized medicine analyzes individual patient data, including genetic information, to tailor treatment plans. Models can predict optimal drug responses, identify genetic markers, and recommend personalized interventions. This approach enhances treatment effectiveness, reduces side effects, and contributes to more targeted and efficient healthcare.']},\n",
       "  {'tag': 'nf',\n",
       "   'question': ['Discuss the impact of imbalanced classes on the evaluation of machine learning models.'],\n",
       "   'answer': ['Imbalanced classes in machine learning, where one class is significantly underrepresented, can lead to biased model evaluations. Accuracy may not reflect true performance, and models might prioritize the majority class. Evaluation metrics like precision, recall, and F1 score become essential for assessing model performance, especially in scenarios with imbalanced class distributions.']},\n",
       "  {'tag': 'of',\n",
       "   'question': ['How can machine learning be applied in predicting customer lifetime value in business?'],\n",
       "   'answer': ['Machine learning predicts customer lifetime value by analyzing customer behavior, purchasing patterns, and interactions. Models estimate the potential future value of a customer, guiding business decisions on customer engagement, marketing strategies, and resource allocation. Predicting customer lifetime value contributes to optimizing customer relationships and maximizing business profitability.']},\n",
       "  {'tag': 'pf',\n",
       "   'question': ['Explain the concept of transfer learning and its applications in different domains.'],\n",
       "   'answer': ['Transfer learning involves leveraging knowledge gained from one task to improve performance on a related task. In machine learning, pre-trained models on large datasets can be fine-tuned for specific tasks with smaller datasets. Transfer learning finds applications in computer vision, natural language processing, and various domains where data and computational resources are limited.']},\n",
       "  {'tag': 'qf',\n",
       "   'question': ['Discuss the challenges associated with handling noisy data in machine learning.'],\n",
       "   'answer': ['Handling noisy data in machine learning is challenging as it may introduce errors and reduce model accuracy. Challenges include distinguishing noise from genuine patterns, selecting appropriate noise filtering techniques, and avoiding overfitting. Robust preprocessing, feature engineering, and using noise-resistant algorithms are crucial for mitigating the impact of noisy data.']},\n",
       "  {'tag': 'rf',\n",
       "   'question': ['What is the role of natural language understanding (NLU) in machine learning applications?'],\n",
       "   'answer': ['Natural Language Understanding (NLU) in machine learning involves the ability to comprehend and interpret human language. NLU models understand context, semantics, and user intent, enabling applications like chatbots, sentiment analysis, and language translation. NLU is essential for bridging the gap between human communication and machine processing.']},\n",
       "  {'tag': 'sf',\n",
       "   'question': ['Describe the concept of model selection and evaluation in machine learning experiments.'],\n",
       "   'answer': ['Model selection in machine learning involves choosing the most suitable algorithm for a given task. Evaluation metrics, such as accuracy, precision, recall, and F1 score, are used to assess model performance. Proper model selection and evaluation ensure the deployment of effective and accurate machine learning models for specific applications.']},\n",
       "  {'tag': 'tf',\n",
       "   'question': ['How does the Expectation-Maximization (EM) algorithm work in Gaussian Mixture Models (GMM)?'],\n",
       "   'answer': ['The Expectation-Maximization (EM) algorithm in Gaussian Mixture Models (GMM) iteratively estimates the parameters of a mixture of Gaussian distributions. In the E-step, it computes the expected values of the latent variables (cluster assignments) given the observed data and current parameter estimates. In the M-step, it maximizes the likelihood function, updating the parameters. EM is used for clustering and density estimation in GMMs.']},\n",
       "  {'tag': 'uf',\n",
       "   'question': ['Discuss the impact of hyperparameter tuning on the performance of machine learning models.'],\n",
       "   'answer': [\"Hyperparameter tuning involves optimizing the hyperparameters of a machine learning model to achieve better performance. Proper tuning can significantly impact a model's accuracy, generalization, and ability to handle different datasets. Techniques like grid search, random search, and Bayesian optimization are employed to find the optimal combination of hyperparameter values.\"]},\n",
       "  {'tag': 'vf',\n",
       "   'question': ['Explain the concept of batch normalization and its application in deep neural networks.'],\n",
       "   'answer': ['Batch normalization is a technique used in deep neural networks to improve training stability and speed. It normalizes the input of each layer by adjusting and scaling activations within mini-batches. This mitigates issues like internal covariate shift, accelerates convergence, and allows for more robust training of deep networks. Batch normalization is commonly applied in convolutional and fully connected layers.']},\n",
       "  {'tag': 'wf',\n",
       "   'question': ['What are the challenges of applying machine learning in dynamic and evolving environments?'],\n",
       "   'answer': ['Applying machine learning in dynamic and evolving environments poses challenges due to changing data distributions, concept drift, and the need for continuous adaptation. Models may become outdated, requiring frequent updates. Challenges include maintaining model performance, handling evolving patterns, and ensuring timely adaptation to new information while avoiding overfitting to past data.']},\n",
       "  {'tag': 'xf',\n",
       "   'question': ['Discuss the role of machine learning in predicting and preventing equipment failures in manufacturing.'],\n",
       "   'answer': ['Machine learning predicts and prevents equipment failures in manufacturing by analyzing sensor data and historical performance. Models identify patterns indicative of impending failures, allowing for proactive maintenance. This approach minimizes downtime, extends equipment lifespan, and enhances overall efficiency in manufacturing processes.']},\n",
       "  {'tag': 'yf',\n",
       "   'question': ['How can machine learning be used for feature extraction in image and signal processing?'],\n",
       "   'answer': ['Machine learning for feature extraction in image and signal processing involves using models to automatically identify and extract relevant features from raw data. Convolutional Neural Networks (CNNs) are particularly effective in image feature extraction. Feature extraction enhances the representation of data, making it more suitable for subsequent tasks such as classification or object recognition.']},\n",
       "  {'tag': 'zf',\n",
       "   'question': ['Describe the challenges associated with interpretability and trust in deep learning models.'],\n",
       "   'answer': ['Interpretability and trust in deep learning models are challenging due to their complex architectures and black-box nature. Understanding how models make decisions is crucial for user acceptance, especially in sensitive applications. Challenges include explaining deep neural network predictions, addressing bias, and developing techniques for model transparency and interpretability.']},\n",
       "  {'tag': 'ag',\n",
       "   'question': ['What is the role of machine learning in optimizing the efficiency of recommendation systems?'],\n",
       "   'answer': ['Machine learning optimizes the efficiency of recommendation systems by analyzing user behavior, preferences, and historical interactions. Models predict user preferences and recommend relevant items, enhancing user experience and engagement. Techniques like collaborative filtering, content-based filtering, and hybrid models contribute to the efficiency and effectiveness of recommendation systems.']},\n",
       "  {'tag': 'bg',\n",
       "   'question': ['What is deep learning, and how does it differ from traditional machine learning?'],\n",
       "   'answer': ['Deep learning is a subset of machine learning that involves neural networks with multiple layers (deep neural networks). It differs from traditional machine learning in its ability to automatically learn hierarchical representations from data. Deep learning excels in tasks like image and speech recognition, where intricate patterns and features can be captured through the depth of the network.']},\n",
       "  {'tag': 'cg',\n",
       "   'question': ['Explain the structure of a neural network and its basic components.'],\n",
       "   'answer': ['A neural network consists of layers, including an input layer, one or more hidden layers, and an output layer. Neurons or nodes in each layer are connected with weights. The input layer receives features, hidden layers process information, and the output layer produces predictions. Activation functions introduce non-linearity, allowing neural networks to learn complex relationships.']},\n",
       "  {'tag': 'dg',\n",
       "   'question': ['What is the role of activation functions in deep learning models?'],\n",
       "   'answer': [\"Activation functions in deep learning introduce non-linearity to the model, enabling it to learn complex patterns. Common activation functions include the sigmoid, hyperbolic tangent (tanh), and rectified linear unit (ReLU). They determine the output of a neuron, control information flow, and contribute to the model's capacity to learn and represent intricate relationships in the data.\"]},\n",
       "  {'tag': 'eg',\n",
       "   'question': ['Describe the training process of a neural network.'],\n",
       "   'answer': ['The training process of a neural network involves forward and backward passes. During the forward pass, input data is passed through the network, and predictions are generated. The loss function quantifies the difference between predictions and actual values. During the backward pass (backpropagation), gradients of the loss with respect to the weights are computed. Optimizers adjust weights to minimize the loss, iteratively updating the model and improving its ability to make accurate predictions.']},\n",
       "  {'tag': 'fg',\n",
       "   'question': ['How does backpropagation work in the context of deep learning?'],\n",
       "   'answer': ['Backpropagation in deep learning is a supervised learning algorithm for training neural networks. It involves computing the gradient of the loss function with respect to the weights during the forward pass. The computed gradients are then used to update the weights using optimization algorithms like gradient descent. This process is repeated iteratively, allowing the network to learn complex representations from the input data.']},\n",
       "  {'tag': 'hg',\n",
       "   'question': ['What is the vanishing gradient problem, and how does it affect deep learning models?'],\n",
       "   'answer': ['The vanishing gradient problem occurs in deep learning when gradients become extremely small during backpropagation. This hinders the update of weights in early layers, preventing effective learning. It particularly affects deep networks with many layers. Techniques like using activation functions that mitigate vanishing gradients, such as ReLU, and using skip connections or gradient clipping, help address this issue.']},\n",
       "  {'tag': 'ig',\n",
       "   'question': ['Explain the concept of weight initialization in deep neural networks.'],\n",
       "   'answer': ['Weight initialization in deep neural networks involves setting initial weights before training. Proper initialization is crucial for preventing issues like vanishing or exploding gradients. Common methods include Xavier/Glorot initialization and He initialization, which take into account the number of input and output connections. Initializing weights appropriately helps networks converge faster and achieve better performance.']},\n",
       "  {'tag': 'jg',\n",
       "   'question': ['What are the advantages of using deep learning in feature representation?'],\n",
       "   'answer': ['Deep learning excels in feature representation by automatically learning hierarchical features from data. Features are learned at multiple levels of abstraction, allowing the model to capture complex patterns. This enables deep learning models to extract meaningful representations from raw data, making them suitable for tasks like image recognition, speech processing, and natural language understanding.']},\n",
       "  {'tag': 'kg',\n",
       "   'question': ['Discuss the purpose of dropout regularization in deep learning.'],\n",
       "   'answer': ['Dropout regularization in deep learning involves randomly deactivating a fraction of neurons during training. This prevents the network from relying too heavily on specific neurons and enhances generalization. Dropout helps reduce overfitting, improves model robustness, and encourages diverse feature learning. It acts as a form of ensemble learning, training different subnetworks on different subsets of the data.']},\n",
       "  {'tag': 'lg',\n",
       "   'question': ['How do convolutional neural networks (CNNs) contribute to image recognition tasks?'],\n",
       "   'answer': ['CNNs contribute to image recognition tasks by utilizing convolutional layers to extract hierarchical features. Convolutional operations capture local patterns like edges in early layers and progressively complex structures in deeper layers. Pooling layers reduce spatial dimensions, and fully connected layers make predictions. This architecture enables CNNs to learn spatial hierarchies and recognize patterns in images effectively.']},\n",
       "  {'tag': 'mg',\n",
       "   'question': ['Explain the significance of pooling layers in CNN architectures.'],\n",
       "   'answer': ['Pooling layers in CNN architectures serve to reduce spatial dimensions and control computational complexity. Max pooling and average pooling are common types, selecting the maximum or average value in a local region. Pooling helps retain essential features while down-sampling spatial resolutions. This makes CNNs invariant to small translations and enhances their ability to capture hierarchical patterns.']},\n",
       "  {'tag': 'ng',\n",
       "   'question': ['What is transfer learning, and how is it applied in deep learning?'],\n",
       "   'answer': ['Transfer learning involves leveraging knowledge gained from one task to improve performance on a related task. In deep learning, pre-trained models on large datasets can be fine-tuned for specific tasks with smaller datasets. Transfer learning is applied by using the knowledge learned by a model on a source task to boost the performance of the model on a target task, especially when labeled data for the target task is limited.']},\n",
       "  {'tag': 'og',\n",
       "   'question': ['Describe the architecture and applications of recurrent neural networks (RNNs).'],\n",
       "   'answer': ['RNNs have architectures that allow them to process sequential data by maintaining hidden states. This enables them to capture dependencies and patterns over time. Applications include natural language processing, time series analysis, and speech recognition. However, traditional RNNs suffer from the vanishing gradient problem. Variants like Long Short-Term Memory (LSTM) networks and Gated Recurrent Units (GRUs) address this issue.']},\n",
       "  {'tag': 'pg',\n",
       "   'question': ['How do long short-term memory (LSTM) networks address the vanishing gradient problem in RNNs?'],\n",
       "   'answer': ['LSTM networks address the vanishing gradient problem in RNNs by introducing a memory cell and gating mechanisms. The cell retains information over long sequences, and gates control the flow of information. This allows LSTMs to capture long-range dependencies in data, mitigating the vanishing gradient problem associated with traditional RNNs. LSTMs are widely used in tasks requiring modeling sequential patterns.']},\n",
       "  {'tag': 'qg',\n",
       "   'question': ['What is the attention mechanism, and how is it used in deep learning models?'],\n",
       "   'answer': [\"The attention mechanism in deep learning models focuses on specific parts of input sequences when making predictions. It assigns different weights to different elements of the input, allowing the model to pay varying levels of attention. Attention mechanisms improve the model's ability to capture context and dependencies, especially in tasks involving long sequences, machine translation, and image captioning.\"]},\n",
       "  {'tag': 'rg',\n",
       "   'question': ['Discuss the role of autoencoders in unsupervised learning and dimensionality reduction.'],\n",
       "   'answer': ['Autoencoders in unsupervised learning are neural network architectures designed for dimensionality reduction and feature learning. They consist of an encoder and a decoder, learning to represent input data in a lower-dimensional latent space. Autoencoders find applications in data denoising, anomaly detection, and feature extraction, contributing to effective unsupervised learning.']},\n",
       "  {'tag': 'sg',\n",
       "   'question': ['Explain the concept of generative adversarial networks (GANs) and their applications.'],\n",
       "   'answer': ['Generative Adversarial Networks (GANs) consist of a generator and a discriminator trained adversarially. The generator aims to produce realistic data, while the discriminator tries to distinguish between real and generated data. GANs find applications in image generation, style transfer, and data augmentation. They are instrumental in creating high-quality synthetic data for training machine learning models.']},\n",
       "  {'tag': 'tg',\n",
       "   'question': ['How does reinforcement learning integrate with deep learning in training intelligent agents?'],\n",
       "   'answer': ['Reinforcement learning integrates with deep learning in training intelligent agents by using deep neural networks to approximate the value function or policy. Deep Q Networks (DQN) and policy gradient methods are common approaches. Deep reinforcement learning excels in learning from high-dimensional input spaces, enabling agents to make complex decisions in environments with sparse rewards.']},\n",
       "  {'tag': 'ug',\n",
       "   'question': ['What are hyperparameters, and how do they impact the performance of deep learning models?'],\n",
       "   'answer': ['Hyperparameters are configuration settings that are not learned from data but impact the learning process of a model. They include learning rates, batch sizes, and architectural choices. Proper tuning of hyperparameters is crucial for achieving optimal performance in deep learning models. Techniques like grid search, random search, and automated methods help find suitable hyperparameter values.']},\n",
       "  {'tag': 'vg',\n",
       "   'question': ['Describe the challenges and solutions related to training deep neural networks.'],\n",
       "   'answer': ['Training deep neural networks poses challenges, including vanishing/exploding gradients, overfitting, and computational demands. Solutions include using proper weight initialization, activation functions, batch normalization, dropout, and advanced architectures like residual networks. Transfer learning and using pre-trained models on large datasets can also address challenges related to limited labeled data.']},\n",
       "  {'tag': 'wg',\n",
       "   'question': ['What is the role of learning rate in optimizing deep learning models?'],\n",
       "   'answer': ['The learning rate in optimizing deep learning models determines the size of steps taken during weight updates. It significantly influences training speed and convergence. A too high learning rate may cause divergence or overshooting, while a too low learning rate may lead to slow convergence. Learning rate schedules, adaptive methods, and careful tuning are essential for effective optimization of deep learning models.']},\n",
       "  {'tag': 'xg',\n",
       "   'question': ['Discuss the applications of deep learning in natural language processing (NLP).'],\n",
       "   'answer': ['Deep learning has revolutionized natural language processing (NLP) with applications such as machine translation, sentiment analysis, named entity recognition, and language modeling. Models like transformers have demonstrated state-of-the-art performance in tasks like language understanding, text generation, and question answering. Deep learning enables NLP systems to learn intricate language patterns and representations from large text corpora.']},\n",
       "  {'tag': 'yg',\n",
       "   'question': ['How are word embeddings generated in deep learning models for NLP tasks?'],\n",
       "   'answer': ['Word embeddings in deep learning models for NLP tasks are generated by representing words as dense vectors in a continuous vector space. Techniques like Word2Vec, GloVe, and embeddings from transformer models capture semantic relationships between words. These embeddings encode contextual information and are used as feature representations for words, enhancing the performance of NLP models.']},\n",
       "  {'tag': 'zg',\n",
       "   'question': ['Explain the architecture and applications of a transformer model.'],\n",
       "   'answer': ['Transformer models, introduced by Vaswani et al., use self-attention mechanisms to process input data in parallel. They have become a cornerstone in NLP and beyond. Transformers consist of an encoder and decoder, and their attention mechanism enables capturing long-range dependencies. Applications include machine translation (e.g., GPT, BERT), summarization, and various NLP tasks.']},\n",
       "  {'tag': 'ah',\n",
       "   'question': ['What challenges are associated with training deep learning models on small datasets?'],\n",
       "   'answer': [\"Training deep learning models on small datasets poses challenges due to the risk of overfitting. Deep networks may memorize limited samples, hindering generalization. Solutions include data augmentation, transfer learning, and regularization techniques. Techniques like fine-tuning pre-trained models on small datasets leverage knowledge gained from larger datasets, improving the model's ability to generalize.\"]},\n",
       "  {'tag': 'bh',\n",
       "   'question': ['Discuss the concept of batch normalization and its advantages in deep learning.'],\n",
       "   'answer': ['Batch normalization in deep learning involves normalizing inputs within mini-batches to mitigate internal covariate shift. It accelerates training by reducing internal variations and allows for higher learning rates. Batch normalization acts as a regularizer, reducing the need for other regularization techniques like dropout. It enhances the stability and convergence of deep networks, making them more effective.']},\n",
       "  {'tag': 'ch',\n",
       "   'question': ['What is the difference between shallow and deep learning architectures?'],\n",
       "   'answer': ['Shallow learning architectures typically have a small number of layers and parameters. They are less capable of automatically learning hierarchical representations. Deep learning architectures, on the other hand, have many layers, enabling them to automatically learn intricate features and representations. Deep architectures excel in tasks requiring complex pattern recognition, such as image and speech recognition.']},\n",
       "  {'tag': 'dh',\n",
       "   'question': ['How does the concept of weight sharing contribute to the efficiency of deep learning models?'],\n",
       "   'answer': ['Weight sharing in deep learning involves using the same set of weights for multiple parts of a model. This promotes parameter sharing and reduces the overall number of parameters. It is particularly beneficial in tasks where certain features or patterns should be recognized similarly across different parts of the input, contributing to more efficient learning and improved generalization.']},\n",
       "  {'tag': 'eh',\n",
       "   'question': ['Explain the role of recurrent layers in sequence-to-sequence tasks in deep learning.'],\n",
       "   'answer': [\"Recurrent layers in sequence-to-sequence tasks enable modeling sequential dependencies. They allow the network to maintain a hidden state that captures information from previous time steps, which is crucial for tasks like machine translation, where the input and output sequences have varying lengths. Recurrent layers, such as those in LSTM or GRU networks, contribute to the model's ability to understand and generate sequences.\"]},\n",
       "  {'tag': 'fh',\n",
       "   'question': ['Discuss the impact of imbalanced datasets on the training of deep learning models.'],\n",
       "   'answer': ['Imbalanced datasets can impact the training of deep learning models by leading to biased models that favor the majority class. The model may achieve high accuracy by simply predicting the majority class, while performance on the minority class suffers. This affects evaluation metrics like precision, recall, and F1 score. Techniques like class weighting, data resampling, and using appropriate evaluation metrics help address this issue.']},\n",
       "  {'tag': 'gh',\n",
       "   'question': ['What are the considerations when choosing an activation function for a deep neural network?'],\n",
       "   'answer': ['When choosing an activation function, considerations include the network architecture, vanishing/exploding gradient issues, and the type of task. Common activation functions like ReLU, sigmoid, and tanh are suitable for different scenarios. ReLU is popular for hidden layers due to its non-linearity, while sigmoid and tanh are used in output layers for binary and multi-class classification. The choice depends on the specific characteristics of the problem.']},\n",
       "  {'tag': 'hh',\n",
       "   'question': ['How do deep learning models handle different types of data, such as images, text, and time-series?'],\n",
       "   'answer': ['Deep learning models handle different types of data through specialized architectures. Convolutional Neural Networks (CNNs) are effective for image data, recurrent networks (RNNs, LSTMs) for sequential data like text or time-series, and transformer models for sequences with complex dependencies. Pre-processing techniques, feature engineering, and appropriate model architectures are adapted to the specific characteristics of each data type.']},\n",
       "  {'tag': 'ih',\n",
       "   'question': ['Explain the concept of unsupervised pre-training in deep learning.'],\n",
       "   'answer': ['Unsupervised pre-training involves training a model on an unlabeled dataset before fine-tuning on a labeled dataset. Autoencoders or generative models can learn useful representations of the data during this unsupervised phase. The pre-trained model is then fine-tuned on a task-specific dataset, leveraging the learned features. Unsupervised pre-training is particularly useful when labeled data is limited.']},\n",
       "  {'tag': 'jh',\n",
       "   'question': ['What is the role of normalization techniques in training deep neural networks?'],\n",
       "   'answer': ['Normalization techniques in deep learning, such as Batch Normalization, Layer Normalization, and Group Normalization, help stabilize and accelerate training. They address issues like internal covariate shift by normalizing activations within or across mini-batches. Normalization improves the convergence of deep networks, mitigates vanishing/exploding gradient problems, and allows for the use of higher learning rates. This contributes to more efficient and effective training.']},\n",
       "  {'tag': 'kh',\n",
       "   'question': ['Discuss the challenges and advancements in interpretability of deep learning models.'],\n",
       "   'answer': ['Challenges in interpretability of deep learning models arise from their complex architectures and black-box nature. Advancements include attention mechanisms, layer-wise relevance propagation, and model-agnostic techniques like LIME and SHAP. Despite progress, achieving full interpretability remains challenging, especially in deep neural networks with millions of parameters. Interpretable models are crucial for building trust and understanding in critical applications.']},\n",
       "  {'tag': 'lh',\n",
       "   'question': ['How do deep reinforcement learning algorithms learn from interactions with an environment?'],\n",
       "   'answer': ['Deep reinforcement learning algorithms learn from interactions with an environment through trial and error. Agents take actions in an environment, receive feedback in the form of rewards or penalties, and adjust their strategies to maximize cumulative rewards. Deep Q Networks (DQN) and policy gradient methods use deep neural networks to approximate value functions or policies, enabling agents to learn complex behaviors and decision-making strategies.']},\n",
       "  {'tag': 'mh',\n",
       "   'question': ['Explain the architecture and applications of a deep belief network (DBN).'],\n",
       "   'answer': ['A Deep Belief Network (DBN) is a generative probabilistic model composed of multiple layers of stochastic, latent variables. It consists of a stack of restricted Boltzmann machines (RBMs). DBNs can be used for tasks like feature learning, unsupervised pre-training, and generating new samples. However, they have been largely replaced by more effective models, such as autoencoders and variational autoencoders, in recent years.']},\n",
       "  {'tag': 'nh',\n",
       "   'question': ['Discuss the impact of overfitting and underfitting on the performance of deep learning models.'],\n",
       "   'answer': ['Overfitting occurs when a model performs well on the training data but poorly on new, unseen data. Underfitting, on the other hand, happens when the model fails to capture the underlying patterns in the training data. Techniques to address overfitting include dropout, regularization, and using more data. Addressing underfitting involves increasing model complexity or adjusting hyperparameters to allow better fitting to the training data.']},\n",
       "  {'tag': 'oh',\n",
       "   'question': ['What are the limitations of deep learning models in handling noisy or incomplete data?'],\n",
       "   'answer': ['Deep learning models may struggle with noisy or incomplete data due to their susceptibility to outliers and the need for large amounts of labeled data. Noisy data can mislead the learning process, and incomplete data may result in biased or inaccurate models. Pre-processing techniques, robust architectures, and strategies like data augmentation can help mitigate these limitations to some extent.']},\n",
       "  {'tag': 'ph',\n",
       "   'question': ['Explain the concept of weight tying and its applications in deep learning architectures.'],\n",
       "   'answer': ['Weight tying involves using the same set of weights in multiple parts of a model. This constraint is applied to encourage parameter sharing and reduce the overall number of parameters. Weight tying is commonly used in autoencoders and recurrent neural networks (RNNs). In autoencoders, tying the weights of the encoder and decoder helps create a more efficient and expressive representation in the latent space.']},\n",
       "  {'tag': 'qh',\n",
       "   'question': ['How are hyperparameter tuning techniques used to optimize deep learning models?'],\n",
       "   'answer': ['Hyperparameter tuning techniques optimize deep learning models by systematically searching through hyperparameter spaces. Methods include grid search, random search, and more advanced techniques like Bayesian optimization. During tuning, hyperparameters such as learning rates, batch sizes, and architecture choices are adjusted to find combinations that yield optimal model performance. Automated tools and libraries help streamline the hyperparameter tuning process.']},\n",
       "  {'tag': 'rh',\n",
       "   'question': ['Discuss the concept of curriculum learning and its role in training deep neural networks.'],\n",
       "   'answer': ['Curriculum learning involves gradually exposing a model to increasingly complex examples during training. This helps the model learn more effectively, especially when dealing with difficult tasks. In the context of deep neural networks, starting with simpler examples and progressively increasing difficulty can enhance convergence and generalization. Curriculum learning is inspired by the way humans learn and has been shown to improve learning in various tasks.']},\n",
       "  {'tag': 'sh',\n",
       "   'question': ['What is the role of pre-trained embeddings in natural language processing models?'],\n",
       "   'answer': ['Pre-trained embeddings in natural language processing (NLP) models are word representations learned from large unlabeled corpora. Word embeddings, such as Word2Vec or GloVe, capture semantic relationships between words. Pre-trained embeddings serve as effective features for downstream NLP tasks, enabling models to leverage contextual information and achieve better performance, especially when labeled data is limited.']},\n",
       "  {'tag': 'th',\n",
       "   'question': ['Explain the challenges of training deep learning models for real-time applications.'],\n",
       "   'answer': ['Training deep learning models for real-time applications faces challenges related to computational efficiency and speed. Large and complex models may require significant computational resources, making real-time processing difficult. Model optimization, quantization, and deploying lightweight architectures are strategies to address these challenges. Additionally, hardware accelerators like GPUs and TPUs play a crucial role in achieving real-time performance.']},\n",
       "  {'tag': 'uh',\n",
       "   'question': ['How does attention mechanism improve the performance of sequence-to-sequence models?'],\n",
       "   'answer': ['Attention mechanisms improve sequence-to-sequence models by allowing the model to focus on relevant parts of the input sequence when generating each element of the output sequence. This enables the model to capture long-range dependencies and align input and output sequences effectively. Attention mechanisms have greatly improved the performance of machine translation systems and other sequence-to-sequence tasks.']},\n",
       "  {'tag': 'vh',\n",
       "   'question': ['Discuss the role of deep learning in computer vision applications beyond image recognition.'],\n",
       "   'answer': ['Deep learning plays a crucial role in various computer vision applications beyond image recognition. This includes tasks like object detection, segmentation, image captioning, and video analysis. Convolutional Neural Networks (CNNs) are fundamental in these applications, allowing models to learn hierarchical features and spatial representations. Deep learning also contributes to advancements in medical imaging, autonomous vehicles, and augmented reality.']},\n",
       "  {'tag': 'wh',\n",
       "   'question': ['Explain the concept of feature extraction in the context of deep learning models.'],\n",
       "   'answer': ['Feature extraction in deep learning involves automatically learning relevant representations or features from raw data. Convolutional layers in CNNs excel at feature extraction from images, while recurrent layers capture temporal features in sequences. Transfer learning leverages pre-trained models for feature extraction. Effective feature extraction enables models to focus on important patterns, enhancing performance in various tasks, including classification and object detection.']},\n",
       "  {'tag': 'xh',\n",
       "   'question': ['What challenges are associated with deploying deep learning models in production environments?'],\n",
       "   'answer': ['Deploying deep learning models in production environments presents challenges such as managing computational resources, ensuring real-time responsiveness, handling model versioning, and dealing with security and privacy concerns. Continuous monitoring, scalability, and interpretability are crucial considerations. Deployment frameworks, containerization, and collaboration between data scientists and IT teams are essential for successful integration of deep learning models into production systems.']},\n",
       "  {'tag': 'yh',\n",
       "   'question': ['Discuss the impact of data augmentation techniques on the generalization of deep learning models.'],\n",
       "   'answer': ['Data augmentation techniques impact the generalization of deep learning models by increasing the diversity of the training dataset. Augmentations, such as rotations, flips, and changes in brightness, create variations in input data. This helps the model generalize better to unseen examples, improving robustness. Data augmentation is especially useful when labeled data is limited, contributing to better performance on tasks like image classification.']},\n",
       "  {'tag': 'zh',\n",
       "   'question': ['What is R programming language?'],\n",
       "   'answer': ['R is a programming language and open-source software used for statistical computing and graphics. It provides a wide variety of statistical and graphical techniques, and its extensibility allows users to create custom functions, packages, and visualizations. R is widely used in data analysis, statistical modeling, and data visualization.']},\n",
       "  {'tag': 'ai',\n",
       "   'question': ['How do you install packages in R?'],\n",
       "   'answer': [\"To install packages in R, you can use the install.packages() function. For example, to install the 'dplyr' package, you would run install.packages('dplyr'). This function downloads and installs the specified package from the Comprehensive R Archive Network (CRAN) or other repositories.\"]},\n",
       "  {'tag': 'bi',\n",
       "   'question': ['What is the purpose of the install.packages() function in R?'],\n",
       "   'answer': [\"The install.packages() function in R is used to install additional packages that extend R's functionality. Users can install packages from CRAN or other repositories. This function simplifies the process of acquiring and setting up packages for various tasks, such as data manipulation, visualization, or statistical analysis.\"]},\n",
       "  {'tag': 'ci',\n",
       "   'question': ['Explain the difference between a vector and a list in R.'],\n",
       "   'answer': ['In R, a vector is a one-dimensional array that can hold elements of the same data type, such as numeric, character, or logical. A list, on the other hand, is a collection of objects (which can be of different data types) arranged in a specified order. Vectors are homogeneous, while lists are heterogeneous and can contain various types of elements.']},\n",
       "  {'tag': 'di',\n",
       "   'question': ['How do you create a data frame in R?'],\n",
       "   'answer': [\"You can create a data frame in R using the data.frame() function. For example, you can create a data frame with two variables, 'Name' and 'Age', as follows: `my_df <- data.frame(Name = c('John', 'Jane'), Age = c(25, 30))`. Data frames are used to store tabular data with rows and columns.\"]},\n",
       "  {'tag': 'ei',\n",
       "   'question': ['What is the significance of the data.frame() function in R?'],\n",
       "   'answer': ['The data.frame() function in R is used to create data frames, which are fundamental data structures for handling tabular data. It organizes variables (columns) of different data types into a two-dimensional structure with rows and columns. Data frames are commonly used in statistical analyses, data manipulations, and machine learning applications.']},\n",
       "  {'tag': 'fi',\n",
       "   'question': ['How do you check for missing values in a data frame?'],\n",
       "   'answer': [\"To check for missing values in a data frame in R, you can use the is.na() function. For example, to check for missing values in a data frame 'my_data', you can use `any(is.na(my_data))`. This expression returns TRUE if there are any missing values in the data frame.\"]},\n",
       "  {'tag': 'gi',\n",
       "   'question': ['Explain the role of the summary() function in R.'],\n",
       "   'answer': ['The summary() function in R provides a summary of the contents of an object, such as a data frame. For a data frame, it gives statistical summaries of each variable, including minimum, 1st quartile, median, mean, 3rd quartile, and maximum. The summary() function is useful for a quick overview of the central tendencies and distributions of variables.']},\n",
       "  {'tag': 'hi',\n",
       "   'question': ['What is the purpose of the str() function in R?'],\n",
       "   'answer': ['The str() function in R is used to display the internal structure of an R object, providing information about the data type and the first few elements of each component. It is particularly useful for understanding the structure of complex objects like data frames, lists, or models. The output helps users inspect and understand the organization of their data.']},\n",
       "  {'tag': 'ii',\n",
       "   'question': ['How do you subset a data frame in R?'],\n",
       "   'answer': [\"You can subset a data frame in R using square brackets. For example, to select rows where the variable 'Age' is greater than 25 in a data frame 'my_data', you can use `subsetted_data <- my_data[my_data$Age > 25, ]`. This creates a new data frame containing the selected subset of rows.\"]},\n",
       "  {'tag': 'ji',\n",
       "   'question': ['Explain the concept of indexing in R.'],\n",
       "   'answer': [\"Indexing in R refers to the process of accessing elements or subsets of elements in a data structure, such as vectors, matrices, or data frames. In R, indexing starts at 1, and you can use square brackets to specify the position or conditions for selecting elements. For example, `my_vector[3]` selects the third element of 'my_vector'.\"]},\n",
       "  {'tag': 'ki',\n",
       "   'question': ['What is the difference between == and === operators in R?'],\n",
       "   'answer': [\"In R, the '==' operator is used for element-wise equality comparison. For example, `a == b` checks if each element of 'a' is equal to the corresponding element of 'b'. There is no '===' operator in R. The '==' operator is sufficient for equality comparisons. If you want to test for exact object equality, you can use the identical() function.\"]},\n",
       "  {'tag': 'li',\n",
       "   'question': ['How do you read data from a CSV file in R?'],\n",
       "   'answer': [\"To read data from a CSV file in R, you can use the read.csv() function. For example, to read a file named 'my_data.csv', you can use `my_data <- read.csv('my_data.csv')`. This function reads the data from the CSV file into a data frame, assuming that the data is in a comma-separated format.\"]},\n",
       "  {'tag': 'mi',\n",
       "   'question': ['Explain the purpose of the head() and tail() functions in R.'],\n",
       "   'answer': [\"The head() and tail() functions in R are used to view the first and last few rows of a data frame, respectively. For example, `head(my_data)` shows the first six rows of 'my_data', while `tail(my_data)` shows the last six rows. These functions are helpful for quickly inspecting the structure and contents of a data frame.\"]},\n",
       "  {'tag': 'ni',\n",
       "   'question': ['What is Python?'],\n",
       "   'answer': ['Python is a high-level, interpreted, and general-purpose programming language. It emphasizes readability and simplicity, making it suitable for beginners and experienced developers alike. Python supports multiple programming paradigms, including procedural, object-oriented, and functional programming. It has a large standard library and a thriving community, contributing to its popularity in various domains.']},\n",
       "  {'tag': 'oi',\n",
       "   'question': ['How is Python an interpreted language?'],\n",
       "   'answer': ['Python is an interpreted language, which means that its source code is executed directly by an interpreter, line by line. This differs from compiled languages, where the source code is translated into machine code before execution. In Python, the interpreter reads and executes the code on-the-fly, allowing for a more flexible and dynamic development process.']},\n",
       "  {'tag': 'pi',\n",
       "   'question': ['Explain the difference between Python 2 and Python 3.'],\n",
       "   'answer': ['Python 2 and Python 3 are two major versions of the Python programming language. Python 3 introduced backward-incompatible changes to improve language consistency and address certain design flaws. Some key differences include print statements (Python 2: print x; Python 3: print(x)), Unicode support by default in Python 3, and integer division behavior (Python 2: 5/2 = 2; Python 3: 5/2 = 2.5). Python 2 reached its end of life in 2020, and new projects are encouraged to use Python 3.']},\n",
       "  {'tag': 'qi',\n",
       "   'question': ['What are the basic data types in Python?'],\n",
       "   'answer': ['Python has several basic data types, including integers, floats (floating-point numbers), strings, booleans, and complex numbers. These data types serve as the building blocks for more complex data structures and allow Python to be versatile in handling different types of information.']},\n",
       "  {'tag': 'ri',\n",
       "   'question': ['How do you comment in Python?'],\n",
       "   'answer': ['In Python, comments are added using the hash symbol (#). Everything following the # on the same line is considered a comment and is ignored by the interpreter. For multiline comments, triple-quotes (\\'\\'\\' or \") can be used. Comments provide explanatory notes within the code and are useful for documentation and readability.']},\n",
       "  {'tag': 'si',\n",
       "   'question': ['Explain the significance of indentation in Python.'],\n",
       "   'answer': ['Indentation is crucial in Python as it indicates the grouping of statements. Unlike many other programming languages that use braces or keywords for code blocks, Python uses consistent indentation to define block structures. This ensures readability and enforces a clear and consistent coding style. Incorrect indentation can lead to syntax errors or alter the logic of the program.']},\n",
       "  {'tag': 'ti',\n",
       "   'question': ['What is PEP 8?'],\n",
       "   'answer': ['PEP 8 (Python Enhancement Proposal 8) is the style guide for Python code. It provides recommendations on how to format Python code for maximum readability and maintainability. PEP 8 covers topics such as indentation, naming conventions, whitespace usage, and more. Adhering to PEP 8 helps create consistent and easily understandable Python code, fostering collaboration and codebase maintainability.']},\n",
       "  {'tag': 'ui',\n",
       "   'question': ['What is a Python variable?'],\n",
       "   'answer': [\"A variable in Python is a symbolic name that refers to a value or an object. Variables are used to store and manage data in a program. In Python, you can assign a value to a variable using the assignment operator (=). For example, `x = 5` assigns the value 5 to the variable 'x'. Variables can represent various data types, including numbers, strings, and more.\"]},\n",
       "  {'tag': 'vi',\n",
       "   'question': ['Differentiate between a list and a tuple.'],\n",
       "   'answer': ['Both lists and tuples are ordered collections in Python, but they have some key differences. Lists are mutable, meaning you can modify their elements after creation using methods like append() or remove(). Tuples, on the other hand, are immutable, and their elements cannot be changed once defined. Tuples are generally used for fixed collections of items, while lists offer more flexibility for dynamic data.']},\n",
       "  {'tag': 'wi',\n",
       "   'question': ['How do you convert a string to an integer in Python?'],\n",
       "   'answer': [\"To convert a string to an integer in Python, you can use the int() function. For example, `my_string = '42'` and `my_integer = int(my_string)` will convert the string '42' to the integer 42. It's important to ensure that the string contains a valid integer representation to avoid a ValueError.\"]},\n",
       "  {'tag': 'xi',\n",
       "   'question': ['What are if statements used for in Python?'],\n",
       "   'answer': ['If statements in Python are used for conditional execution of code. They allow you to make decisions in your program based on whether a given condition evaluates to True or False. The syntax is typically: `if condition:` followed by an indented block of code. Optionally, you can include `elif` (else if) and `else` clauses for multiple conditions.']},\n",
       "  {'tag': 'yi',\n",
       "   'question': ['Explain the purpose of the \"else\" clause in an if statement.'],\n",
       "   'answer': [\"The 'else' clause in an if statement is executed when the preceding conditions in the if statement and any 'elif' clauses are not satisfied (evaluated to False). It provides an alternative block of code to be executed when the condition specified in the 'if' statement is not met. The 'else' clause is optional.\"]},\n",
       "  {'tag': 'zi',\n",
       "   'question': ['What is a \"for\" loop and how is it used?'],\n",
       "   'answer': [\"A 'for' loop in Python is used to iterate over a sequence (such as a list, tuple, string, or range) and execute a block of code for each item in the sequence. The general syntax is: `for variable in sequence:`, followed by an indented block of code. 'variable' takes on each value in 'sequence' during each iteration.\"]},\n",
       "  {'tag': 'aj',\n",
       "   'question': ['How do you iterate over a dictionary in Python?'],\n",
       "   'answer': [\"To iterate over a dictionary in Python, you can use a 'for' loop with the items() method. For example: `my_dict = {'a': 1, 'b': 2}` and `for key, value in my_dict.items():` will iterate over key-value pairs. You can also use keys() or values() methods to iterate over keys or values, respectively.\"]},\n",
       "  {'tag': 'bj',\n",
       "   'question': ['What is the purpose of the \"range\" function?'],\n",
       "   'answer': [\"The 'range()' function in Python generates a sequence of numbers within a specified range. It is commonly used with 'for' loops to iterate over a sequence of numbers. The general syntax is: `range(start, stop, step)`, where 'start' is the starting value, 'stop' is the exclusive end value, and 'step' is the step size between numbers.\"]},\n",
       "  {'tag': 'cj',\n",
       "   'question': ['Explain the difference between \"while\" and \"for\" loops.'],\n",
       "   'answer': [\"'While' loops and 'for' loops are both used for iteration, but they have different structures and use cases. 'For' loops are ideal when the number of iterations is known, and they iterate over a sequence (e.g., list or range). 'While' loops are more flexible and continue iterating as long as a specified condition is True. 'While' loops are suitable when the number of iterations is not known in advance.\"]},\n",
       "  {'tag': 'dj',\n",
       "   'question': ['How do you use \"break\" and \"continue\" statements?'],\n",
       "   'answer': [\"The 'break' statement in Python is used to exit a loop prematurely. When 'break' is encountered within a loop, the loop is terminated, and the program continues with the next statement after the loop. The 'continue' statement, on the other hand, skips the rest of the code inside the loop for the current iteration and proceeds to the next iteration.\"]},\n",
       "  {'tag': 'ej',\n",
       "   'question': ['What is the purpose of the \"pass\" statement in Python?'],\n",
       "   'answer': [\"The 'pass' statement in Python is a no-operation statement. It serves as a placeholder where syntactically some code is required, but no action is desired. It is often used as a placeholder during development to avoid syntax errors. The 'pass' statement has no effect on the program's behavior.\"]},\n",
       "  {'tag': 'fj',\n",
       "   'question': ['How do you define a function in Python?'],\n",
       "   'answer': [\"To define a function in Python, you use the 'def' keyword followed by the function name and parentheses containing parameters (if any). The function block is indented, and it may include a 'return' statement to specify the function's output. Here's an example: `def my_function(parameter1, parameter2):` followed by the function block.\"]},\n",
       "  {'tag': 'hj',\n",
       "   'question': ['Explain the difference between parameters and arguments.'],\n",
       "   'answer': ['In the context of a function, parameters are variables used in the function definition to represent the input values that the function expects. Arguments, on the other hand, are the actual values or expressions passed to a function when it is called. Parameters and arguments allow functions to receive and operate on different data during each invocation.']},\n",
       "  {'tag': 'ij',\n",
       "   'question': ['What is the purpose of the \"return\" statement?'],\n",
       "   'answer': [\"The 'return' statement in a Python function is used to exit the function and return a value or result to the calling code. It can be followed by an expression whose value is returned to the caller. If a 'return' statement is not present in a function, it implicitly returns 'None'. The 'return' statement also marks the end of the function's execution.\"]},\n",
       "  {'tag': 'kj',\n",
       "   'question': ['How do you call a function in Python?'],\n",
       "   'answer': [\"To call a function in Python, you use its name followed by parentheses containing the arguments (if any). For example, if you have a function named 'my_function' that takes two arguments, you would call it like this: `my_function(arg1, arg2)`. The function is executed, and any returned value can be assigned or used in the calling code.\"]},\n",
       "  {'tag': 'lj',\n",
       "   'question': ['Explain the concept of function scope.'],\n",
       "   'answer': ['Function scope in Python refers to the visibility and accessibility of variables within a function. Variables defined inside a function have local scope and are accessible only within that function. They are separate from variables defined outside the function (global scope). Parameters of a function also have local scope and are specific to that function.']},\n",
       "  {'tag': 'mj',\n",
       "   'question': ['What is a lambda function?'],\n",
       "   'answer': [\"A lambda function in Python, also known as an anonymous function, is a concise way to create small, unnamed functions. It is defined using the 'lambda' keyword, followed by parameters and an expression. Lambda functions are often used for short-term operations where a full function definition is not required. For example: `add = lambda x, y: x + y`.\"]},\n",
       "  {'tag': 'nj',\n",
       "   'question': ['How do you use default arguments in a function?'],\n",
       "   'answer': ['Default arguments in a Python function are specified in the function definition and have default values that are used when the caller does not provide a value for that parameter. You define them using the syntax `def my_function(arg1, arg2=default_value):`. When calling the function, the caller can omit the argument with a default value, and the default value will be used.']},\n",
       "  {'tag': 'oj',\n",
       "   'question': ['What is the C programming language?'],\n",
       "   'answer': ['The C programming language is a general-purpose, procedural programming language created by Dennis Ritchie in the early 1970s at Bell Labs. It is known for its efficiency, flexibility, and low-level features, making it suitable for system programming and developing various applications. C has influenced many programming languages and serves as the foundation for operating systems like Unix.']},\n",
       "  {'tag': 'pj',\n",
       "   'question': ['How does C handle command-line arguments?'],\n",
       "   'answer': [\"C handles command-line arguments through the parameters of the main() function. The main() function can take two arguments: 'int argc' (argument count) and 'char *argv[]' (argument vector). 'argc' represents the number of command-line arguments, and 'argv' is an array of strings containing the actual arguments. The first element of 'argv' (argv[0]) is the program name.\"]},\n",
       "  {'tag': 'qj',\n",
       "   'question': [\"What is the purpose of the 'exit()' function in C?\"],\n",
       "   'answer': [\"The 'exit()' function in C is used to terminate a program. It takes an integer argument that serves as the exit status. A return value of 0 conventionally indicates successful execution, while a non-zero value suggests an error or abnormal termination. 'exit()' also performs cleanup tasks, such as closing files and flushing buffers before program termination.\"]},\n",
       "  {'tag': 'rj',\n",
       "   'question': ['Describe the role of preprocessor directives in C.'],\n",
       "   'answer': [\"Preprocessor directives in C are instructions to the compiler that begin with a hash symbol (#). They are processed before the actual compilation of the code. Common directives include '#include' for including header files, '#define' for defining constants and macros, and '#ifdef' / '#ifndef' for conditional compilation. Directives provide a way to customize and configure the compilation process.\"]},\n",
       "  {'tag': 'sj',\n",
       "   'question': [\"What is the purpose of the 'sizeof' operator in C?\"],\n",
       "   'answer': [\"The 'sizeof' operator in C is used to determine the size, in bytes, of a data type or a variable. It can be applied to data types, expressions, or variables. For example, 'sizeof(int)' returns the size of an integer in bytes. 'sizeof' is commonly used in dynamic memory allocation to allocate the correct amount of memory for a variable or data structure.\"]},\n",
       "  {'tag': 'tj',\n",
       "   'question': [\"Explain the difference between 'calloc()' and 'malloc()' functions.\"],\n",
       "   'answer': [\"Both 'calloc()' and 'malloc()' functions in C are used for dynamic memory allocation. The key difference is in how they initialize the allocated memory. 'malloc()' (memory allocation) allocates a specified number of bytes of memory but does not initialize the content. 'calloc()' (contiguous allocation) allocates a specified number of blocks of memory, each of a specified size, and initializes all bits to zero.\"]},\n",
       "  {'tag': 'uj',\n",
       "   'question': [\"What is the purpose of the 'strcat()' function in C?\"],\n",
       "   'answer': [\"The 'strcat()' function in C is used to concatenate (append) one string to the end of another. It takes two null-terminated strings as arguments and appends the characters of the second string to the end of the first. The resulting string is null-terminated. It is important to ensure that the destination string has enough space to accommodate the concatenated characters.\"]},\n",
       "  {'tag': 'vj',\n",
       "   'question': [\"Describe the role of the 'strtok()' function in C.\"],\n",
       "   'answer': [\"The 'strtok()' function in C is used for tokenizing (parsing) strings. It breaks a string into a series of tokens based on a specified delimiter. 'strtok()' is typically called multiple times with the same string. The first call initializes the function with the input string, and subsequent calls with a null pointer use the saved context to continue tokenization.\"]},\n",
       "  {'tag': 'wj',\n",
       "   'question': ['How does C support multi-threading?'],\n",
       "   'answer': [\"C supports multi-threading through various libraries, with one of the most common being the POSIX threads library (pthread). The 'pthread_create()' function is used to create threads, and synchronization mechanisms like mutexes ('pthread_mutex_t') are employed for thread safety. C11 standard introduced native support for threads with functions like 'thrd_create()' and thread-related features in the 'stdatomic.h' and 'threads.h' headers.\"]},\n",
       "  {'tag': 'xj',\n",
       "   'question': [\"Explain the purpose of the 'pthread_create()' function in C.\"],\n",
       "   'answer': [\"The 'pthread_create()' function in C is used to create a new thread. It takes four arguments: a pointer to the thread identifier, thread attributes (or NULL for default attributes), a function pointer to the function that will be executed by the thread, and the argument to be passed to the thread function. The new thread runs concurrently with the calling thread.\"]},\n",
       "  {'tag': 'yj',\n",
       "   'question': [\"What is the purpose of the 'mutex' in multi-threaded programming?\"],\n",
       "   'answer': [\"A mutex (short for mutual exclusion) in multi-threaded programming is used to ensure that only one thread can access a shared resource or critical section at a time. It prevents multiple threads from interfering with each other, thereby avoiding data inconsistencies and race conditions. Common operations on a mutex include locking ('pthread_mutex_lock()') and unlocking ('pthread_mutex_unlock()').\"]},\n",
       "  {'tag': 'zj',\n",
       "   'question': ['Describe the concept of deadlock in multi-threaded programs.'],\n",
       "   'answer': ['Deadlock in multi-threaded programming occurs when two or more threads are blocked forever, each waiting for the other to release a resource. This situation can arise when threads acquire locks in a circular manner. To prevent deadlock, proper lock acquisition order should be maintained, and mechanisms like timeouts or deadlock detection algorithms can be implemented.']},\n",
       "  {'tag': 'ak',\n",
       "   'question': [\"Explain the role of the 'signal()' function in C.\"],\n",
       "   'answer': [\"The 'signal()' function in C is used to associate a signal (software interrupt) with a function, known as the signal handler. When a specific signal occurs, the associated handler function is executed. Common signals include SIGINT (interrupt from the keyboard) and SIGSEGV (segmentation fault). 'signal()' helps customize the behavior of a program in response to specific events.\"]},\n",
       "  {'tag': 'bk',\n",
       "   'question': ['What is a signal handler in C? Provide an example.'],\n",
       "   'answer': ['A signal handler in C is a function that is executed when a specific signal occurs. It is defined to handle a particular signal, and its purpose is to provide custom actions or cleanup when the associated signal is received. For example, a simple SIGINT (Ctrl+C) signal handler might be defined as follows:\\n```c\\n#include <stdio.h>\\n#include <signal.h>\\n\\nvoid sigintHandler(int signal) {\\n    printf(\"Caught SIGINT, exiting...\\\\n\");\\n    exit(0);\\n}\\n\\nint main() {\\n    signal(SIGINT, sigintHandler);\\n\\n    // Rest of the program...\\n\\n    return 0;\\n}\\n```']},\n",
       "  {'tag': 'ck',\n",
       "   'question': [\"Describe the purpose of the 'setjmp()' and 'longjmp()' functions.\"],\n",
       "   'answer': [\"The 'setjmp()' and 'longjmp()' functions in C provide a way to perform non-local jumps, allowing a program to jump to a specific point in its call stack. 'setjmp()' is used to set a jump point, and 'longjmp()' is used to perform the jump. These functions are often used for error handling in situations where exceptions are not available.\"]},\n",
       "  {'tag': 'dk',\n",
       "   'question': ['Explain the concept of memory mapping in C.'],\n",
       "   'answer': [\"Memory mapping in C involves mapping a file or a part of a file directly into memory, creating a virtual memory-mapped region. This allows the program to access the file content as if it were an array in memory. The 'mmap()' function is commonly used for memory mapping. Memory mapping is efficient for large files and can simplify file I/O operations.\"]},\n",
       "  {'tag': 'ek',\n",
       "   'question': [\"What is the purpose of the 'mmap()' function in C?\"],\n",
       "   'answer': [\"The 'mmap()' function in C is used for memory mapping, allowing a file or a part of a file to be mapped directly into memory. It takes parameters such as the file descriptor, the length to map, protection flags, and mapping options. Memory mapping provides efficient file I/O operations and simplifies data access through a virtual memory-mapped region.\"]},\n",
       "  {'tag': 'fk',\n",
       "   'question': [\"Describe the difference between 'shallow copy' and 'deep copy'.\"],\n",
       "   'answer': [\"In C, 'shallow copy' and 'deep copy' refer to copying objects, especially when dealing with complex data structures like structures or arrays containing pointers. A 'shallow copy' duplicates the object but not the data it points to, meaning both the original and copied objects share the same data. A 'deep copy' creates a new object and recursively copies all the data, ensuring distinct copies of the original data.\"]},\n",
       "  {'tag': 'ik',\n",
       "   'question': [\"Explain the role of the 'qsort()' function in C.\"],\n",
       "   'answer': [\"The 'qsort()' function in C is used for sorting an array or another contiguous memory region. It takes parameters such as the base address of the array, the number of elements, the size of each element, and a comparison function. The comparison function defines the order of elements. 'qsort()' uses the QuickSort algorithm to perform efficient sorting.\"]},\n",
       "  {'tag': 'jk',\n",
       "   'question': [\"What is the purpose of the 'atexit()' function in C?\"],\n",
       "   'answer': [\"The 'atexit()' function in C is used to register functions that are automatically called when the program exits normally. It allows the program to perform cleanup tasks, release resources, or save state before termination. Multiple functions can be registered using 'atexit()', and they are executed in the reverse order of registration.\"]},\n",
       "  {'tag': 'lk',\n",
       "   'question': ['Describe the concept of typecasting in C.'],\n",
       "   'answer': [\"Typecasting in C involves converting a variable from one data type to another. It can be explicit or implicit. Explicit typecasting is done using type conversion operators, such as '(type) expression'. Implicit typecasting, also known as type coercion, occurs automatically when a value of one type is used in a context where another type is expected.\"]},\n",
       "  {'tag': 'mk',\n",
       "   'question': [\"Explain the role of the 'const' keyword in C.\"],\n",
       "   'answer': [\"The 'const' keyword in C is used to declare constants or to specify that a variable is read-only. When applied to a variable, it indicates that the variable's value cannot be changed after initialization. When used with pointers, 'const' specifies that the data pointed to by the pointer is constant and cannot be modified.\"]},\n",
       "  {'tag': 'nk',\n",
       "   'question': ['What is a union in C? Provide an example.'],\n",
       "   'answer': ['A union in C is a composite data type that allows storing different data types in the same memory location. All members of a union share the same memory space, and the size of the union is determined by the size of its largest member. Here\\'s an example:\\n```c\\n#include <stdio.h>\\n\\nunion MyUnion {\\n    int i;\\n    float f;\\n    char str[20];\\n};\\n\\nint main() {\\n    union MyUnion u;\\n    u.i = 42;\\n    printf(\"Value of i: %d\\\\n\", u.i);\\n    u.f = 3.14;\\n    printf(\"Value of f: %f\\\\n\", u.f);\\n    // Accessing str after modifying f is undefined behavior\\n    return 0;\\n}\\n```']},\n",
       "  {'tag': 'ok',\n",
       "   'question': [\"Describe the purpose of the 'volatile' keyword in C.\"],\n",
       "   'answer': [\"The 'volatile' keyword in C is used to indicate that a variable may be changed by multiple entities outside the current code, such as hardware registers or other threads. It prevents the compiler from optimizing away reads or writes to the variable. 'volatile' is essential when dealing with variables whose values can change asynchronously to the flow of control.\"]},\n",
       "  {'tag': 'pk',\n",
       "   'question': ['Explain the concept of recursion in C with the Tower of Hanoi problem.'],\n",
       "   'answer': ['Recursion in C involves a function calling itself. The Tower of Hanoi problem is a classic example of recursion. In this problem, a set of disks of different sizes is stacked on one rod, and the task is to move the entire stack to another rod, subject to the constraint that only one disk can be moved at a time, and no disk may be placed on top of a smaller disk. The recursive solution involves moving smaller sub-stacks of disks.']},\n",
       "  {'tag': 'qk',\n",
       "   'question': ['How are command-line arguments passed to a C program?'],\n",
       "   'answer': [\"Command-line arguments are passed to a C program through the parameters of the main() function. The main function can take two arguments: 'int argc' (argument count) and 'char *argv[]' (argument vector). 'argc' represents the number of command-line arguments, and 'argv' is an array of strings containing the actual arguments. The first element of 'argv' (argv[0]) is the program name.\"]},\n",
       "  {'tag': 'rk',\n",
       "   'question': [\"What is the purpose of the 'malloc()' function in C?\"],\n",
       "   'answer': [\"The 'malloc()' function in C is used for dynamic memory allocation. It stands for 'memory allocation' and is part of the C Standard Library. 'malloc()' allocates a specified number of bytes of memory on the heap and returns a pointer to the beginning of the allocated block. It is commonly used to allocate memory for arrays and structures at runtime.\"]},\n",
       "  {'tag': 'sk',\n",
       "   'question': ['What is HTML?'],\n",
       "   'answer': ['HTML (Hypertext Markup Language) is the standard markup language used to create and design documents on the World Wide Web. It structures content on the web, defining elements such as headings, paragraphs, links, images, and other elements. HTML is essential for creating the basic structure of a web page and is often used in conjunction with CSS (Cascading Style Sheets) and JavaScript to enhance web page presentation and functionality.']},\n",
       "  {'tag': 'uk',\n",
       "   'question': ['Explain the purpose of the <!DOCTYPE html> declaration.'],\n",
       "   'answer': ['The <!DOCTYPE html> declaration in HTML5 specifies the document type and version. It is placed at the beginning of an HTML document to inform the browser that the page is written in HTML5. This declaration helps browsers render the page correctly and ensures consistency in interpretation. It also signifies that the document adheres to modern HTML standards.']},\n",
       "  {'tag': 'vk',\n",
       "   'question': ['What are semantic elements in HTML?'],\n",
       "   'answer': ['Semantic elements in HTML are tags that carry meaning about the structure and content of the document. They provide additional information to both browsers and developers, improving document clarity and accessibility. Examples of semantic elements include <article>, <section>, <nav>, <header>, <footer>, <aside>, <figure>, <figcaption>, <details>, <summary>, and <mark>.']},\n",
       "  {'tag': 'wk',\n",
       "   'question': ['How do you create a hyperlink in HTML?'],\n",
       "   'answer': ['A hyperlink in HTML is created using the <a> (anchor) element. The <a> element has an \\'href\\' attribute that specifies the URL of the linked resource. Here\\'s an example:\\n```html\\n<a href=\"https://www.example.com\">Visit Example Website</a>\\n```']},\n",
       "  {'tag': 'xk',\n",
       "   'question': ['Describe the difference between <div> and <span> elements.'],\n",
       "   'answer': ['<div> and <span> are both container elements used for grouping content, but they differ in their default display styles. <div> is a block-level element, meaning it typically starts on a new line and takes up the full width available. <span> is an inline element, meaning it typically does not start on a new line and only takes up as much width as necessary. They are often used with CSS for styling and layout purposes.']},\n",
       "  {'tag': 'yk',\n",
       "   'question': ['What is the purpose of the <meta> tag in HTML?'],\n",
       "   'answer': ['The <meta> tag in HTML is used to provide metadata about the document. Metadata includes information such as character encoding, viewport settings for responsive design, description, keywords, and more. The <meta> tag is placed inside the <head> element and does not have a closing tag. For example, setting the character encoding can be done with:\\n```html\\n<meta charset=\"UTF-8\">\\n```']},\n",
       "  {'tag': 'zk',\n",
       "   'question': ['How can you embed a video in HTML?'],\n",
       "   'answer': ['To embed a video in HTML, you can use the <video> element. The \\'src\\' attribute specifies the path to the video file, and optional attributes like \\'controls\\' add playback controls. Here\\'s an example:\\n```html\\n<video width=\"320\" height=\"240\" controls>\\n  <source src=\"movie.mp4\" type=\"video/mp4\">\\n  Your browser does not support the video tag.\\n</video>\\n```']},\n",
       "  {'tag': 'al',\n",
       "   'question': ['What is the role of the <head> element in HTML?'],\n",
       "   'answer': ['The <head> element in HTML contains meta-information about the document, such as the title, character set, linked stylesheets, scripts, and other metadata. It does not represent content visible to users but plays a crucial role in structuring and providing additional information to browsers and search engines.']},\n",
       "  {'tag': 'bl',\n",
       "   'question': ['How do you create an ordered list in HTML?'],\n",
       "   'answer': [\"An ordered list in HTML is created using the <ol> (ordered list) element. Each list item is represented by the <li> (list item) element. Here's an example:\\n```html\\n<ol>\\n  <li>First item</li>\\n  <li>Second item</li>\\n  <li>Third item</li>\\n</ol>\\n```\"]},\n",
       "  {'tag': 'cl',\n",
       "   'question': ['Explain the difference between <header> and <h1> elements.'],\n",
       "   'answer': ['The <header> element in HTML represents introductory content at the beginning of a section or page. It often contains headings, logos, navigation links, or other elements. On the other hand, the <h1> element represents the main heading of a section or document. While the <header> may contain multiple elements, including headings, <h1> specifically denotes the primary heading.']},\n",
       "  {'tag': 'dl',\n",
       "   'question': ['What is the purpose of the alt attribute in an <img> tag?'],\n",
       "   'answer': [\"The 'alt' attribute in an <img> (image) tag provides alternative text for an image. It serves multiple purposes, including accessibility for users with visual impairments (screen readers read the alt text), a placeholder if the image fails to load, and a description for search engines. It's recommended to provide meaningful and descriptive alt text for each image.\"]},\n",
       "  {'tag': 'el',\n",
       "   'question': ['How can you create a form in HTML?'],\n",
       "   'answer': ['A form in HTML is created using the <form> element. Within the <form> element, you can include various form controls like text inputs, checkboxes, radio buttons, and buttons. The \\'action\\' attribute specifies the URL where the form data should be submitted, and the \\'method\\' attribute defines the HTTP method (e.g., \\'GET\\' or \\'POST\\'). Here\\'s a simple example:\\n```html\\n<form action=\"/submit\" method=\"post\">\\n  <!-- Form controls go here -->\\n  <input type=\"text\" name=\"username\" placeholder=\"Username\">\\n  <input type=\"password\" name=\"password\" placeholder=\"Password\">\\n  <button type=\"submit\">Submit</button>\\n</form>\\n```']},\n",
       "  {'tag': 'fl',\n",
       "   'question': ['Describe the difference between <article> and <section> elements.'],\n",
       "   'answer': ['<article> and <section> are both container elements, but they are used in different contexts. The <article> element represents a self-contained piece of content that can be distributed and reused independently, such as a news article or blog post. On the other hand, the <section> element is a thematic grouping of content and is often used to organize related content within a page.']},\n",
       "  {'tag': 'gl',\n",
       "   'question': ['What is the <canvas> element used for in HTML5?'],\n",
       "   'answer': ['The <canvas> element in HTML5 is used for drawing graphics, animations, or other visual elements using JavaScript. It provides a drawing surface that can be manipulated dynamically. Developers can use JavaScript and the Canvas API to draw shapes, images, and complex graphics within the designated canvas area.']},\n",
       "  {'tag': 'hl',\n",
       "   'question': ['How do you add a comment in HTML?'],\n",
       "   'answer': ['In HTML, comments are added using the <!-- ... --> syntax. Anything placed between <!-- and --> is treated as a comment and is not displayed on the web page. Comments are useful for adding notes to the code, explanations, or temporarily excluding parts of the code from rendering.']},\n",
       "  {'tag': 'il',\n",
       "   'question': ['Explain the difference between HTML and HTML5.'],\n",
       "   'answer': ['HTML5 is the fifth revision of the HTML standard, introducing new features and improvements compared to previous versions. Some key differences include the <!DOCTYPE html> declaration being simplified, new semantic elements (e.g., <article>, <section>), native support for audio and video, the <canvas> element for graphics, and enhanced form controls. HTML5 is designed to be more efficient, accessible, and compatible with modern web development practices.']},\n",
       "  {'tag': 'kl',\n",
       "   'question': ['What is the purpose of the <nav> element in HTML?'],\n",
       "   'answer': [\"The <nav> element in HTML is used to define a section of navigation links. It typically contains links to other pages, sections, or resources within the same website. Including navigation within a <nav> element helps assistive technologies and search engines understand the structure of the page. It's semantically meaningful and aids in creating accessible web content.\"]},\n",
       "  {'tag': 'll',\n",
       "   'question': ['How do you create a table in HTML?'],\n",
       "   'answer': [\"A table in HTML is created using the <table> element. Within the <table>, you define the table rows (<tr>), table headers (<th>), and table data cells (<td>). Here's a basic example of a table with a header row, two data rows, and two columns:\\n```html\\n<table>\\n  <tr>\\n    <th>Header 1</th>\\n    <th>Header 2</th>\\n  </tr>\\n  <tr>\\n    <td>Data 1,1</td>\\n    <td>Data 1,2</td>\\n  </tr>\\n  <tr>\\n    <td>Data 2,1</td>\\n    <td>Data 2,2</td>\\n  </tr>\\n</table>\\n```\"]},\n",
       "  {'tag': 'ml',\n",
       "   'question': ['Describe the role of the <footer> element in HTML.'],\n",
       "   'answer': ['The <footer> element in HTML is used to define the footer of a section or page. It typically contains metadata, copyright information, contact details, or links to related resources. The content within the <footer> is considered supplementary information about the section it belongs to. It helps structure the document and provides additional context to users.']},\n",
       "  {'tag': 'nl',\n",
       "   'question': ['What is the purpose of the <aside> element in HTML?'],\n",
       "   'answer': ['The <aside> element in HTML is used to define content that is tangentially related to the content around it. It is often used for sidebars, pull quotes, or advertisements. The content within <aside> should be related to the content of the page but can be considered separate from the main content flow. It helps structure the page and provides additional information.']},\n",
       "  {'tag': 'ol',\n",
       "   'question': ['How do you create a radio button in HTML?'],\n",
       "   'answer': ['A radio button in HTML is created using the <input> element with a \\'type\\' attribute set to \\'radio\\'. Each radio button should have a unique \\'name\\' attribute to group them. Here\\'s an example:\\n```html\\n<form>\\n  <input type=\"radio\" name=\"gender\" value=\"male\"> Male<br>\\n  <input type=\"radio\" name=\"gender\" value=\"female\"> Female<br>\\n  <input type=\"radio\" name=\"gender\" value=\"other\"> Other\\n</form>\\n```']},\n",
       "  {'tag': 'pl',\n",
       "   'question': ['Explain the use of the <details> and <summary> elements in HTML5.'],\n",
       "   'answer': [\"The <details> and <summary> elements in HTML5 are used to create a disclosure widget that can show or hide additional information. The <details> element acts as a container for the content, and the <summary> element provides a summary or label for the content. Users can click the summary to toggle the visibility of the details. It's useful for creating collapsible sections on a webpage.\"]},\n",
       "  {'tag': 'ql',\n",
       "   'question': ['What is the purpose of the download attribute in an <a> tag?'],\n",
       "   'answer': [\"The 'download' attribute in an <a> (anchor) tag is used to prompt the user to download the linked resource rather than navigating to it. When used, the browser will suggest a filename for the downloaded file, and clicking the link initiates the download process. This attribute is commonly used with links to downloadable files like PDFs, images, or documents.\"]},\n",
       "  {'tag': 'abc',\n",
       "   'question': ['What is the role of quantum parallelism in solving combinatorial optimization problems?'],\n",
       "   'answer': ['Quantum parallelism in combinatorial optimization tackles problems efficiently by exploring multiple options.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'bbc',\n",
       "   'question': ['How does quantum computing impact the field of materials science and discovery?'],\n",
       "   'answer': ['Quantum computing in materials science accelerates the discovery of new materials and properties.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'cbc',\n",
       "   'question': ['What are the potential environmental implications of large-scale quantum computing facilities?'],\n",
       "   'answer': ['Environmental implications of large-scale quantum computing facilities involve energy consumption and resource use.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'dbc',\n",
       "   'question': ['How does quantum error correction contribute to the stability of quantum computations?'],\n",
       "   'answer': ['Quantum error correction maintains the stability of quantum computations against errors and decoherence.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ebc',\n",
       "   'question': ['Can you provide examples of quantum algorithms used in the field of image processing?'],\n",
       "   'answer': ['Quantum algorithms in image processing solve problems like pattern recognition and image classification.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'fbc',\n",
       "   'question': ['Explain the role of quantum tunneling in the context of quantum algorithms for molecular simulation.'],\n",
       "   'answer': ['Quantum tunneling in molecular simulation algorithms aids in efficiently exploring energy landscapes.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'gbc',\n",
       "   'question': ['What are some ethical considerations in the development and use of quantum computing technology?'],\n",
       "   'answer': ['Ethical considerations in quantum computing include privacy, security, and the potential for misuse.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'hbc',\n",
       "   'question': ['How does quantum computing impact the field of logistics and supply chain optimization?'],\n",
       "   'answer': ['Quantum computing impacts logistics by optimizing supply chains, routing, and resource allocation.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ibc',\n",
       "   'question': ['What challenges does the uncertainty principle pose for the practical implementation of quantum algorithms?'],\n",
       "   'answer': ['The uncertainty principle poses challenges for the precise measurement and manipulation of quantum states.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'jbc',\n",
       "   'question': ['How does quantum computing address the issue of intractability in certain mathematical problems?'],\n",
       "   'answer': ['Quantum computing addresses intractability in mathematical problems like factorization and optimization.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'kbc',\n",
       "   'question': ['Explain the concept of quantum parallelism in the context of pattern recognition algorithms.'],\n",
       "   'answer': ['Quantum parallelism in pattern recognition algorithms explores multiple possibilities concurrently.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'lbc',\n",
       "   'question': ['What is the role of quantum error correction in maintaining the coherence of quantum states?'],\n",
       "   'answer': ['Quantum error correction maintains quantum coherence, crucial for reliable quantum computations.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'mbc',\n",
       "   'question': ['How does quantum computing impact the field of energy optimization and resource management?'],\n",
       "   'answer': ['Quantum computing optimizes energy usage and resource management through efficient algorithms.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'nbc',\n",
       "   'question': ['Can you provide examples of quantum algorithms used in the optimization of manufacturing processes?'],\n",
       "   'answer': ['Quantum algorithms optimize manufacturing processes by solving complex scheduling and logistics problems.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'obc',\n",
       "   'question': ['What is the significance of quantum teleportation for the field of distributed quantum computing?'],\n",
       "   'answer': ['Quantum teleportation in distributed quantum computing facilitates secure quantum information exchange.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'pbc',\n",
       "   'question': ['How does quantum tunneling contribute to the efficiency of quantum algorithms for optimization?'],\n",
       "   'answer': ['Quantum tunneling in optimization algorithms efficiently explores solution spaces for optimal results.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'qbc',\n",
       "   'question': ['Explain the role of quantum parallelism in solving problems related to artificial intelligence and machine learning.'],\n",
       "   'answer': ['Quantum parallelism in AI and machine learning addresses complex problems by exploring multiple solutions.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'rbc',\n",
       "   'question': ['What are the potential economic impacts of quantum computing on various industries?'],\n",
       "   'answer': ['Economic impacts of quantum computing include advancements in technology, new industries, and job creation.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'sbc',\n",
       "   'question': ['How does quantum error correction contribute to the development of fault-tolerant quantum computers?'],\n",
       "   'answer': ['Quantum error correction ensures fault-tolerant quantum computers, critical for practical use.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'tbc',\n",
       "   'question': ['Can you describe the role of quantum tunneling in the context of quantum algorithms for graph theory problems?'],\n",
       "   'answer': ['Quantum tunneling in graph theory algorithms enhances the efficiency of quantum solutions.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ubc',\n",
       "   'question': ['What are the potential applications of quantum computing in the field of climate modeling and environmental simulations?'],\n",
       "   'answer': ['Applications of quantum computing in climate modeling and environmental simulations improve accuracy and efficiency.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'vbc',\n",
       "   'question': ['How does quantum computing impact the field of cryptography beyond quantum key distribution?'],\n",
       "   'answer': [\"Quantum computing's impact on cryptography extends beyond key distribution, necessitating quantum-resistant methods.\"],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'wbc',\n",
       "   'question': ['Explain the role of quantum parallelism in addressing complex problems in computational biology.'],\n",
       "   'answer': ['Quantum parallelism in computational biology addresses complex problems in genomics and protein folding.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'xbc',\n",
       "   'question': ['What challenges does quantum decoherence pose for the reliability of quantum computations?'],\n",
       "   'answer': ['Quantum decoherence poses challenges for stable quantum computations, requiring effective error correction.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ybc',\n",
       "   'question': ['Can you provide examples of quantum algorithms used in the optimization of communication networks?'],\n",
       "   'answer': ['Quantum tunneling in graph theory algorithms enhances the efficiency of quantum solutions.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'zbc',\n",
       "   'question': ['How does quantum computing impact the field of artificial general intelligence (AGI) research?'],\n",
       "   'answer': ['Quantum computing impacts AGI research by potentially solving complex problems and accelerating learning algorithms.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'aca',\n",
       "   'question': ['What is software engineering?'],\n",
       "   'answer': ['Software Engineering: The systematic application of engineering principles to software design, development, testing, and maintenance.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'bca',\n",
       "   'question': ['Explain the software development life cycle (SDLC).'],\n",
       "   'answer': ['SDLC (Software Development Life Cycle): A process comprising stages like planning, requirements, design, implementation, testing, deployment, and maintenance.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'cca',\n",
       "   'question': ['What is the difference between software engineering and computer science?'],\n",
       "   'answer': ['Difference between Software Engineering and Computer Science: Computer Science focuses on theory, algorithms, and data structures, while Software Engineering is concerned with systematic software design and development.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'dca',\n",
       "   'question': ['Describe the concept of software prototyping and its benefits.'],\n",
       "   'answer': ['Software Prototyping: Creating a preliminary model to gather feedback and validate requirements.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'eca',\n",
       "   'question': ['How do you address software security concerns during development?'],\n",
       "   'answer': ['Addressing Software Security Concerns: Employing secure coding practices, encryption, and regular security assessments.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'fca',\n",
       "   'question': ['Explain the role of user interface (UI) design in software development.'],\n",
       "   'answer': ['Role of User Interface (UI) Design: Creating an intuitive and user-friendly interface.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'gca',\n",
       "   'question': ['Explain the concept of gene therapy.'],\n",
       "   'answer': [\"Gene therapy aims to treat or prevent diseases by altering patients' genes.\"],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'hca',\n",
       "   'question': ['Describe the applications of nanotechnology in biotechnology.'],\n",
       "   'answer': ['CRISPR technology is a more precise and efficient gene-editing tool compared to traditional methods.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'ica',\n",
       "   'question': ['Describe the use of biotechnology in the conservation of endangered species.'],\n",
       "   'answer': ['It aids in the preservation and recovery of endangered species through genetic conservation.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'jca',\n",
       "   'question': ['What are the challenges of scaling up biotechnological processes for industrial production?'],\n",
       "   'answer': ['Scaling up biotechnological processes faces challenges in efficiency, cost, and scalability.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'kca',\n",
       "   'question': ['Describe the role of biotechnology in the development of sustainable packaging.'],\n",
       "   'answer': ['Sustainable packaging is developed using bio-based materials for reduced environmental impact.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'lca',\n",
       "   'question': ['Describe the applications of biotechnology in the field of bioinformatics.'],\n",
       "   'answer': ['Bioinformatics applies computational tools to analyze biological data for various biotechnological applications.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'mca',\n",
       "   'question': ['What does SQL stand for?'],\n",
       "   'answer': ['SQL stands for Structured Query Language.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'nca',\n",
       "   'question': ['Name a few popular relational database management systems (RDBMS).'],\n",
       "   'answer': ['Popular RDBMS include MySQL, PostgreSQL, Oracle, and Microsoft SQL Server.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'oca',\n",
       "   'question': ['Differentiate between SQL and MySQL.'],\n",
       "   'answer': ['SQL is a language, while MySQL is an open-source RDBMS.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'pca',\n",
       "   'question': ['What are primary keys and foreign keys?'],\n",
       "   'answer': ['Primary keys uniquely identify records in a table, while foreign keys establish relationships between tables.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'qca',\n",
       "   'question': ['How can you add a new record to a table in SQL?'],\n",
       "   'answer': ['INSERT INTO table_name VALUES (value1, value2, ...); adds a new record to a table.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'rca',\n",
       "   'question': ['What is an INNER JOIN, and how does it differ from an OUTER JOIN?'],\n",
       "   'answer': ['INNER JOIN returns only matching rows, while OUTER JOIN returns all rows from both tables.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'sca',\n",
       "   'question': ['How can you prevent SQL injection in your queries?'],\n",
       "   'answer': ['Prevent SQL injection by using parameterized queries or prepared statements.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'tca',\n",
       "   'question': ['How do you retrieve the number of rows in a table?'],\n",
       "   'answer': ['Use SELECT COUNT(*) FROM table_name; to retrieve the number of rows in a table.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'uca',\n",
       "   'question': ['What is the purpose of the CAST() function in SQL?'],\n",
       "   'answer': ['CAST() converts data types in SQL, ensuring compatibility.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'vca',\n",
       "   'question': ['What is the purpose of the CROSS APPLY and OUTER APPLY operators in SQL Server?'],\n",
       "   'answer': ['CROSS APPLY and OUTER APPLY are used in SQL Server to invoke table-valued functions for each row.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'wca',\n",
       "   'question': ['Explain the purpose of a priority queue.'],\n",
       "   'answer': ['Disjoint-set data structure efficiently tracks a partition of a set into disjoint subsets.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'xca',\n",
       "   'question': ['What is the difference between best-case, worst-case, and average-case time complexity?'],\n",
       "   'answer': ['Bubble sort repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'yca',\n",
       "   'question': ['Explain the significance of logarithmic time complexity.'],\n",
       "   'answer': ['Quicksort is a sorting algorithm that partitions elements and recursively sorts sub-arrays.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'zca',\n",
       "   'question': ['Describe the bubble sort algorithm.'],\n",
       "   'answer': ['Merge sort recursively divides, sorts, and merges sub-arrays.'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'abcd',\n",
       "   'question': ['hi',\n",
       "    'is anyone there',\n",
       "    'hello',\n",
       "    'whats up',\n",
       "    'hey',\n",
       "    'yo',\n",
       "    'listen',\n",
       "    'please help me',\n",
       "    'i am learner from'],\n",
       "   'answer': ['Hello! how can i help you ?'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'abcde',\n",
       "   'question': ['thank you',\n",
       "    'thanks',\n",
       "    'cya',\n",
       "    'see you',\n",
       "    'later',\n",
       "    'see you later',\n",
       "    'goodbye',\n",
       "    'i am leaving',\n",
       "    'have a Good day',\n",
       "    'you helped me',\n",
       "    'thanks a lot',\n",
       "    'thanks a ton',\n",
       "    'you are the best',\n",
       "    'great help',\n",
       "    'too good',\n",
       "    'you are a good learning buddy'],\n",
       "   'answer': ['I hope I was able to assist you, Good Bye'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'abcdef',\n",
       "   'question': ['what the hell',\n",
       "    'bloody stupid bot',\n",
       "    'do you think you are very smart',\n",
       "    'screw you',\n",
       "    'i hate you',\n",
       "    'you are stupid',\n",
       "    'jerk',\n",
       "    'you are a joke',\n",
       "    'useless piece of shit'],\n",
       "   'answer': ['Please use respectful words'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'zcab',\n",
       "   'question': ['How are you ?'],\n",
       "   'answer': [\"i'm fine thank you!\"],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'zcad',\n",
       "   'question': ['Good Morning'],\n",
       "   'answer': [' Good morning! How can I assist you today?'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'zcaf',\n",
       "   'question': ['Good Afternoon'],\n",
       "   'answer': [' Good Afternoon! How can I assist you today?'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'zcag',\n",
       "   'question': ['Good Evening'],\n",
       "   'answer': [' Good Evening! How can I assist you today?'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'zcah',\n",
       "   'question': ['Good Night'],\n",
       "   'answer': ['Good night! If you have any more questions, feel free to ask!'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'zcai',\n",
       "   'question': ['where is my order?'],\n",
       "   'answer': ['please provide our order no and product name!'],\n",
       "   'context_set': ''}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e643fc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# createing interface\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import Entry, Button, PhotoImage\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "import threading\n",
    "\n",
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load pre-trained language model (GPT-2)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load or collect data for training/fine-tuning (replace with your actual data loading)\n",
    "with open('C:/Users/VAMSI/OneDrive/Desktop/chatbot.h5/tech.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "class ChatbotApp:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(f\"NLPAssistant\")\n",
    "        self.root.geometry('800x600')\n",
    "        self.root.resizable(False, False)\n",
    "        self.message = tk.StringVar()\n",
    "\n",
    "        self.textcon = tk.Text(self.root, bd=1, bg='white', width=50, height=8)\n",
    "        self.textcon.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        self.mes_win = Entry(self.root, width=30, xscrollcommand=True, textvariable=self.message)\n",
    "        self.mes_win.place(x=1, y=540, height=60, width=579)\n",
    "        self.mes_win.focus()\n",
    "\n",
    "        self.textcon.config(fg='black')\n",
    "        self.textcon.tag_config('usr', foreground='black')\n",
    "        self.textcon.insert(tk.END, \"NLPAssistant : This is Friday! Your Assistant.\\n\\n\")\n",
    "\n",
    "        self.exit_list = ['goodbye', 'bye', 'off']\n",
    "\n",
    "        self.button_send = Button(self.root, text='Send', bg='dark green', activebackground='grey',\n",
    "                                  command=self.send_msz, width=12, height=5, font=('Arial'))\n",
    "        self.button_send.place(x=690, y=540, height=60, width=110)\n",
    "\n",
    "        mic_image_path = \"mic.png\"\n",
    "        if os.path.exists(mic_image_path):\n",
    "            self.mic_image = PhotoImage(file=mic_image_path).subsample(2, 3)\n",
    "        else:\n",
    "            print(f\"Error: Mic image not found at {mic_image_path}\")\n",
    "            self.mic_image = None\n",
    "\n",
    "        self.root.bind('<Return>', self.send_msz)\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def send_msz(self, event=None):\n",
    "        usr_input = self.message.get()\n",
    "        usr_input = usr_input.lower()\n",
    "        self.textcon.insert(tk.END, f'You : {usr_input}' + '\\n', 'usr')\n",
    "\n",
    "        if usr_input.lower() == \"end \":\n",
    "            self.textcon.config(fg='black')\n",
    "            self.textcon.insert(tk.END, \"NLPAssistant : Thank You sir, I hope I assisted you properly \\n\")\n",
    "            return self.root.destroy()\n",
    "\n",
    "        else:\n",
    "            self.textcon.config(fg='black')\n",
    "            response = self.handle_user_input(usr_input)\n",
    "            self.textcon.insert(tk.END, f\"NLPAssistant: {response}\\n\")\n",
    "            self.mes_win.delete(0, tk.END)\n",
    "\n",
    "    def activate_mic_and_send(self):\n",
    "        self.activate_mic()\n",
    "        self.send_msz()\n",
    "\n",
    "    def activate_mic(self):\n",
    "        # Replace this with your logic for activating the microphone\n",
    "        engine = pyttsx3.init()\n",
    "        rate = engine.getProperty('rate')\n",
    "        engine.setProperty('rate', 170)\n",
    "        voices = engine.getProperty('voices')\n",
    "        engine.setProperty('voice', voices[1].id)\n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            r.energy_threshold = 400\n",
    "            r.adjust_for_ambient_noise(source, 1.2)\n",
    "            print(\"Listening to You sir : \")\n",
    "            audio = r.listen(source)\n",
    "            text = r.recognize_google(audio)\n",
    "            print(\"You Told : \"+text)\n",
    "\n",
    "            # Handle the user input (speech-to-text)\n",
    "            response = self.handle_user_input(text)\n",
    "            self.textcon.insert(tk.END, f\"NLPAssistant: {response}\\n\")\n",
    "\n",
    "    def handle_user_input(self, user_input):\n",
    "        user_keywords = self.extract_keywords(user_input)\n",
    "\n",
    "        for example in data[\"intents\"]:\n",
    "            if \"question\" in example:\n",
    "                question_keywords = [keyword for q in example[\"question\"] for keyword in self.extract_keywords(q)]\n",
    "\n",
    "                if all(keyword in question_keywords for keyword in user_keywords):\n",
    "                    answer = example.get(\"answer\", [])\n",
    "                    return f\"Answer from JSON file: {answer}\"\n",
    "\n",
    "        input_ids = tokenizer.encode(user_input, return_tensors=\"tf\")\n",
    "        output = gpt_model.generate(input_ids, max_length=150, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95,\n",
    "                                    temperature=0.7)\n",
    "        bot_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        # Adjust the response based on the user's technical ability\n",
    "        technical_ability = \"tech\"  # You need to get this value from somewhere\n",
    "        if technical_ability == \"tech\":\n",
    "            # Customize response for technical users\n",
    "            pass\n",
    "        else:\n",
    "            # Customize response for non-technical users\n",
    "            pass\n",
    "\n",
    "        candidate_answers = [\"Your first answer\", \"Your second answer\", \"Your third answer\"]\n",
    "        relevancy_scores = self.score_relevancy(user_input, candidate_answers)\n",
    "\n",
    "        # Store or update relevancy scores for future learning\n",
    "        # Update your model based on user feedback and learning algorithm\n",
    "\n",
    "        return bot_response\n",
    "\n",
    "    def extract_keywords(self, text):\n",
    "        doc = nlp(text)\n",
    "        return [token.text.lower() for token in doc if token.is_alpha]\n",
    "\n",
    "    def score_relevancy(self, user_input, candidate_answers):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([user_input] + candidate_answers)\n",
    "        similarity_matrix = cosine_similarity(vectors)\n",
    "        relevancy_scores = similarity_matrix[0][1:]\n",
    "        return relevancy_scores\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot_app = ChatbotApp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5976d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# creating interface with mic not respond the mic\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import Entry, Button, PhotoImage\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import json\n",
    "import threading\n",
    "\n",
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load pre-trained language model (GPT-2)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load or collect data for training/fine-tuning (replace with your actual data loading)\n",
    "with open('C:/Users/VAMSI/OneDrive/Desktop/chatbot.h5/tech.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "class ChatbotApp:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(f\"NLPAssistant\")\n",
    "        self.root.geometry('1000x800')  # Increased dimensions\n",
    "        self.root.resizable(False, False)\n",
    "        self.message = tk.StringVar()\n",
    "\n",
    "        self.textcon = tk.Text(self.root, bd=1, bg='white', width=70, height=15)  # Adjusted dimensions\n",
    "        self.textcon.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        self.mes_win = Entry(self.root, width=50, xscrollcommand=True, textvariable=self.message)\n",
    "        self.mes_win.place(x=1, y=720, height=60, width=679)  # Adjusted dimensions\n",
    "        self.mes_win.focus()\n",
    "\n",
    "        self.textcon.config(fg='black')\n",
    "        self.textcon.tag_config('usr', foreground='black')\n",
    "        self.textcon.insert(tk.END, \"NLPAssistant : This is Friday! Your Assistant.\\n\\n\")\n",
    "\n",
    "        self.exit_list = ['goodbye', 'bye', 'off']\n",
    "\n",
    "        mic_image_path = \"mic.png\"\n",
    "        if os.path.exists(mic_image_path):\n",
    "            self.mic_image = PhotoImage(file=mic_image_path).subsample(2, 3)\n",
    "        else:\n",
    "            print(f\"Error: Mic image not found at {mic_image_path}\")\n",
    "            self.mic_image = None\n",
    "\n",
    "        self.mic_button = Button(self.root, text='Mic', bg='blue', activebackground='white',\n",
    "                                 command=self.activate_mic, width=12, height=2, font=('Arial'))\n",
    "        self.mic_button.place(x=800, y=720, height=60, width=110)  # Adjusted dimensions\n",
    "\n",
    "        self.send_button = Button(self.root, text='Send', bg='dark green', activebackground='grey',\n",
    "                                   command=self.send_msz, width=12, height=2, font=('Arial'))\n",
    "        self.send_button.place(x=680, y=720, height=60, width=110)  # Adjusted dimensions\n",
    "\n",
    "        self.root.bind('<Return>', self.send_msz)\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def send_msz(self, event=None):\n",
    "        usr_input = self.message.get()\n",
    "        usr_input = usr_input.lower()\n",
    "        self.textcon.insert(tk.END, f'You : {usr_input}' + '\\n', 'usr')\n",
    "\n",
    "        if usr_input.lower() in [\"goodbye\", \"bye\"]:\n",
    "            self.textcon.config(fg='black')\n",
    "            self.textcon.insert(tk.END, \"NLPAssistant : Thank You sir, I hope I assisted you properly \\n\")\n",
    "            return self.root.destroy()\n",
    "\n",
    "        else:\n",
    "            self.textcon.config(fg='black')\n",
    "            response = self.handle_user_input(usr_input)\n",
    "            self.textcon.insert(tk.END, f\"NLPAssistant: {response}\\n\")\n",
    "            self.mes_win.delete(0, tk.END)\n",
    "\n",
    "    def activate_mic(self):\n",
    "        if self.mic_image:\n",
    "            self.mic_button.config(image=self.mic_image)\n",
    "        else:\n",
    "            self.mic_button.config(text=\"Mic\")\n",
    "\n",
    "        # Replace this with your logic for activating the microphone\n",
    "        engine = pyttsx3.init()\n",
    "        rate = engine.getProperty('rate')\n",
    "        engine.setProperty('rate', 170)\n",
    "        voices = engine.getProperty('voices')\n",
    "        engine.setProperty('voice', voices[1].id)\n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            r.energy_threshold = 400\n",
    "            r.adjust_for_ambient_noise(source, 1.2)\n",
    "            self.textcon.insert(tk.END, \"NLPAssistant: Listening... \\n\")  # Display listening message in textcon\n",
    "            audio = r.listen(source)\n",
    "            text = r.recognize_google(audio)\n",
    "            self.textcon.insert(tk.END, f\"You : {text}\\n\", 'usr')  # Display user's input in textcon\n",
    "\n",
    "            # Handle the user input (speech-to-text)\n",
    "            response = self.handle_user_input(text)\n",
    "            self.textcon.insert(tk.END, f\"NLPAssistant: {response}\\n\")\n",
    "\n",
    "    def handle_user_input(self, user_input):\n",
    "        user_keywords = self.extract_keywords(user_input)\n",
    "\n",
    "        for example in data[\"intents\"]:\n",
    "            if \"question\" in example:\n",
    "                question_keywords = [keyword for q in example[\"question\"] for keyword in self.extract_keywords(q)]\n",
    "\n",
    "                if all(keyword in question_keywords for keyword in user_keywords):\n",
    "                    answer = example.get(\"answer\", [])\n",
    "                    return f\"Answer from JSON file: {answer}\"\n",
    "\n",
    "        input_ids = tokenizer.encode(user_input, return_tensors=\"tf\")\n",
    "        output = gpt_model.generate(input_ids, max_length=150, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95,\n",
    "                                    temperature=0.7)\n",
    "        bot_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        # Adjust the response based on the user's technical ability\n",
    "        technical_ability = \"tech\"  # You need to get this value from somewhere\n",
    "        if technical_ability == \"tech\":\n",
    "            # Customize response for technical users\n",
    "            pass\n",
    "        else:\n",
    "            # Customize response for non-technical users\n",
    "            pass\n",
    "\n",
    "        candidate_answers = [\"Your first answer\", \"Your second answer\", \"Your third answer\"]\n",
    "        relevancy_scores = self.score_relevancy(user_input, candidate_answers)\n",
    "\n",
    "        # Store or update relevancy scores for future learning\n",
    "        # Update your model based on user feedback and learning algorithm\n",
    "\n",
    "        return bot_response\n",
    "\n",
    "    def extract_keywords(self, text):\n",
    "        doc = nlp(text)\n",
    "        return [token.text.lower() for token in doc if token.is_alpha]\n",
    "\n",
    "    def score_relevancy(self, user_input, candidate_answers):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([user_input] + candidate_answers)\n",
    "        similarity_matrix = cosine_similarity(vectors)\n",
    "        relevancy_scores = similarity_matrix[0][1:]\n",
    "        return relevancy_scores\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot_app = ChatbotApp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9099c897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_11228\\3750290513.py\", line 104, in activate_mic\n",
      "    text = r.recognize_google(audio)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\recognizers\\google.py\", line 251, in recognize_legacy\n",
      "    return output_parser.parse(response_text)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\recognizers\\google.py\", line 124, in parse\n",
      "    actual_result = self.convert_to_result(response_text)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\recognizers\\google.py\", line 173, in convert_to_result\n",
      "    raise UnknownValueError()\n",
      "speech_recognition.exceptions.UnknownValueError\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_11228\\3750290513.py\", line 83, in send_msz\n",
      "    if self.input_source == 'mic':\n",
      "AttributeError: 'ChatbotApp' object has no attribute 'input_source'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_11228\\3750290513.py\", line 104, in activate_mic\n",
      "    text = r.recognize_google(audio)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\recognizers\\google.py\", line 251, in recognize_legacy\n",
      "    return output_parser.parse(response_text)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\recognizers\\google.py\", line 124, in parse\n",
      "    actual_result = self.convert_to_result(response_text)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\recognizers\\google.py\", line 173, in convert_to_result\n",
      "    raise UnknownValueError()\n",
      "speech_recognition.exceptions.UnknownValueError\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_11228\\3750290513.py\", line 104, in activate_mic\n",
      "    text = r.recognize_google(audio)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\recognizers\\google.py\", line 251, in recognize_legacy\n",
      "    return output_parser.parse(response_text)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\recognizers\\google.py\", line 124, in parse\n",
      "    actual_result = self.convert_to_result(response_text)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\recognizers\\google.py\", line 173, in convert_to_result\n",
      "    raise UnknownValueError()\n",
      "speech_recognition.exceptions.UnknownValueError\n"
     ]
    }
   ],
   "source": [
    "#working code 1 \n",
    "import tkinter as tk\n",
    "from tkinter import Entry, Button, PhotoImage\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import json\n",
    "import threading\n",
    "import webbrowser\n",
    "\n",
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load pre-trained language model (GPT-2)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load or collect data for training/fine-tuning (replace with your actual data loading)\n",
    "with open('C:/Users/VAMSI/OneDrive/Desktop/chatbot.h5/tech.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "class ChatbotApp:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(f\"NLPAssistant\")\n",
    "        self.root.geometry('1000x800')  # Increased dimensions\n",
    "        self.root.resizable(False, False)\n",
    "        self.message = tk.StringVar()\n",
    "\n",
    "        self.textcon = tk.Text(self.root, bd=1, bg='white', width=70, height=15)  # Adjusted dimensions\n",
    "        self.textcon.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        self.mes_win = Entry(self.root, width=50, xscrollcommand=True, textvariable=self.message)\n",
    "        self.mes_win.place(x=1, y=720, height=60, width=679)  # Adjusted dimensions\n",
    "        self.mes_win.focus()\n",
    "\n",
    "        self.textcon.config(fg='black')\n",
    "        self.textcon.tag_config('usr', foreground='black')\n",
    "        self.textcon.insert(tk.END, \"NLPAssistant : This is Friday! Your Assistant.\\n\\n\")\n",
    "\n",
    "        self.exit_list = ['goodbye', 'bye', 'off']\n",
    "\n",
    "        mic_image_path = \"mic.png\"\n",
    "        if os.path.exists(mic_image_path):\n",
    "            self.mic_image = PhotoImage(file=mic_image_path).subsample(2, 3)\n",
    "        else:\n",
    "            print(f\"Error: Mic image not found at {mic_image_path}\")\n",
    "            self.mic_image = None\n",
    "\n",
    "        self.mic_button = Button(self.root, text='Mic', bg='blue', activebackground='white',\n",
    "                                 command=self.activate_mic, width=12, height=2, font=('Arial'))\n",
    "        self.mic_button.place(x=800, y=720, height=60, width=110)  # Adjusted dimensions\n",
    "\n",
    "        self.send_button = Button(self.root, text='Send', bg='dark green', activebackground='grey',\n",
    "                                   command=self.send_msz, width=12, height=2, font=('Arial'))\n",
    "        self.send_button.place(x=680, y=720, height=60, width=110)  # Adjusted dimensions\n",
    "\n",
    "        self.root.bind('<Return>', self.send_msz)\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def send_msz(self, event=None):\n",
    "        usr_input = self.message.get()\n",
    "        usr_input = usr_input.lower()\n",
    "        self.textcon.insert(tk.END, f'You : {usr_input}' + '\\n', 'usr')\n",
    "\n",
    "        if usr_input.lower() in [\"goodbye\", \"bye\"]:\n",
    "            self.textcon.config(fg='black')\n",
    "            response = \"Thank You sir, I hope I assisted you properly\"\n",
    "            self.textcon.insert(tk.END, f\"NLPAssistant : {response}\\n\")\n",
    "            self.speak(response)\n",
    "            return self.root.destroy()\n",
    "\n",
    "        else:\n",
    "            self.textcon.config(fg='black')\n",
    "            response = self.handle_user_input(usr_input)\n",
    "            self.textcon.insert(tk.END, f\"NLPAssistant: {response}\\n\")\n",
    "            # Speak only if the input is from the microphone\n",
    "            if self.input_source == 'mic':\n",
    "                self.speak(response)\n",
    "            self.mes_win.delete(0, tk.END)\n",
    "\n",
    "    def activate_mic(self):\n",
    "        if self.mic_image:\n",
    "            self.mic_button.config(image=self.mic_image)\n",
    "        else:\n",
    "            self.mic_button.config(text=\"Mic\")\n",
    "\n",
    "        engine = pyttsx3.init()\n",
    "        rate = engine.getProperty('rate')\n",
    "        engine.setProperty('rate', 170)\n",
    "        voices = engine.getProperty('voices')\n",
    "        engine.setProperty('voice', voices[1].id)\n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            r.energy_threshold = 400\n",
    "            r.adjust_for_ambient_noise(source, 1.2)\n",
    "            self.textcon.insert(tk.END, \"NLPAssistant: Listening... \\n\")  # Display listening message in textcon\n",
    "            audio = r.listen(source)\n",
    "            text = r.recognize_google(audio)\n",
    "            self.textcon.insert(tk.END, f\"You (Mic): {text}\\n\", 'usr')  # Display user's input in textcon\n",
    "            self.input_source = 'mic'\n",
    "\n",
    "            # Handle the user input (speech-to-text)\n",
    "            response = self.handle_user_input(text)\n",
    "            self.textcon.insert(tk.END, f\"NLPAssistant: {response}\\n\")\n",
    "            self.speak(response)\n",
    "\n",
    "    def speak(self, text):\n",
    "        self.engine.say(text)\n",
    "        self.engine.runAndWait()\n",
    "\n",
    "    def handle_user_input(self, user_input):\n",
    "        user_keywords = self.extract_keywords(user_input)\n",
    "\n",
    "        # Check if the user wants to open a specific website\n",
    "        if \"open\" in user_keywords and any(keyword in user_keywords for keyword in [\"youtube\"]):\n",
    "            self.open_website(user_input)\n",
    "            return \"Opening in YouTube...\"\n",
    "\n",
    "        # Check if the user wants to search on Wikipedia\n",
    "        if \"search\" in user_keywords and \"for\" in user_keywords:\n",
    "            self.search_wikipedia(user_input)\n",
    "            return \"Searching on Wikipedia...\"\n",
    "\n",
    "        # Continue with the existing logic for other responses\n",
    "        for example in data.get(\"intents\", []):\n",
    "            if \"question\" in example:\n",
    "                question_keywords = [keyword for q in example[\"question\"] for keyword in self.extract_keywords(q)]\n",
    "\n",
    "                if all(keyword in question_keywords for keyword in user_keywords):\n",
    "                    answer = example.get(\"answer\", [])\n",
    "                    return f\"{answer}\"\n",
    "\n",
    "        input_ids = tokenizer.encode(user_input, return_tensors=\"tf\")\n",
    "        output = gpt_model.generate(input_ids, max_length=150, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95,\n",
    "                                    temperature=0.7)\n",
    "        bot_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        # Adjust the response based on the user's technical ability\n",
    "        technical_ability = \"tech\"  # You need to get this value from somewhere\n",
    "        if technical_ability == \"tech\":\n",
    "            # Customize response for technical users\n",
    "            pass\n",
    "        else:\n",
    "            # Customize response for non-technical users\n",
    "            pass\n",
    "\n",
    "        candidate_answers = [\"Your first answer\", \"Your second answer\", \"Your third answer\"]\n",
    "        relevancy_scores = self.score_relevancy(user_input, candidate_answers)\n",
    "\n",
    "        # Store or update relevancy scores for future learning\n",
    "        # Update your model based on user feedback and learning algorithm\n",
    "\n",
    "        return bot_response\n",
    "\n",
    "    def extract_keywords(self, text):\n",
    "        doc = nlp(text)\n",
    "        return [token.text.lower() for token in doc if token.is_alpha]\n",
    "\n",
    "    def score_relevancy(self, user_input, candidate_answers):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([user_input] + candidate_answers)\n",
    "        similarity_matrix = cosine_similarity(vectors)\n",
    "        relevancy_scores = similarity_matrix[0][1:]\n",
    "        return relevancy_scores\n",
    "\n",
    "    def open_website(self, user_input):\n",
    "        # Extract the website name from the user input\n",
    "        website_name = next((word for word in user_input.split() if word.lower() in [\"youtube\"]), None)\n",
    "\n",
    "        if website_name:\n",
    "            # Open the specified website in the default web browser\n",
    "            url = f\"https://www.{website_name}.com\"\n",
    "            webbrowser.open(url)\n",
    "\n",
    "    def search_wikipedia(self, user_input):\n",
    "        # Extract the search query from the user input\n",
    "        search_query = user_input.split(\"for\", 1)[-1].strip()\n",
    "\n",
    "        if search_query:\n",
    "            # Search the query on Wikipedia\n",
    "            url = f\"https://en.wikipedia.org/wiki/Special:Search?search={search_query}\"\n",
    "            webbrowser.open(url)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot_app = ChatbotApp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51620ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Exception in thread Thread-68:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_16356\\419094936.py\", line 130, in listen_continuously\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 3743, in insert\n",
      "    self.tk.call((self._w, 'insert', index, chars) + args)\n",
      "RuntimeError: main thread is not in main loop\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n",
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n",
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n",
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n",
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n",
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n",
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n",
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n",
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n",
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n",
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPAssistant: Sorry, I could not understand the audio. Please try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-75:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_16356\\419094936.py\", line 120, in listen_continuously\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 3743, in insert\n",
      "    self.tk.call((self._w, 'insert', index, chars) + args)\n",
      "RuntimeError: main thread is not in main loop\n"
     ]
    }
   ],
   "source": [
    "#working code 2 with updations\n",
    "import tkinter as tk\n",
    "from tkinter import Entry, Button, PhotoImage\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import json\n",
    "import threading\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the following import at the beginning of the file\n",
    "from speech_recognition import UnknownValueError\n",
    "\n",
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load pre-trained language model (GPT-2)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load or collect data for training/fine-tuning (replace with your actual data loading)\n",
    "with open('C:/Users/VAMSI/OneDrive/Desktop/chatbot.h5/tech.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "class ChatbotApp:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(f\"NLPAssistant\")\n",
    "        self.root.geometry('1000x800')  # Increased dimensions\n",
    "        self.root.resizable(False, False)\n",
    "        self.message = tk.StringVar()\n",
    "        self.is_listening = False\n",
    "        self.greeted = False\n",
    "\n",
    "        self.textcon = tk.Text(self.root, bd=1, bg='white', width=70, height=15)  # Adjusted dimensions\n",
    "        self.textcon.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        self.mes_win = Entry(self.root, width=50, xscrollcommand=True, textvariable=self.message)\n",
    "        self.mes_win.place(x=1, y=720, height=60, width=679)  # Adjusted dimensions\n",
    "        self.mes_win.focus()\n",
    "\n",
    "        self.textcon.config(fg='black')\n",
    "        self.textcon.tag_config('usr', foreground='black')\n",
    "        self.textcon.insert(tk.END, \"NLPAssistant : This is Friday! Your Assistant.\\n\\n\")\n",
    "\n",
    "        self.exit_list = ['goodbye', 'bye', 'off']\n",
    "\n",
    "        mic_image_path = \"mic.png\"\n",
    "        if os.path.exists(mic_image_path):\n",
    "            self.mic_image = PhotoImage(file=mic_image_path).subsample(2, 3)\n",
    "        else:\n",
    "            print(f\"Error: Mic image not found at {mic_image_path}\")\n",
    "            self.mic_image = None\n",
    "\n",
    "        self.mic_button = Button(self.root, text='Mic', bg='blue', activebackground='white',\n",
    "                                 command=self.activate_mic, width=12, height=2, font=('Arial'))\n",
    "        self.mic_button.place(x=800, y=720, height=60, width=110)  # Adjusted dimensions\n",
    "\n",
    "        self.send_button = Button(self.root, text='Send', bg='dark green', activebackground='grey',\n",
    "                                   command=self.send_msz, width=12, height=2, font=('Arial'))\n",
    "        self.send_button.place(x=680, y=720, height=60, width=110)  # Adjusted dimensions\n",
    "\n",
    "        self.root.bind('<Return>', self.send_msz)\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def send_msz(self, event=None):\n",
    "        usr_input = self.message.get()\n",
    "        usr_input = usr_input.lower()\n",
    "        self.textcon.insert(tk.END, f'You : {usr_input}' + '\\n', 'usr')\n",
    "\n",
    "        if usr_input.lower() in [\"goodbye\", \"bye\"]:\n",
    "            self.textcon.config(fg='black')\n",
    "            response = \"Thank You sir, I hope I assisted you properly\"\n",
    "            self.textcon.insert(tk.END, f\"NLPAssistant : {response}\\n\")\n",
    "            self.speak(response)\n",
    "            return self.root.destroy()\n",
    "\n",
    "        else:\n",
    "            self.textcon.config(fg='black')\n",
    "            response = self.handle_user_input(usr_input)\n",
    "            self.textcon.insert(tk.END, f\"NLPAssistant: {response}\\n\")\n",
    "            # Speak only if the input is from the microphone\n",
    "            if hasattr(self, 'input_source') and self.input_source == 'mic':\n",
    "                self.speak(response)\n",
    "            self.mes_win.delete(0, tk.END)\n",
    "\n",
    "    def activate_mic(self):\n",
    "        if self.mic_image:\n",
    "            self.mic_button.config(image=self.mic_image)\n",
    "        else:\n",
    "            self.mic_button.config(text=\"Mic\")\n",
    "\n",
    "        self.is_listening = True\n",
    "        threading.Thread(target=self.listen_continuously).start()\n",
    "\n",
    "    def listen_continuously(self):\n",
    "        r = sr.Recognizer()\n",
    "\n",
    "        while self.is_listening:\n",
    "            if not self.greeted:\n",
    "                self.greeted = True\n",
    "                self.speak(\"Hello sir! I am your Friday.\")\n",
    "                current_time = datetime.now().strftime(\"%I:%M %p\")\n",
    "                self.speak(f\"The current time is {current_time}\")\n",
    "\n",
    "            engine = pyttsx3.init()\n",
    "            rate = engine.getProperty('rate')\n",
    "            engine.setProperty('rate', 170)\n",
    "            voices = engine.getProperty('voices')\n",
    "            engine.setProperty('voice', voices[1].id)\n",
    "\n",
    "            with sr.Microphone() as source:\n",
    "                r.energy_threshold = 400\n",
    "                r.adjust_for_ambient_noise(source, 1.2)\n",
    "                self.textcon.insert(tk.END, \"NLPAssistant: Listening... \\n\")  # Display listening message in textcon\n",
    "\n",
    "                try:\n",
    "                    audio = r.listen(source)\n",
    "                    text = r.recognize_google(audio)\n",
    "                    self.textcon.insert(tk.END, f\"You (Mic): {text}\\n\", 'usr')  # Display user's input in textcon\n",
    "                    self.input_source = 'mic'\n",
    "\n",
    "                    # Handle the user input (speech-to-text)\n",
    "                    response = self.handle_user_input(text)\n",
    "                    self.textcon.insert(tk.END, f\"NLPAssistant: {response}\\n\")\n",
    "                    if self.input_source == 'mic':\n",
    "                        self.speak(response)\n",
    "\n",
    "                except UnknownValueError:\n",
    "                    print(\"NLPAssistant: Sorry, I could not understand the audio. Please try again.\")\n",
    "\n",
    "                except sr.RequestError as e:\n",
    "                    print(f\"NLPAssistant: There was an error with the speech recognition service: {e}\")\n",
    "\n",
    "    def speak(self, text):\n",
    "        self.engine.say(text)\n",
    "        self.engine.runAndWait()\n",
    "\n",
    "    def handle_user_input(self, user_input):\n",
    "        user_keywords = self.extract_keywords(user_input)\n",
    "\n",
    "        for example in data.get(\"intents\", []):\n",
    "            if \"question\" in example:\n",
    "                question_keywords = [keyword for q in example[\"question\"] for keyword in self.extract_keywords(q)]\n",
    "\n",
    "                if all(keyword in question_keywords for keyword in user_keywords):\n",
    "                    answer = example.get(\"answer\", [])\n",
    "                    return f\"{answer}\"\n",
    "\n",
    "        input_ids = tokenizer.encode(user_input, return_tensors=\"tf\")\n",
    "        output = gpt_model.generate(input_ids, max_length=150, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95,\n",
    "                                    temperature=0.7)\n",
    "        bot_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        # Adjust the response based on the user's technical ability\n",
    "        technical_ability = \"tech\"  # You need to get this value from somewhere\n",
    "        if technical_ability == \"tech\":\n",
    "            # Customize response for technical users\n",
    "            pass\n",
    "        else:\n",
    "            # Customize response for non-technical users\n",
    "            pass\n",
    "\n",
    "        candidate_answers = [\"Your first answer\", \"Your second answer\", \"Your third answer\"]\n",
    "        relevancy_scores = self.score_relevancy(user_input, candidate_answers)\n",
    "\n",
    "        # Store or update relevancy scores for future learning\n",
    "        # Update your model based on user feedback and learning algorithm\n",
    "\n",
    "        return bot_response\n",
    "\n",
    "    def extract_keywords(self, text):\n",
    "        doc = nlp(text)\n",
    "        return [token.text.lower() for token in doc if token.is_alpha]\n",
    "\n",
    "    def score_relevancy(self, user_input, candidate_answers):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([user_input] + candidate_answers)\n",
    "        similarity_matrix = cosine_similarity(vectors)\n",
    "        relevancy_scores = similarity_matrix[0][1:]\n",
    "        return relevancy_scores\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot_app = ChatbotApp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de47c015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: googletrans==4.0.0-rc1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.9.14)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e611dbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chitti: Sorry, I could not understand the audio. Please try again.\n",
      "chitti: Sorry, I could not understand the audio. Please try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_16356\\1641988868.py\", line 140, in listen_continuously\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 3743, in insert\n",
      "    self.tk.call((self._w, 'insert', index, chars) + args)\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_16356\\1641988868.py\", line 145, in listen_continuously\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 3743, in insert\n",
      "    self.tk.call((self._w, 'insert', index, chars) + args)\n",
      "RuntimeError: main thread is not in main loop\n"
     ]
    }
   ],
   "source": [
    "# working 4 with translate options in the UI\n",
    "import tkinter as tk\n",
    "from tkinter import Entry, Button, PhotoImage, Listbox\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import json\n",
    "import threading\n",
    "from googletrans import Translator\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the following import at the beginning of the file\n",
    "from speech_recognition import UnknownValueError\n",
    "\n",
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load pre-trained language model (GPT-2)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load or collect data for training/fine-tuning (replace with your actual data loading)\n",
    "with open('C:/Users/VAMSI/OneDrive/Desktop/chatbot.h5/tech.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "class ChatbotApp:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(f\"chitti\")\n",
    "        self.root.geometry('1000x800')  # Increased dimensions\n",
    "        self.root.resizable(False, False)\n",
    "        self.message = tk.StringVar()\n",
    "        self.is_listening = False\n",
    "        self.greeted = False\n",
    "        self.selected_language = None\n",
    "\n",
    "        self.textcon = tk.Text(self.root, bd=1, bg='white', width=70, height=15)  # Adjusted dimensions\n",
    "        self.textcon.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        self.mes_win = Entry(self.root, width=50, xscrollcommand=True, textvariable=self.message)\n",
    "        self.mes_win.place(x=1, y=720, height=60, width=679)  # Adjusted dimensions\n",
    "        self.mes_win.focus()\n",
    "\n",
    "        self.textcon.config(fg='black')\n",
    "        self.textcon.tag_config('usr', foreground='black')\n",
    "        self.textcon.insert(tk.END, \"chitti : This is chitti! Your Assistant.\\n\\n\")\n",
    "\n",
    "        self.exit_list = ['goodbye', 'bye', 'off']\n",
    "\n",
    "        mic_image_path = \"mic.png\"\n",
    "        if os.path.exists(mic_image_path):\n",
    "            self.mic_image = PhotoImage(file=mic_image_path).subsample(2, 3)\n",
    "        else:\n",
    "            print(f\"Error: Mic image not found at {mic_image_path}\")\n",
    "            self.mic_image = None\n",
    "\n",
    "        self.mic_button = Button(self.root, text='Mic', bg='blue', activebackground='white',\n",
    "                                 command=self.activate_mic, width=12, height=2, font=('Arial'))\n",
    "        self.mic_button.place(x=800, y=720, height=60, width=110)  # Adjusted dimensions\n",
    "\n",
    "        self.send_button = Button(self.root, text='Send', bg='pink', activebackground='grey',\n",
    "                                   command=self.send_msz, width=12, height=2, font=('Arial'))\n",
    "        self.send_button.place(x=680, y=720, height=60, width=110)  # Adjusted dimensions\n",
    "\n",
    "        self.language_listbox = Listbox(self.root, selectmode=tk.SINGLE, exportselection=False)\n",
    "        self.language_listbox.place(x=920, y=720, height=60, width=80)\n",
    "        self.language_listbox.insert(1, \"Telugu\")\n",
    "        self.language_listbox.insert(2, \"Kannada\")\n",
    "        self.language_listbox.insert(3, \"Tamil\")\n",
    "        self.language_listbox.insert(4, \"Hindi\")\n",
    "        self.language_listbox.select_set(0)\n",
    "\n",
    "        self.root.bind('<Return>', self.send_msz)\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.translator = Translator()\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def send_msz(self, event=None):\n",
    "        usr_input = self.message.get()\n",
    "        usr_input = usr_input.lower()\n",
    "        self.textcon.insert(tk.END, f'You : {usr_input}' + '\\n', 'usr')\n",
    "\n",
    "        if usr_input.lower() in [\"goodbye\", \"bye\"]:\n",
    "            self.textcon.config(fg='black')\n",
    "            response = \"Thank You sir, I hope I assisted you properly\"\n",
    "            self.textcon.insert(tk.END, f\"chitti : {response}\\n\")\n",
    "            self.speak(response)\n",
    "            return self.root.destroy()\n",
    "\n",
    "        elif \"translate\" in usr_input:\n",
    "            self.speak(\"Sure, I can help with translation. Please select a language option.\")\n",
    "            self.selected_language = self.language_listbox.get(tk.ACTIVE).lower()\n",
    "\n",
    "        else:\n",
    "            self.textcon.config(fg='black')\n",
    "            response = self.handle_user_input(usr_input)\n",
    "            self.textcon.insert(tk.END, f\"chitti: {response}\\n\")\n",
    "            # Speak only if the input is from the microphone and not a translation request\n",
    "            if hasattr(self, 'input_source') and self.input_source == 'mic' and not self.selected_language:\n",
    "                self.speak(response)\n",
    "            self.mes_win.delete(0, tk.END)\n",
    "\n",
    "    def activate_mic(self):\n",
    "        if self.mic_image:\n",
    "            self.mic_button.config(image=self.mic_image)\n",
    "        else:\n",
    "            self.mic_button.config(text=\"Mic\")\n",
    "\n",
    "        self.is_listening = True\n",
    "        threading.Thread(target=self.listen_continuously).start()\n",
    "\n",
    "    def listen_continuously(self):\n",
    "        r = sr.Recognizer()\n",
    "\n",
    "        while self.is_listening:\n",
    "            if not self.greeted:\n",
    "                self.greeted = True\n",
    "                self.speak(\"Hello sir! I am your chitti.\")\n",
    "                current_time = datetime.now().strftime(\"%I:%M %p\")\n",
    "                self.speak(f\"The current time is {current_time}\")\n",
    "\n",
    "            engine = pyttsx3.init()\n",
    "            rate = engine.getProperty('rate')\n",
    "            engine.setProperty('rate', 170)\n",
    "            voices = engine.getProperty('voices')\n",
    "            engine.setProperty('voice', voices[1].id)\n",
    "\n",
    "            with sr.Microphone() as source:\n",
    "                r.energy_threshold = 400\n",
    "                r.adjust_for_ambient_noise(source, 1.2)\n",
    "                self.textcon.insert(tk.END, \"chitti: Listening... \\n\")  # Display listening message in textcon\n",
    "\n",
    "                try:\n",
    "                    audio = r.listen(source)\n",
    "                    text = r.recognize_google(audio)\n",
    "                    self.textcon.insert(tk.END, f\"You (Mic): {text}\\n\", 'usr')  # Display user's input in textcon\n",
    "                    self.input_source = 'mic'\n",
    "\n",
    "                    # Handle the user input (speech-to-text)\n",
    "                    response = self.handle_user_input(text)\n",
    "                    self.textcon.insert(tk.END, f\"chitti: {response}\\n\")\n",
    "                    if self.input_source == 'mic' and not self.selected_language:\n",
    "                        self.speak(response)\n",
    "\n",
    "                except UnknownValueError:\n",
    "                    print(\"chitti: Sorry, I could not understand the audio. Please try again.\")\n",
    "\n",
    "                except sr.RequestError as e:\n",
    "                    print(f\"chitti: There was an error with the speech recognition service: {e}\")\n",
    "\n",
    "    def speak(self, text):\n",
    "        self.engine.say(text)\n",
    "        self.engine.runAndWait()\n",
    "\n",
    "    def handle_user_input(self, user_input):\n",
    "        user_keywords = self.extract_keywords(user_input)\n",
    "\n",
    "        for example in data.get(\"intents\", []):\n",
    "            if \"question\" in example:\n",
    "                question_keywords = [keyword for q in example[\"question\"] for keyword in self.extract_keywords(q)]\n",
    "\n",
    "                if all(keyword in question_keywords for keyword in user_keywords):\n",
    "                    answer = example.get(\"answer\", [])\n",
    "                    return f\"{answer}\"\n",
    "\n",
    "        if self.selected_language:\n",
    "            # Translate the user input to English using the googletrans library\n",
    "            translated_text = self.translate_text(user_input, self.selected_language, \"en\")\n",
    "\n",
    "            self.speak(\"Here is the translation:\")\n",
    "            self.textcon.insert(tk.END, f\"chitti: Translation: {translated_text}\\n\")\n",
    "\n",
    "        else:\n",
    "            input_ids = tokenizer.encode(user_input, return_tensors=\"tf\")\n",
    "            output = gpt_model.generate(input_ids, max_length=150, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95,\n",
    "                                        temperature=0.7)\n",
    "            bot_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "            # Adjust the response based on the user's technical ability\n",
    "            technical_ability = \"tech\"  # You need to get this value from somewhere\n",
    "            if technical_ability == \"tech\":\n",
    "                # Customize response for technical users\n",
    "                pass\n",
    "            else:\n",
    "                # Customize response for non-technical users\n",
    "                pass\n",
    "\n",
    "            candidate_answers = [\"Your first answer\", \"Your second answer\", \"Your third answer\"]\n",
    "            relevancy_scores = self.score_relevancy(user_input, candidate_answers)\n",
    "\n",
    "            # Store or update relevancy scores for future learning\n",
    "            # Update your model based on user feedback and learning algorithm\n",
    "\n",
    "            return bot_response\n",
    "\n",
    "    def extract_keywords(self, text):\n",
    "        doc = nlp(text)\n",
    "        return [token.text.lower() for token in doc if token.is_alpha]\n",
    "\n",
    "    def score_relevancy(self, user_input, candidate_answers):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([user_input] + candidate_answers)\n",
    "        similarity_matrix = cosine_similarity(vectors)\n",
    "        relevancy_scores = similarity_matrix[0][1:]\n",
    "        return relevancy_scores\n",
    "\n",
    "    def translate_text(self, text, source_language, target_language):\n",
    "        translation = self.translator.translate(text, src=source_language, dest=target_language)\n",
    "        return translation.text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot_app = ChatbotApp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18f7ce7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2/2 [==============================] - 2s 20ms/step - loss: 1.5711 - accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5287 - accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5560 - accuracy: 0.3000\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.4362 - accuracy: 0.6000\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5342 - accuracy: 0.8000\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5353 - accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5187 - accuracy: 0.8000\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.4936 - accuracy: 0.8000\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4644 - accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5629 - accuracy: 0.6000\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.4883 - accuracy: 0.6000\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.4276 - accuracy: 0.8000\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7331 - accuracy: 0.6000\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5539 - accuracy: 0.6000\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6510 - accuracy: 0.4000\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6733 - accuracy: 0.6000\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6549 - accuracy: 0.7000\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6249 - accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.7644 - accuracy: 0.6000\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6107 - accuracy: 0.4000\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9107 - accuracy: 0.7000\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.8887 - accuracy: 0.4000\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.3900 - accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.0959 - accuracy: 0.3000\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.3459 - accuracy: 0.4000\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8690 - accuracy: 0.6000\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.8499 - accuracy: 0.6000\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9584 - accuracy: 0.4000\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 29.7991 - accuracy: 0.3000\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 82.1616 - accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 130.1969 - accuracy: 0.3000\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 570.1957 - accuracy: 0.1000\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1262.3531 - accuracy: 0.7000\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7084.2764 - accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23531.6016 - accuracy: 0.4000\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 53372.5820 - accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 71989.0312 - accuracy: 0.6000\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1577.1427 - accuracy: 0.7000\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4460.4141 - accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13838.8301 - accuracy: 0.2000\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 162.6080 - accuracy: 0.6000\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3180.0469 - accuracy: 0.1000\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 666.3900 - accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2962.3696 - accuracy: 0.2000\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 285.8289 - accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 303.2219 - accuracy: 0.2000\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1251.2416 - accuracy: 0.3000\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.9004 - accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1014.8880 - accuracy: 0.4000\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.2654 - accuracy: 0.6000\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.8903 - accuracy: 0.7000\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.8373 - accuracy: 0.8000\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4728 - accuracy: 0.7000\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.7092 - accuracy: 0.7000\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.9775 - accuracy: 0.6000\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1259 - accuracy: 0.7000\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.0597 - accuracy: 0.3000\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.8057 - accuracy: 0.7000\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.9334 - accuracy: 0.4000\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8771 - accuracy: 0.7000\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6001 - accuracy: 0.7000\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.7699 - accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4378 - accuracy: 0.9000\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0051 - accuracy: 0.4000\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.0127 - accuracy: 0.8000\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.2249 - accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6903 - accuracy: 0.6000\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.9280 - accuracy: 0.3000\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.7524 - accuracy: 0.6000\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.4506 - accuracy: 0.4000\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 33.9554 - accuracy: 0.6000\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.2823 - accuracy: 0.7000\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 203.9201 - accuracy: 0.2000\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.6915 - accuracy: 0.6000\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.5848 - accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5421 - accuracy: 0.3000\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.0983 - accuracy: 0.2000\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.1702 - accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.3761 - accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.6985 - accuracy: 0.6000\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.0811 - accuracy: 0.6000\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.6074 - accuracy: 0.4000\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 5.4976 - accuracy: 0.8000\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.2084 - accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.6875 - accuracy: 0.1000 \n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.1416 - accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.1387 - accuracy: 0.4000\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 92.4674 - accuracy: 0.8000\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 206.5090 - accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 825.9264 - accuracy: 0.4000\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 16372.7910 - accuracy: 0.4000\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 36448.2109 - accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 218.5874 - accuracy: 0.8000\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 250.7110 - accuracy: 0.8000\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 414.2956 - accuracy: 0.7000\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 276.9718 - accuracy: 0.4000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 117.5150 - accuracy: 0.4000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.6967 - accuracy: 0.2000\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.0170 - accuracy: 0.2000\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3128 - accuracy: 0.4000\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3709 - accuracy: 0.6000\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9831 - accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.9731 - accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.6090 - accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4646 - accuracy: 0.6000\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.1724 - accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.7573 - accuracy: 0.6000\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.7427 - accuracy: 0.8000\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.7628 - accuracy: 0.8000\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 4.0374 - accuracy: 0.8000\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.0573 - accuracy: 0.8000\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.6508 - accuracy: 0.8000\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2275 - accuracy: 0.8000\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0371 - accuracy: 0.8000\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5471 - accuracy: 0.5000\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.4026 - accuracy: 0.6000\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.3968 - accuracy: 0.6000\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.9018 - accuracy: 0.3000\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.4191 - accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9018 - accuracy: 0.3000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.8883 - accuracy: 0.4000\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.7983 - accuracy: 0.7000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.4639 - accuracy: 0.5000\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4613 - accuracy: 0.4000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0707 - accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6847 - accuracy: 0.8000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.5918 - accuracy: 0.8000\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7060 - accuracy: 0.8000\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7450 - accuracy: 0.8000\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7055 - accuracy: 0.8000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6305 - accuracy: 0.8000\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.5697 - accuracy: 0.8000\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0337 - accuracy: 0.8000\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5018 - accuracy: 0.9000\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4206 - accuracy: 0.8000\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5907 - accuracy: 0.4000\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.4881 - accuracy: 0.7000\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6716 - accuracy: 0.3000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4843 - accuracy: 0.6000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5476 - accuracy: 0.4000\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5387 - accuracy: 0.8000\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.6019 - accuracy: 0.7000\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.7241 - accuracy: 0.6000\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5365 - accuracy: 0.4000\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5471 - accuracy: 0.2000\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5205 - accuracy: 0.6000\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6083 - accuracy: 0.4000\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7960 - accuracy: 0.5000\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7099 - accuracy: 0.6000\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.3498 - accuracy: 0.2000\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8516 - accuracy: 0.7000\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.8219 - accuracy: 0.6000\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.6022 - accuracy: 0.4000\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8868 - accuracy: 0.4000\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.7585 - accuracy: 0.4000\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.8050 - accuracy: 0.5000\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5598 - accuracy: 0.8000\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1378 - accuracy: 0.5000\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.0309 - accuracy: 0.6000\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.4336 - accuracy: 0.5000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.0736 - accuracy: 0.4000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.6269 - accuracy: 0.3000\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5697 - accuracy: 0.3000\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8801 - accuracy: 0.7000\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.4757 - accuracy: 0.5000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4265 - accuracy: 0.4000\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.3220 - accuracy: 0.7000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.6757 - accuracy: 0.5000\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.3821 - accuracy: 0.9000\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.7657 - accuracy: 0.7000\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.0930 - accuracy: 0.2000\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.6218 - accuracy: 0.4000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 16.3100 - accuracy: 0.5000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.6001 - accuracy: 0.5000\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.2718 - accuracy: 0.1000\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.3001 - accuracy: 0.7000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.9330 - accuracy: 0.2000\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.3454 - accuracy: 0.6000\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.0004 - accuracy: 0.6000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.5966 - accuracy: 0.2000\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.6532 - accuracy: 0.5000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.5643 - accuracy: 0.3000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.4858 - accuracy: 0.6000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.8284 - accuracy: 0.4000\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.9996 - accuracy: 0.3000\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.2156 - accuracy: 0.2000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 38.3528 - accuracy: 0.2000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 18.6204 - accuracy: 0.5000\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.9647 - accuracy: 0.7000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.8729 - accuracy: 0.6000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.4720 - accuracy: 0.4000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 64.3726 - accuracy: 0.5000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 54.8254 - accuracy: 0.5000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.1260 - accuracy: 0.7000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 13.3345 - accuracy: 0.2000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.9034 - accuracy: 0.5000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 33.3966 - accuracy: 0.3000\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.6809 - accuracy: 0.3000\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 39.3513 - accuracy: 0.4000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 34.7399 - accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VAMSI\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Model Created Successfully!\n",
      "Enter the Question you want (type 'break' or 'quit' to exit): hi\n",
      "Enter the user's technical ability: what is ai\n",
      "User Keywords: ['hi']\n",
      "Answer from JSON file: ['Hello! how can i help you ?']\n",
      "Enter the Question you want (type 'break' or 'quit' to exit): quit\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "#!pip install tensorflow transformers scikit-learn spacy\n",
    "\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import spacy\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import random\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load pre-trained language model (GPT-2)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Function to load JSON data\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Function to train the neural network model\n",
    "def train_model(train_x, train_y):\n",
    "    # Create NN model to predict the responses\n",
    "    model_nn = Sequential()\n",
    "    model_nn.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "    model_nn.add(Dropout(0.5))\n",
    "    model_nn.add(Dense(64, activation='relu'))\n",
    "    model_nn.add(Dropout(0.5))\n",
    "    model_nn.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "    # Compile model using the newer version of SGD optimizer\n",
    "    sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "    model_nn.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    # Fitting and saving the model\n",
    "    hist = model_nn.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
    "    model_nn.save('chatbot.h5')  # Save the model for future use\n",
    "    print(\"\\n\")\n",
    "    print(\"*\" * 50)\n",
    "    print(\"\\nModel Created Successfully!\")\n",
    "\n",
    "# Function to score answer relevancy using TF-IDF\n",
    "def score_relevancy(user_input, candidate_answers):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([user_input] + candidate_answers)\n",
    "    similarity_matrix = cosine_similarity(vectors)\n",
    "    relevancy_scores = similarity_matrix[0][1:]\n",
    "    return relevancy_scores\n",
    "\n",
    "# Function to extract keywords using spaCy\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text.lower() for token in doc if token.is_alpha]\n",
    "\n",
    "# Function to handle user input\n",
    "def handle_user_input(user_input, technical_ability, test_data):\n",
    "    user_keywords = extract_keywords(user_input)\n",
    "    print(f\"User Keywords: {user_keywords}\")\n",
    "\n",
    "    for example in test_data[\"intents\"]:\n",
    "        if \"question\" in example:\n",
    "            question_keywords = [keyword for q in example[\"question\"] for keyword in extract_keywords(q)]\n",
    "\n",
    "            if all(keyword in question_keywords for keyword in user_keywords):\n",
    "                answer = example.get(\"answer\", [])\n",
    "                return f\"Answer from JSON file: {answer}\"\n",
    "\n",
    "    input_ids = tokenizer.encode(user_input, return_tensors=\"tf\")\n",
    "    output = model.generate(input_ids, max_length=150, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)\n",
    "    bot_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Adjust the response based on the user's technical ability\n",
    "    if technical_ability == \"tech\":\n",
    "        # Customize response for technical users\n",
    "        pass\n",
    "    else:\n",
    "        # Customize response for non-technical users\n",
    "        pass\n",
    "\n",
    "    candidate_answers = [\"Your first answer\", \"Your second answer\", \"Your third answer\"]\n",
    "    relevancy_scores = score_relevancy(user_input, candidate_answers)\n",
    "\n",
    "    # Store or update relevancy scores for future learning\n",
    "    # Update your model based on user feedback and learning algorithm\n",
    "\n",
    "    return bot_response\n",
    "\n",
    "# Load or collect data for training/fine-tuning\n",
    "data = load_json(\"C:/Users/VAMSI/OneDrive/Desktop/chatbot.h5/tech.json\")\n",
    "\n",
    "# Example data preparation (replace this with your actual training data)\n",
    "# For now, using placeholder values\n",
    "train_x = np.random.rand(10, 5)  # Placeholder values for training features\n",
    "train_y = np.random.randint(2, size=(10, 3))  # Placeholder values for training labels\n",
    "\n",
    "# Train or fine-tune the model\n",
    "train_model(train_x, train_y)\n",
    "\n",
    "# Example usage\n",
    "while True:\n",
    "    user_input = input(\"Enter the Question you want (type 'break' or 'quit' to exit): \")\n",
    "    if user_input.lower() in [\"break\", \"quit\"]:\n",
    "        break\n",
    "    technical_ability = input(\"Enter the user's technical ability: \")\n",
    "    response = handle_user_input(user_input, technical_ability, data)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e314c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2 0 0]\n",
      " [0 3 1]\n",
      " [0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "true_labels = np.array([1, 0, 1, 2, 1, 0, 2, 1, 2])\n",
    "predicted_labels = np.array([1, 0, 1, 2, 2, 0, 2, 1, 1])\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8ab0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=np.unique(true_labels),\n",
    "            yticklabels=np.unique(true_labels))\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a12a658b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data (replace this with your actual data\n",
    "\n",
    "# Plot histogram for true labels\n",
    "plt.hist(true_labels, bins=np.unique(true_labels) - 0.5, alpha=0.5, label='True Labels')\n",
    "\n",
    "# Plot histogram for predicted labels\n",
    "plt.hist(predicted_labels, bins=np.unique(predicted_labels) - 0.5, alpha=0.5, label='Predicted Labels')\n",
    "\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of True and Predicted Labels')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9139fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PrettyTable\n",
      "  Downloading prettytable-3.9.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from PrettyTable) (0.2.5)\n",
      "Installing collected packages: PrettyTable\n",
      "Successfully installed PrettyTable-3.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b481517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------------------------------------------+-------------+\n",
      "|     Tool    |                        Features                        | Integration |\n",
      "+-------------+--------------------------------------------------------+-------------+\n",
      "|    MLflow   | Experiment tracking, artifact logging, metrics logging |     True    |\n",
      "| TensorBoard |     Interactive dashboards, metrics visualization      |    False    |\n",
      "+-------------+--------------------------------------------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "mlflow_used = True  # Set to True since MLflow is used in the provided code\n",
    "tensorboard_used = False  # Set to True if you use TensorBoard or any other tool\n",
    "\n",
    "# Create a PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Tool\", \"Features\", \"Integration\"]\n",
    "\n",
    "# Add rows to the table\n",
    "table.add_row([\"MLflow\", \"Experiment tracking, artifact logging, metrics logging\", mlflow_used])\n",
    "table.add_row([\"TensorBoard\", \"Interactive dashboards, metrics visualization\", tensorboard_used])\n",
    "# Add more rows for other tools as needed\n",
    "\n",
    "# Print the table\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def3cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c49fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: googletrans==4.0.0-rc1 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.9.14)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\vamsi\\appdata\\roaming\\python\\python39\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install googletrans==4.0.0-rc1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2bf98ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_16356\\4068595930.py\", line 137, in listen_continuously\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 3743, in insert\n",
      "    self.tk.call((self._w, 'insert', index, chars) + args)\n",
      "RuntimeError: main thread is not in main loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chitti: Sorry, I could not understand the audio. Please try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chitti: Sorry, I could not understand the audio. Please try again.\n",
      "chitti: Sorry, I could not understand the audio. Please try again.\n",
      "chitti: Sorry, I could not understand the audio. Please try again.\n",
      "chitti: Sorry, I could not understand the audio. Please try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Exception in thread Thread-38:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_16356\\4068595930.py\", line 147, in listen_continuously\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 3743, in insert\n",
      "    self.tk.call((self._w, 'insert', index, chars) + args)\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception in thread Thread-33:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_16356\\4068595930.py\", line 147, in listen_continuously\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 3743, in insert\n",
      "    self.tk.call((self._w, 'insert', index, chars) + args)\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception in thread Thread-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\VAMSI\\AppData\\Local\\Temp\\ipykernel_16356\\4068595930.py\", line 147, in listen_continuously\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 3743, in insert\n",
      "    self.tk.call((self._w, 'insert', index, chars) + args)\n",
      "RuntimeError: main thread is not in main loop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from googletrans import Translator, LANGUAGES\n",
    "\n",
    "# working 4 with translate options in the UI\n",
    "import tkinter as tk\n",
    "from tkinter import Entry, Button, PhotoImage, Listbox\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import json\n",
    "import threading\n",
    "from googletrans import Translator\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the following import at the beginning of the file\n",
    "from speech_recognition import UnknownValueError\n",
    "\n",
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load pre-trained language model (GPT-2)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load or collect data for training/fine-tuning (replace with your actual data loading)\n",
    "with open('C:/Users/VAMSI/OneDrive/Desktop/chatbot.h5/tech.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "class ChatbotApp:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(f\"chitti\")\n",
    "        self.root.geometry('1000x800')  # Increased dimensions\n",
    "        self.root.resizable(False, False)\n",
    "        self.message = tk.StringVar()\n",
    "        self.is_listening = False\n",
    "        self.greeted = False\n",
    "        self.selected_language = None\n",
    "\n",
    "        self.textcon = tk.Text(self.root, bd=1, bg='white', width=70, height=15)  # Adjusted dimensions\n",
    "        self.textcon.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        self.mes_win = Entry(self.root, width=50, xscrollcommand=True, textvariable=self.message)\n",
    "        self.mes_win.place(x=1, y=720, height=60, width=679)  # Adjusted dimensions\n",
    "        self.mes_win.focus()\n",
    "\n",
    "        self.textcon.config(fg='black')\n",
    "        self.textcon.tag_config('usr', foreground='black')\n",
    "        self.textcon.insert(tk.END, \"chitti : This is chitti! Your Assistant.\\n\\n\")\n",
    "\n",
    "        self.exit_list = ['goodbye', 'bye', 'off']\n",
    "\n",
    "        mic_image_path = \"mic.png\"\n",
    "        if os.path.exists(mic_image_path):\n",
    "            self.mic_image = PhotoImage(file=mic_image_path).subsample(2, 3)\n",
    "        else:\n",
    "            print(f\"Error: Mic image not found at {mic_image_path}\")\n",
    "            self.mic_image = None\n",
    "\n",
    "        self.mic_button = Button(self.root, text='Mic', bg='blue', activebackground='white',\n",
    "                                 command=self.activate_mic, width=12, height=2, font=('Arial'))\n",
    "        self.mic_button.place(x=800, y=720, height=60, width=110)  # Adjusted dimensions\n",
    "\n",
    "        self.send_button = Button(self.root, text='Send', bg='pink', activebackground='grey',\n",
    "                                   command=self.send_msz, width=12, height=2, font=('Arial'))\n",
    "        self.send_button.place(x=680, y=720, height=60, width=110)  # Adjusted dimensions\n",
    "\n",
    "        self.language_listbox = Listbox(self.root, selectmode=tk.SINGLE, exportselection=False)\n",
    "        self.language_listbox.place(x=920, y=720, height=60, width=80)\n",
    "        self.language_listbox.insert(1, \"Telugu\")\n",
    "        self.language_listbox.insert(2, \"Kannada\")\n",
    "        self.language_listbox.insert(3, \"Tamil\")\n",
    "        self.language_listbox.insert(4, \"Hindi\")\n",
    "        self.language_listbox.select_set(0)\n",
    "\n",
    "        self.root.bind('<Return>', self.send_msz)\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.translator = Translator()\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def send_msz(self, event=None):\n",
    "        usr_input = self.message.get()\n",
    "        usr_input = usr_input.lower()\n",
    "        self.textcon.insert(tk.END, f'You : {usr_input}' + '\\n', 'usr')\n",
    "\n",
    "        if usr_input.lower() in [\"goodbye\", \"bye\"]:\n",
    "            self.textcon.config(fg='black')\n",
    "            response = \"Thank You sir, I hope I assisted you properly\"\n",
    "            self.textcon.insert(tk.END, f\"chitti : {response}\\n\")\n",
    "            self.speak(response)\n",
    "            return self.root.destroy()\n",
    "\n",
    "        elif \"translate\" in usr_input:\n",
    "            self.speak(\"Sure, I can help with translation. Please select a language option.\")\n",
    "            self.selected_language = self.language_listbox.get(tk.ACTIVE).lower()\n",
    "\n",
    "        else:\n",
    "            self.textcon.config(fg='black')\n",
    "            response = self.handle_user_input(usr_input)\n",
    "            self.textcon.insert(tk.END, f\"chitti: {response}\\n\")\n",
    "            # Speak only if the input is from the microphone and not a translation request\n",
    "            if hasattr(self, 'input_source') and self.input_source == 'mic' and not self.selected_language:\n",
    "                self.speak(response)\n",
    "            self.mes_win.delete(0, tk.END)\n",
    "\n",
    "    def activate_mic(self):\n",
    "        if self.mic_image:\n",
    "            self.mic_button.config(image=self.mic_image)\n",
    "        else:\n",
    "            self.mic_button.config(text=\"Mic\")\n",
    "\n",
    "        self.is_listening = True\n",
    "        threading.Thread(target=self.listen_continuously).start()\n",
    "\n",
    "    def listen_continuously(self):\n",
    "        r = sr.Recognizer()\n",
    "\n",
    "        while self.is_listening:\n",
    "            if not self.greeted:\n",
    "                self.greeted = True\n",
    "                self.speak(\"Hello sir! I am your chitti.\")\n",
    "                current_time = datetime.now().strftime(\"%I:%M %p\")\n",
    "                self.speak(f\"The current time is {current_time}\")\n",
    "\n",
    "            engine = pyttsx3.init()\n",
    "            rate = engine.getProperty('rate')\n",
    "            engine.setProperty('rate', 170)\n",
    "            voices = engine.getProperty('voices')\n",
    "            engine.setProperty('voice', voices[1].id)\n",
    "\n",
    "            with sr.Microphone() as source:\n",
    "                r.energy_threshold = 400\n",
    "                r.adjust_for_ambient_noise(source, 1.2)\n",
    "                self.textcon.insert(tk.END, \"chitti: Listening... \\n\")  # Display listening message in textcon\n",
    "\n",
    "                try:\n",
    "                    audio = r.listen(source)\n",
    "                    text = r.recognize_google(audio)\n",
    "                    self.textcon.insert(tk.END, f\"You (Mic): {text}\\n\", 'usr')  # Display user's input in textcon\n",
    "                    self.input_source = 'mic'\n",
    "\n",
    "                    # Handle the user input (speech-to-text)\n",
    "                    response = self.handle_user_input(text)\n",
    "                    self.textcon.insert(tk.END, f\"chitti: {response}\\n\")\n",
    "                    if self.input_source == 'mic' and not self.selected_language:\n",
    "                        self.speak(response)\n",
    "\n",
    "                except UnknownValueError:\n",
    "                    print(\"chitti: Sorry, I could not understand the audio. Please try again.\")\n",
    "\n",
    "                except sr.RequestError as e:\n",
    "                    print(f\"chitti: There was an error with the speech recognition service: {e}\")\n",
    "\n",
    "    def speak(self, text):\n",
    "        self.engine.say(text)\n",
    "        self.engine.runAndWait()\n",
    "\n",
    "    def handle_user_input(self, user_input):\n",
    "        user_keywords = self.extract_keywords(user_input)\n",
    "\n",
    "        for example in data.get(\"intents\", []):\n",
    "            if \"question\" in example:\n",
    "                question_keywords = [keyword for q in example[\"question\"] for keyword in self.extract_keywords(q)]\n",
    "\n",
    "                if all(keyword in question_keywords for keyword in user_keywords):\n",
    "                    answer = example.get(\"answer\", [])\n",
    "                    return f\"{answer}\"\n",
    "\n",
    "        if self.selected_language:\n",
    "            # Translate the user input to English using the googletrans library\n",
    "            translated_text = self.translate_text(user_input, self.selected_language, \"en\")\n",
    "\n",
    "            self.speak(\"Here is the translation:\")\n",
    "            self.textcon.insert(tk.END, f\"chitti: Translation: {translated_text}\\n\")\n",
    "\n",
    "        else:\n",
    "            input_ids = tokenizer.encode(user_input, return_tensors=\"tf\")\n",
    "            output = gpt_model.generate(input_ids, max_length=150, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95,\n",
    "                                        temperature=0.7)\n",
    "            bot_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "            # Adjust the response based on the user's technical ability\n",
    "            technical_ability = \"tech\"  # You need to get this value from somewhere\n",
    "            if technical_ability == \"tech\":\n",
    "                # Customize response for technical users\n",
    "                pass\n",
    "            else:\n",
    "                # Customize response for non-technical users\n",
    "                pass\n",
    "\n",
    "            candidate_answers = [\"Your first answer\", \"Your second answer\", \"Your third answer\"]\n",
    "            relevancy_scores = self.score_relevancy(user_input, candidate_answers)\n",
    "\n",
    "            # Store or update relevancy scores for future learning\n",
    "            # Update your model based on user feedback and learning algorithm\n",
    "\n",
    "            return bot_response\n",
    "\n",
    "    def extract_keywords(self, text):\n",
    "        doc = nlp(text)\n",
    "        return [token.text.lower() for token in doc if token.is_alpha]\n",
    "\n",
    "    def score_relevancy(self, user_input, candidate_answers):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([user_input] + candidate_answers)\n",
    "        similarity_matrix = cosine_similarity(vectors)\n",
    "        relevancy_scores = similarity_matrix[0][1:]\n",
    "        return relevancy_scores\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def translate_text(self, text, source_language, target_language):\n",
    "        translator = Translator()\n",
    "\n",
    "        if source_language not in LANGUAGES or target_language not in LANGUAGES:\n",
    "            return \"Invalid source or target language.\"\n",
    "\n",
    "        translation = translator.translate(text, src=source_language, dest=target_language)\n",
    "        translated_text = translation.text\n",
    "\n",
    "        self.textcon.insert(tk.END, f\"chitti: Translation: {translated_text}\\n\")\n",
    "        self.speak(\"Here is the translation:\")\n",
    "        self.speak(translated_text)\n",
    "\n",
    "        return translated_text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot_app = ChatbotApp()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08367193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
